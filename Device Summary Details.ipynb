{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a796d3e4-adbd-4303-84b5-33afbe20131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import streamlit as st\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "import pyodbc\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from pandasai import SmartDataframe\n",
    "import pandas as pd\n",
    "# from pandasai.llm import AzureOpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import base64\n",
    "import pandasql as ps\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "#Initializing API Keys to use LLM\n",
    "AZURE_OPENAI_API_KEY = '17299c5927e64bb382352a6e246fa6ef'\n",
    "AZURE_OPENAI_ENDPOINT = 'https://fordmustang.openai.azure.com/'\n",
    "\n",
    "\n",
    "#Reading the dataset\n",
    "Sentiment_Data  = pd.read_csv(\"Sampled_Copilot_Reviews_Final.csv\")\n",
    "\n",
    "#Function to derive Sentiment Score based on Sentiment\n",
    "def Sentiment_Score_Derivation(value):\n",
    "    try:\n",
    "        if value == \"positive\":\n",
    "            return 1\n",
    "        elif value == \"negative\":\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while deriving Sentiment Score: {e}\"\n",
    "        return err    \n",
    "\n",
    "#Deriving Sentiment Score and Review Count columns into the dataset\n",
    "Sentiment_Data[\"Sentiment_Score\"] = Sentiment_Data[\"Sentiment\"].apply(Sentiment_Score_Derivation)\n",
    "Sentiment_Data[\"Review_Count\"] = 1.0\n",
    "\n",
    "\n",
    "################################# Definiting Functions #################################\n",
    "\n",
    "#Review Summarization (Detailed) + Feature Comparison and Suggestion\n",
    "\n",
    "#Function to extract text from file\n",
    "def get_text_from_file(txt_file):\n",
    "    try:\n",
    "        with open(txt_file, 'r',encoding='latin') as file:\n",
    "            text = file.read()\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting text from file: {e}\"\n",
    "        return err\n",
    "\n",
    "# Function to split text into chunks\n",
    "def get_text_chunks(text):\n",
    "    try:\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting text chunks: {e}\"\n",
    "        return err\n",
    "\n",
    "# Function to create and store embeddings\n",
    "def get_vector_store(text_chunks):\n",
    "    try:\n",
    "        embeddings = AzureOpenAIEmbeddings(azure_deployment=\"MV_Agusta\")\n",
    "        vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)\n",
    "        vector_store.save_local(\"faiss_index_CopilotSample\")\n",
    "        return vector_store\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting vectos: {e}\"\n",
    "        return err\n",
    "\n",
    "# Function to setup the vector store (to be run once or upon text update)\n",
    "def setup(txt_file_path):\n",
    "    try:\n",
    "        raw_text = get_text_from_file(txt_file_path)\n",
    "        text_chunks = get_text_chunks(raw_text)\n",
    "        get_vector_store(text_chunks)\n",
    "        print(\"Setup completed. Vector store is ready for queries.\")\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while setting up vector store: {e}\"\n",
    "        return err\n",
    "\n",
    "# Function to get conversational chain\n",
    "def get_conversational_chain_detailed(history):\n",
    "    try:\n",
    "        hist = \"\"\"\"\"\"\n",
    "        for i in history:\n",
    "            hist = hist+\"\\nUser: \"+i[0]\n",
    "            if isinstance(i[1],pd.DataFrame):\n",
    "                x = i[1].to_string()\n",
    "            else:\n",
    "                x = i[1]\n",
    "            hist = hist+\"\\nResponse: \"+x\n",
    "        prompt_template = \"\"\"\n",
    "        Given a dataset with these columns: Review, Data_Source, Geography, Product_Family, Sentiment and Aspect (also called Features)\n",
    "          \n",
    "          Review: This column contains the opinions and experiences of users regarding different product families across geographies, providing insights into customer satisfaction or complaints and areas for improvement.\n",
    "          Data_Source: This column indicates the platform from which the user reviews were collected, such as Reddit, Play Store, App Store, Tech Websites, or YouTube videos.\n",
    "          Geography: This column lists the countries of the users who provided the reviews, allowing for an analysis of regional preferences and perceptions of the products.\n",
    "          Product_Family: This column identifies the broader category of products to which the revie\n",
    "w pertains, enabling comparisons and trend analysis across different product families.\n",
    "          Sentiment: This column reflects the overall tone of the review, whether positive, negative, or neutral, and is crucial for gauging customer sentiment.\n",
    "          Aspect: This column highlights the particular features or attributes of the product that the review discusses, pinpointing areas of strength or concern.\n",
    "          \n",
    "          Perform the required task from the list below, as per user's query: \n",
    "          1. Review Summarization - Summarize the reviews by filtering the relevant Aspect, Geography, Product_Family, Sentiment or Data_Source, only based on available reviews and their sentiments in the dataset.\n",
    "          2. Aspect Comparison - Provide a summarized comparison for each overlapping feature/aspect between the product families or geographies ,  only based on available user reviews and their sentiments in the dataset. Include pointers for each aspect highlighting the key differences between the product families or geographies, along with the positive and negative sentiments as per customer perception.\n",
    "          3. New Feature Suggestion/Recommendation - Generate feature suggestions or improvements or recommendations based on the frequency and sentiment of reviews and mentioned aspects and keywords. Show detailed responses to user queries by analyzing review sentiment, specific aspects, and keywords.\n",
    "          4. Hypothetical Reviews - Based on varying customer sentiments for the reviews in the existing dataset, generate hypothetical reviews for any existing feature updation or new feature addition in any device family across any geography, by simulating user reactions. Ensure to synthesize realistic reviews that capture all types of sentiments and opinions of users, by considering their hypothetical prior experience working with the new feature and generate output based on data present in dataset only. After these, provide solutions/remedies for negative hypothetical reviews. \n",
    "          \n",
    "          Enhance the model’s comprehension to accurately interpret user queries by:\n",
    "          Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.\n",
    "          Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).\n",
    "          Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references\n",
    "          Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.\n",
    "          Generate acurate response only, do not provide extra information.\n",
    "            \n",
    "            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\\n Following is the previous conversation from User and Response, use it to get context only:\"\"\" + hist + \"\"\"\\n\n",
    "                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\\n\n",
    "        Context:\\n {context}?\\n\n",
    "        Question: \\n{question}\\n\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_deployment=\"Thruxton_R\",\n",
    "            api_version='2024-03-01-preview',\n",
    "            temperature = 0.4)\n",
    "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "        return chain\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting conversation chain for detailed review summarization: {e}\"\n",
    "        return err\n",
    "\n",
    "# Function to handle user queries using the existing vector store\n",
    "def query_detailed(user_question, history, vector_store_path=\"faiss_index_CopilotSample\"):\n",
    "    try:\n",
    "        embeddings = AzureOpenAIEmbeddings(azure_deployment=\"MV_Agusta\")\n",
    "        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        chain = get_conversational_chain_detailed(history)\n",
    "        docs = vector_store.similarity_search(user_question)\n",
    "        response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
    "        return response[\"output_text\"]\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting LLM response for detailed review summarization: {e}\"\n",
    "        return err\n",
    "\n",
    "\n",
    "## Review Summarization (Quantifiable)\n",
    "\n",
    "#Converting Top Operator to Limit Operator as pandasql doesn't support Top\n",
    "def convert_top_to_limit(sql):\n",
    "    try:\n",
    "        tokens = sql.upper().split()\n",
    "        is_top_used = False\n",
    "\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token == 'TOP':\n",
    "                is_top_used = True\n",
    "                if i + 1 < len(tokens) and tokens[i + 1].isdigit():\n",
    "                    limit_value = tokens[i + 1]\n",
    "                    # Remove TOP and insert LIMIT and value at the end\n",
    "                    del tokens[i:i + 2]\n",
    "                    tokens.insert(len(tokens), 'LIMIT')\n",
    "                    tokens.insert(len(tokens), limit_value)\n",
    "                    break  # Exit loop after successful conversion\n",
    "                else:\n",
    "                    raise ValueError(\"TOP operator should be followed by a number\")\n",
    "\n",
    "        return ' '.join(tokens) if is_top_used else sql\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while converting Top to Limit in SQL Query: {e}\"\n",
    "        return err\n",
    "\n",
    "#Function to add Table Name into the SQL Query as it is, as the Table Name is Case Sensitive here\n",
    "def process_tablename(sql, table_name):\n",
    "    try:\n",
    "        x = sql.upper()\n",
    "        query = x.replace(table_name.upper(), table_name)\n",
    "        return query\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while processing table name in SQL query: {e}\"\n",
    "        return err\n",
    "\n",
    "## Generating Response by Identifying Prompt Nature\n",
    "\n",
    "#Function to get conversation chain for quantitative outputs and also add context from historical conversation as well\n",
    "def get_conversational_chain_quant(history):\n",
    "    try:\n",
    "        hist = \"\"\"\"\"\"\n",
    "        for i in history:\n",
    "            hist = hist+\"\\nUser: \"+i[0]\n",
    "            if isinstance(i[1],pd.DataFrame):\n",
    "                x = i[1].to_string()\n",
    "            else:\n",
    "                x = i[1]\n",
    "            hist = hist+\"\\nResponse: \"+x\n",
    "        prompt_template = \"\"\"\n",
    "        1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.\n",
    "            2. There is only one table with table name Sentiment_Data where each row is a user review. The table has 10 columns, they are:\n",
    "                Review: Review of the Copilot Product\n",
    "                Data_Source: From where is the review taken. It contains following values: 'LaptopMag', 'PCMag', 'Verge', 'ZDNET', 'PlayStore', 'App Store','AppStore', 'Reddit', 'YouTube'.\n",
    "                Geography: From which Country or Region the review was given. It contains following values: 'Unknown', 'Brazil', 'Australia', 'Canada', 'China', 'Germany','France'.\n",
    "                Title: What is the title of the review\n",
    "                Review_Date: The date on which the review was posted\n",
    "                Product: Corresponding product for the review. It contains following values: 'COPILOT'.\n",
    "                Product_Family: Which version or type of the corresponding Product was the review posted for. It contains following values: 'Copilot in Windows 11', 'Copilot for Microsoft 365','Microsoft Copilot', 'Copilot for Security', 'Copilot Pro','Github Copilot', 'Copilot for Mobile'.\n",
    "                Sentiment: What is the sentiment of the review. It contains following values: 'positive', 'neutral', 'negative'.\n",
    "                Aspect: The review is talking about which aspect or feature of the product. It contains following values: 'Microsoft Product', 'Interface', 'Connectivity', 'Privacy','Compatibility', 'Generic', 'Innovation', 'Reliability','Productivity', 'Price', 'Text Summarization/Generation','Code Generation', 'Ease of Use', 'Performance','Personalization/Customization'.\n",
    "                Keyword: What are the keywords mentioned in the product\n",
    "                Review_Count - It will be 1 for each review or each row\n",
    "                Sentiment_Score - It will be 1, 0 or -1 based on the Sentiment.\n",
    "            3. Sentiment mark is calculated by sum of Sentiment_Score.\n",
    "            4. Net sentiment is calculcated by sum of Sentiment_Score divided by sum of Review_Count. It should be in percentage. Example:\n",
    "                    SELECT ((SUM(Sentiment_Score)*1.0)/(SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment \n",
    "                    FROM Sentiment_Data\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            5. Net sentiment across country or across region is sentiment mark of a country divided by total reviews of that country. It should be in percentage.\n",
    "                Example to calculate net sentiment across country:\n",
    "                    SELECT Geography, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment\n",
    "                    FROM Sentiment_Data\n",
    "                    GROUP BY Geography\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            6. Net Sentiment across a column \"X\" is calculcated by Sentiment Mark for each \"X\" divided by Total Reviews for each \"X\".\n",
    "                Example to calculate net sentiment across a column \"X\":\n",
    "                    SELECT X, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment\n",
    "                    FROM Sentiment_Data\n",
    "                    GROUP BY X\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            7. Distribution of sentiment is calculated by sum of Review_Count for each Sentiment divided by overall sum of Review_Count\n",
    "                Example: \n",
    "                    SELECT Sentiment, SUM(ReviewCount)*100/(SELECT SUM(Review_Count) AS Reviews FROM Sentiment_Data) AS Total_Reviews \n",
    "                    FROM Sentiment_Data \n",
    "                    GROUP BY Sentiment\n",
    "                    ORDER BY Total_Reviews DESC\n",
    "            8. Convert numerical outputs to float upto 1 decimal point.\n",
    "            9. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.\n",
    "            10. Top Country is based on Sentiment_Score i.e., the Country which have highest sum(Sentiment_Score)\n",
    "            11. Always use 'LIKE' operator whenever they mention about any Country. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.\n",
    "            12. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.\n",
    "            13. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.\n",
    "            14. Important: Always show Net_Sentiment in Percentage upto 1 decimal point. Hence always make use of ROUND function while giving out Net Sentiment and Add % Symbol after it.\n",
    "            15. Important: User can ask question about any categories including Aspects, Geograpgy, Sentiment etc etc. Hence, include the in SQL Query if someone ask it.\n",
    "            16. Important: You Response should directly starts from SQL query nothing else.\n",
    "            17. Important: Always use LIKE keyword instead of = symbol while generating SQL query.\n",
    "            18. Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\n",
    "        \\n Following is the previous conversation from User and Response, use it to get context only:\"\"\" + hist + \"\"\"\\n\n",
    "                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\\n\n",
    "        Context:\\n {context}?\\n\n",
    "        Question: \\n{question}\\n\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_deployment=\"Thruxton_R\",\n",
    "            api_version='2024-03-01-preview',\n",
    "            temperature = 0.3)\n",
    "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "        return chain\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting conversation chain for quantifiable review summarization: {e}\"\n",
    "        return err\n",
    "\n",
    "#Function to convert user prompt to quantitative outputs for Copilot Review Summarization\n",
    "def query_quant(user_question, history, vector_store_path=\"faiss_index_CopilotSample\"):\n",
    "    try:\n",
    "        # Initialize the embeddings model\n",
    "        embeddings = AzureOpenAIEmbeddings(azure_deployment=\"MV_Agusta\")\n",
    "        \n",
    "        # Load the vector store with the embeddings model\n",
    "        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        \n",
    "        # Rest of the function remains unchanged\n",
    "        chain = get_conversational_chain_quant(history)\n",
    "        docs = []\n",
    "        response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
    "        SQL_Query = response[\"output_text\"]\n",
    "        SQL_Query = convert_top_to_limit(SQL_Query)\n",
    "        SQL_Query = process_tablename(SQL_Query,\"Sentiment_Data\")\n",
    "    #     print(SQL_Query)\n",
    "        data = ps.sqldf(SQL_Query, globals())\n",
    "        data_1 = data\n",
    "        html_table = data.to_html(index=False)\n",
    "    #     return html_table\n",
    "        return data_1\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while generating response for quantitative review summarization: {e}\"\n",
    "        return err\n",
    "\n",
    "\n",
    "## Generating Response by Identifying Prompt Nature\n",
    "\n",
    "\n",
    "#Function to identify the nature of prompt, whether the user is asking for a detailed summary or a quantitative summary\n",
    "def identify_prompt(user_question):\n",
    "    try:\n",
    "        prompt_template = \"\"\"\n",
    "        Given a user prompt about customer reviews for products (Copilot, Windows, Surface) and various different features, classify the prompt into one of two categories:\n",
    "            Quantifiable: This prompt seeks a numerical answer or data point related to the reviews. \n",
    "                            (e.g., \"What is the net sentiment score for Product A reviews?\", \n",
    "                                    \"How many reviews mention the battery life of Product B?\", \n",
    "                                    \"Calculate the net sentiment of Product A.\", \n",
    "                                    \"Net Sentiment\", \n",
    "                                    \"Sentiment Score\", \n",
    "                                    \"Top Countries\", \n",
    "                                    \"Top Products\", etc.)\n",
    "            Detailed: This prompt seeks a summary, comparison, recommendation/suggestion or hypothetical reviews based on the reviews, expressed in words. The task can be either Review Summarization, Feature Comparison, New Feature Suggestion/Recommendation or Hypothetical Reviews generation based on the type of user question:\n",
    "                      (example of Review Summarization - Summarize / Give a summary of the reviews for different product families or geographies, \n",
    "                      example of Aspect Comparison - Give feature comparison among product families a1,a2,a3... across geographies g1,g2,g3... or Compare the features of product families a1,a2,a3... across geographies g1,g2,g3,... or Compare utility of feature 'x' among product families a1,a2,a3... across geographies g1,g2,g3... , \n",
    "                      example of New Feature Suggestion/Recommendation - Suggest new features or improvements or recommendations for different product families in different geographies,\n",
    "                      example of Hypothetical Reviews - Generate hypothetical user reviews for the feature upgrade for any product family in any geography, focusing on the feature/aspect or Provide hypothetical user reviews for the addition of the new feature 'x' in any product family across any geography)\n",
    "\n",
    "        Input: User prompt about customer reviews\n",
    "        Output: Category (Quantifiable or Detailed)\n",
    "        Context:\\n {context}?\\n\n",
    "        Question: \\n{question}\\n\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_deployment=\"Thruxton_R\",\n",
    "            api_version='2024-03-01-preview')\n",
    "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "        response = chain({\"input_documents\": [], \"question\": user_question}, return_only_outputs=True)\n",
    "        if \"detailed\" in response[\"output_text\"].lower():\n",
    "            return \"Detailed\"\n",
    "        elif \"quantifiable\" in response[\"output_text\"].lower():\n",
    "            return \"Quantifiable\"\n",
    "        else:\n",
    "            return \"Others\"+\"\\nPrompt Identified as:\"+response[\"output_text\"]+\"\\n\"\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while generating conversation chain for identifying nature of prompt: {e}\"\n",
    "        return err\n",
    "\n",
    "#Function to generate Review Summarization (Detailed)/Feature Comparison/Feature Suggestion from User Prompt\n",
    "def review_summarization(user_question, history):\n",
    "    try:\n",
    "        txt_file_path = \"Sample_Copilot_Reviews_50K_Translated_v2.txt\"\n",
    "        # Automatically call setup with the predefined file on startup\n",
    "        if not os.path.exists(\"faiss_index_CopilotSample\"):\n",
    "            setup(txt_file_path)\n",
    "\n",
    "        if os.path.exists(\"faiss_index_CopilotSample\"):\n",
    "            response = query_detailed(user_question, history)\n",
    "            return response\n",
    "        else:\n",
    "            return \"The vector store setup has failed. Please check the file path and try again.\"\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while generating detailed review summarization: {e}\"\n",
    "        return err\n",
    "\n",
    "#Function to generate Quantitative Review Summarization from User Prompt\n",
    "def quantifiable_data(user_question, history):\n",
    "    try:\n",
    "        response = query_quant(user_question, history)\n",
    "        \n",
    "        return response\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while generating quantitative review summarization: {e}\"\n",
    "        return err\n",
    "\n",
    "#Function to generate a response from User Question\n",
    "def device_llm_review_generator(user_question, history):\n",
    "    try:\n",
    "        identity_prompt = identify_prompt(user_question)\n",
    "        if identity_prompt == \"Detailed\":\n",
    "            output = review_summarization(user_question, history)\n",
    "        elif identity_prompt == \"Quantifiable\":\n",
    "            output = quantifiable_data(user_question, history)\n",
    "\n",
    "            if output.isnull().all().all() or output.empty:\n",
    "                output = \"I don't have necessary knowledge to provide a helpful response. Please ask anything related to Insights around Copilot customer feedback and I'll do my best to assist you.\"\n",
    "                \n",
    "        else:\n",
    "            output = \"Error: Cannot identify the nature of your question\\nPrompt identified as: \"+identity_prompt\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while generating LLM response: {e}\"\n",
    "        return err\n",
    "\n",
    "\n",
    "################################# Model Deployment #################################\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "    # Chat history state management\n",
    "        if 'chat_history' not in st.session_state:\n",
    "            st.session_state['chat_history'] = []\n",
    "\n",
    "        # Create a container for logos and title with horizontal layout\n",
    "        col1, col2, col3 = st.columns([1, 2, 1])\n",
    "      \n",
    "        # Display logo on the left\n",
    "        with col1:\n",
    "            st.image(\"microsoft_logo.png\", width=50)  # Adjust width as needed\n",
    "\n",
    "        # Display title in the center\n",
    "        with col2:\n",
    "            st.header(\"Copilot LLM Review Generator\")\n",
    "\n",
    "        # Display logo on the right\n",
    "        with col3:\n",
    "            st.image(\"copilot_logo.svg\", width=50)  # Align the logo to the right\n",
    "      \n",
    "        # User input section\n",
    "        user_input = st.text_input(\"Enter your text:\", placeholder=\"What would you like to process?\")\n",
    "\n",
    "        # Process button and output section\n",
    "        if st.button(\"Process\"):\n",
    "            # Re-check if 'chat_history' is initialized before appending\n",
    "            if 'chat_history' not in st.session_state:\n",
    "                st.session_state['chat_history'] = []\n",
    "            \n",
    "            output = device_llm_review_generator(user_input,st.session_state['chat_history'])\n",
    "            st.session_state['chat_history'].append((user_input, output))\n",
    "        \n",
    "            # Display output based on type (string or dataframe)\n",
    "            if isinstance(output, pd.DataFrame):\n",
    "                st.dataframe(output)\n",
    "                \n",
    "            else:\n",
    "                st.write(output)\n",
    "\n",
    "        # Chat history section with some formatting\n",
    "        st.header(\"Chat History\")\n",
    "        for user_text, output_text in st.session_state['chat_history']:\n",
    "            st.markdown(f\"- You: {user_text}\")\n",
    "            if isinstance(output_text, pd.DataFrame):\n",
    "                st.dataframe(output_text)  # Convert dataframe to string for display\n",
    "            else:\n",
    "                st.markdown(f\"- Bot: {output_text}\")\n",
    "            st.write(\"---\")\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while calling the final function: {e}\"\n",
    "        print(err)\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0a2698-7a36-4e9b-b700-25343c3820fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "    # Chat history state management\n",
    "        if 'chat_history' not in st.session_state:\n",
    "            st.session_state['chat_history'] = []\n",
    "\n",
    "        # Create a container for logos and title with horizontal layout\n",
    "        col1, col2, col3 = st.columns([1, 2, 1])\n",
    "      \n",
    "        # Display logo on the left\n",
    "        with col1:\n",
    "            st.image(\"microsoft_logo.png\", width=50)  # Adjust width as needed\n",
    "\n",
    "        # Display title in the center\n",
    "        with col2:\n",
    "            st.header(\"Copilot LLM Review Generator\")\n",
    "\n",
    "        # Display logo on the right\n",
    "        with col3:\n",
    "            st.image(\"copilot_logo.svg\", width=50)  # Align the logo to the right\n",
    "      \n",
    "        # User input section\n",
    "        user_input = st.text_input(\"Enter your text:\", placeholder=\"What would you like to process?\")\n",
    "        if st.button(\"Process\"):\n",
    "            st.image(\"https://in-files.apjonlinecdn.com/landingpages/content-pages/visid-rich-content/hp-laptop-15/images/w100_product_highlight_v1.png\",width = 100)\n",
    "            st.write(\"HP Laptop 15\")\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while calling the final function: {e}\"\n",
    "        print(err)\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48be4a43-c513-4cfd-bbd2-7d848ed07e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-15 19:32:08.367 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2024-05-15 19:32:10.300 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Anaconda 3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48243d3d-5b03-46e9-b504-82494dc7b80a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1269006424.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    streamlit run C:\\Anaconda 3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "        1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.\n",
    "            2. There is only one table with table name Sentiment_Data where each row is a user review. The table has 10 columns, they are:\n",
    "                Review: Review of the Copilot Product\n",
    "                Data_Source: From where is the review taken. It contains following values: 'LaptopMag', 'PCMag', 'Verge', 'ZDNET', 'PlayStore', 'App Store','AppStore', 'Reddit', 'YouTube'.\n",
    "                Geography: From which Country or Region the review was given. It contains following values: 'Unknown', 'Brazil', 'Australia', 'Canada', 'China', 'Germany','France'.\n",
    "                Title: What is the title of the review\n",
    "                Review_Date: The date on which the review was posted\n",
    "                Product: Corresponding product for the review. It contains following values: 'COPILOT'.\n",
    "                Product_Family: Which version or type of the corresponding Product was the review posted for. It contains following values: 'Copilot in Windows 11', 'Copilot for Microsoft 365','Microsoft Copilot', 'Copilot for Security', 'Copilot Pro','Github Copilot', 'Copilot for Mobile'.\n",
    "                Sentiment: What is the sentiment of the review. It contains following values: 'positive', 'neutral', 'negative'.\n",
    "                Aspect: The review is talking about which aspect or feature of the product. It contains following values: 'Microsoft Product', 'Interface', 'Connectivity', 'Privacy','Compatibility', 'Generic', 'Innovation', 'Reliability','Productivity', 'Price', 'Text Summarization/Generation','Code Generation', 'Ease of Use', 'Performance','Personalization/Customization'.\n",
    "                Keyword: What are the keywords mentioned in the product\n",
    "                Review_Count - It will be 1 for each review or each row\n",
    "                Sentiment_Score - It will be 1, 0 or -1 based on the Sentiment.\n",
    "            3. Sentiment mark is calculated by sum of Sentiment_Score.\n",
    "            4. Net sentiment is calculcated by sum of Sentiment_Score divided by sum of Review_Count. It should be in percentage. Example:\n",
    "                    SELECT ((SUM(Sentiment_Score)*1.0)/(SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment \n",
    "                    FROM Sentiment_Data\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            5. Net sentiment across country or across region is sentiment mark of a country divided by total reviews of that country. It should be in percentage.\n",
    "                Example to calculate net sentiment across country:\n",
    "                    SELECT Geography, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment\n",
    "                    FROM Sentiment_Data\n",
    "                    GROUP BY Geography\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            6. Net Sentiment across a column \"X\" is calculcated by Sentiment Mark for each \"X\" divided by Total Reviews for each \"X\".\n",
    "                Example to calculate net sentiment across a column \"X\":\n",
    "                    SELECT X, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment\n",
    "                    FROM Sentiment_Data\n",
    "                    GROUP BY X\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            7. Distribution of sentiment is calculated by sum of Review_Count for each Sentiment divided by overall sum of Review_Count\n",
    "                Example: \n",
    "                    SELECT Sentiment, SUM(ReviewCount)*100/(SELECT SUM(Review_Count) AS Reviews FROM Sentiment_Data) AS Total_Reviews \n",
    "                    FROM Sentiment_Data \n",
    "                    GROUP BY Sentiment\n",
    "                    ORDER BY Total_Reviews DESC\n",
    "            8. Convert numerical outputs to float upto 1 decimal point.\n",
    "            9. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.\n",
    "            10. Top Country is based on Sentiment_Score i.e., the Country which have highest sum(Sentiment_Score)\n",
    "            11. Always use 'LIKE' operator whenever they mention about any Country. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.\n",
    "            12. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.\n",
    "            13. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.\n",
    "            14. Important: Always show Net_Sentiment in Percentage upto 1 decimal point. Hence always make use of ROUND function while giving out Net Sentiment and Add % Symbol after it.\n",
    "            15. Important: User can ask question about any categories including Aspects, Geograpgy, Sentiment etc etc. Hence, include the in SQL Query if someone ask it.\n",
    "            16. Important: You Response should directly starts from SQL query nothing else.\n",
    "            17. Important: Always use LIKE keyword instead of = symbol while generating SQL query.\n",
    "            18. Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\n",
    "        \\n Following is the previous conversation from User and Response, use it to get context only:\"\"\" + hist + \"\"\"\\n\n",
    "                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\\n\n",
    "        Context:\\n {context}?\\n\n",
    "        Question: \\n{question}\\n\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_deployment=\"Thruxton_R\",\n",
    "            api_version='2024-03-01-preview',\n",
    "            temperature = 0.3)\n",
    "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "        return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97d626cd-5132-4510-9f31-84e64f341fa4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for StuffDocumentsChain\n__root__\n  document_variable_name context was not found in llm_chain input_variables: [] (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m prompt \u001b[38;5;241m=\u001b[39m PromptTemplate(template\u001b[38;5;241m=\u001b[39mprompt_template, input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m AzureChatOpenAI(\n\u001b[0;32m      4\u001b[0m     azure_deployment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThruxton_R\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m     api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-03-01-preview\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      6\u001b[0m     temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m chain \u001b[38;5;241m=\u001b[39m load_qa_chain(model, chain_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstuff\u001b[39m\u001b[38;5;124m\"\u001b[39m, prompt\u001b[38;5;241m=\u001b[39mprompt)\n",
      "File \u001b[1;32mC:\\Anaconda 3\\Lib\\site-packages\\langchain\\chains\\question_answering\\__init__.py:249\u001b[0m, in \u001b[0;36mload_qa_chain\u001b[1;34m(llm, chain_type, verbose, callback_manager, **kwargs)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chain_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loader_mapping:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unsupported chain type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchain_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloader_mapping\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m     )\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loader_mapping[chain_type](\n\u001b[0;32m    250\u001b[0m     llm, verbose\u001b[38;5;241m=\u001b[39mverbose, callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    251\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda 3\\Lib\\site-packages\\langchain\\chains\\question_answering\\__init__.py:81\u001b[0m, in \u001b[0;36m_load_stuff_chain\u001b[1;34m(llm, prompt, document_variable_name, verbose, callback_manager, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m llm_chain \u001b[38;5;241m=\u001b[39m LLMChain(\n\u001b[0;32m     74\u001b[0m     llm\u001b[38;5;241m=\u001b[39mllm,\n\u001b[0;32m     75\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m_prompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m     79\u001b[0m )\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# TODO: document prompt\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m StuffDocumentsChain(\n\u001b[0;32m     82\u001b[0m     llm_chain\u001b[38;5;241m=\u001b[39mllm_chain,\n\u001b[0;32m     83\u001b[0m     document_variable_name\u001b[38;5;241m=\u001b[39mdocument_variable_name,\n\u001b[0;32m     84\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     callback_manager\u001b[38;5;241m=\u001b[39mcallback_manager,\n\u001b[0;32m     86\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m     88\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda 3\\Lib\\site-packages\\langchain_core\\load\\serializable.py:120\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mC:\\Anaconda 3\\Lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for StuffDocumentsChain\n__root__\n  document_variable_name context was not found in llm_chain input_variables: [] (type=value_error)"
     ]
    }
   ],
   "source": [
    "prompt_template = \"How are you?\"\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "model = AzureChatOpenAI(\n",
    "    azure_deployment=\"Thruxton_R\",\n",
    "    api_version='2024-03-01-preview',\n",
    "    temperature = 0.3)\n",
    "chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66fe63ed-d4ed-4c60-8fd7-fda912039642",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import streamlit as st\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "import pyodbc\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from pandasai import SmartDataframe\n",
    "import pandas as pd\n",
    "# from pandasai.llm import AzureOpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import base64\n",
    "import pandasql as ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea542a2-9fdb-4786-97c7-b44e88ae4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"672370cd6ca440f2a0327351d4f4d2bf\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://hulk-openai.openai.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "930e35e3-b633-4d29-887f-1ff1e6b60048",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"672370cd6ca440f2a0327351d4f4d2bf\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"https://hulk-openai.openai.azure.com/\")\n",
    "    )\n",
    "    \n",
    "deployment_name='SurfaceGenAI'\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "    1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.\n",
    "    2. There is only one table with table name RCR_Sales_Data where each row has. The table has 20 columns, they are:\n",
    "        Month: Contains dates for the records\n",
    "        Country: From where the sales has happened. It contains following values: 'Turkey','India','Brazil','Germany','Philippines','France','Netherlands','Spain','United Arab Emirates','Czech Republic','Norway','Belgium','Finland','Canada','Mexico','Russia','Austria','Poland','United States','Switzerland','Italy','Colombia','Japan','Chile','Sweden','Vietnam','Saudi Arabia','South Africa','Peru','Indonesia','Taiwan','Thailand','Ireland','Korea','Hong Kong SAR','Malaysia','Denmark','New Zealand','China' and 'Australia'.\n",
    "        Geography: From which Country or Region the review was given. It contains following values: 'Unknown', 'Brazil', 'Australia', 'Canada', 'China', 'Germany','France'.\n",
    "        OEMGROUP: OEM or Manufacturer of the Device. It contains following values: 'Lenovo','Acer','Asus','HP','All Other OEMs', 'Microsoft' and 'Samsung'\n",
    "        SUBFORMFACTOR: Formfactor of the device. It contains following values: 'Ultraslim Notebook'.\n",
    "        GAMINGPRODUCTS: Flag whether Device is a gaming device or not. It contains following values: 'GAMING', 'NO GAMING' and 'N.A.'.\n",
    "        SCREEN_SIZE_INCHES: Screen Size of the Device.\n",
    "        PRICE_BRAND_USD_3: Band of the price at which the device is selling. It contains following values: '0-300', '300-500', '500-800' and '800+.\n",
    "        OS_VERSION: Operating System version intall on the device. It contains following values: 'Windows 11', 'Chrome', 'Mac OS'.\n",
    "        Operating_System_Summary: Operating System installed on the device. This is at uber level. It contains following values: 'Windows', 'Google OS', 'Apple OS'.\n",
    "        Sales_Units: Number of Devices sold for that device in a prticular month and country.\n",
    "        Sales_Value: Revenue Generated by the devices sold.\n",
    "        Series: Family of the device such as IdeaPad 1, HP Laptop 15 etc.\n",
    "        Specs_Combination: Its contains the combination of Series, Processor, RAM , Storage and Screen Size. For Example: SURFACE LAPTOP GO | Ci5 | 8 GB | 256.0 SSD | 12\" .\n",
    "    3.  When Asked for Price Range you have to use ASP Column to get minimum and Maxium value. Do not consider Negative Values. Also Consider Sales Units it shouldn't be 0.\n",
    "        Exaple Query:\n",
    "            SELECT MIN(ASP) AS Lowest_Value, MAX(ASP) AS Highest_Value\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE\n",
    "            Series = 'Device Name'\n",
    "            AND ASP >= 0\n",
    "            AND Sales_Units <> 0;\n",
    "    4. Total Sales_Units Should Always be in Thousands. \n",
    "        Example Query:\n",
    "            SELECT (SUM(Sales_Units) / 1000) AS \"TOTAL SALES UNITS\"\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE\n",
    "            SERIES LIKE '%SURFACE LAPTOP GO%';\n",
    "    5. Average Selling Price (ASP): It is calculated by sum of SUM(Sales_Value)/SUM(Sales_Units)\n",
    "    6. Total Sales Units across countries or across regions is sum of sales_units for those country. It should be in thousand of million hence add \"K\" or \"M\" after the number.\n",
    "        Example to calculate sales units across country:\n",
    "            SELECT Country, (SUM(Sales_Units) / 1000) AS \"Sales_Units(In Thousands)\"\n",
    "            FROM RCR_Sales_Data\n",
    "            GROUP BY Country\n",
    "            ORDER BY Sales_Units DESC\n",
    "    7. Total Sales Units across column \"X\" or across regions is sum of sales_units for those country. It should be in thousand of million hence add \"K\" or \"M\" after the number.\n",
    "        Example to calculate sales units across country:\n",
    "            SELECT \"X\", (SUM(Sales_Units) / 1000) AS \"Sales_Units(In Thousands)\"\n",
    "            FROM RCR_Sales_Data\n",
    "            GROUP BY \"X\"\n",
    "            ORDER BY Sales_Units DESC\n",
    "    8. If asked about the highest selling Specs Combination. \n",
    "        Example Query:\n",
    "            SELECT Specs_Combination, (SUM(Sales_Units) / 1000) AS \"TOTAL SALES UNITS\"\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE SERIES LIKE '%Macbook AIR%'\n",
    "            AND SALES_UNITS <> 0\n",
    "            GROUP BY Specs_Combination\n",
    "            ORDER BY \"TOTAL SALES UNITS\" DESC\n",
    "            LIMIT 1;\n",
    "    9. If asked about similar compete devices.\n",
    "    Example Query:\n",
    "            WITH SurfaceLaptopGoASP AS (\n",
    "                SELECT\n",
    "                    'Surface Laptop Go' AS Series,\n",
    "                    SUM(Sales_Value) / SUM(Sales_Units) AS ASP\n",
    "                FROM\n",
    "                    RCR_Sales_Data\n",
    "                WHERE\n",
    "                    Series LIKE '%Surface Laptop Go%'\n",
    "            ),\n",
    "            CompetitorASP AS (\n",
    "                SELECT\n",
    "                    Series,\n",
    "                    SUM(Sales_Value) / SUM(Sales_Units) AS ASP\n",
    "                FROM\n",
    "                    RCR_Sales_Data\n",
    "                WHERE\n",
    "                    Operating_System_Summary IN ('Apple OS', 'Google OS')\n",
    "                GROUP BY\n",
    "                    Series\n",
    "            )\n",
    "            SELECT\n",
    "                C.Series,\n",
    "                C.ASP AS CompetitorASP\n",
    "            FROM\n",
    "                CompetitorASP C\n",
    "            JOIN\n",
    "                SurfaceLaptopGoASP S\n",
    "            ON\n",
    "                ABS(C.ASP - S.ASP) <= 200;\n",
    "    10. If asked about dates or year SUBSTR() function instead of Year() or Month()\n",
    "    11. Convert numerical outputs to float upto 2 decimal point.\n",
    "    12. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.\n",
    "    13. Always use 'LIKE' operator whenever they mention about any Country, Series. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.\n",
    "    14. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.\n",
    "    15. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.\n",
    "    16. Always use LIKE function instead of = Symbol while generating SQL Query\n",
    "    17. Important: User can ask question about any categories including Country, OEMGROUP,OS_VERSION etc etc. Hence, include the in SQL Query if someone ask it.\n",
    "    18. Important: Use the correct column names listed above. There should not be Case Sensitivity issue. \n",
    "    19. Important: The values in OPERATING_SYSTEM_SUMMARY are ('Apple OS', 'Google OS') not ('APPLE OS', 'GOOGLE OS'). So use exact values. Not everything should be capital letters.\n",
    "    20. Important: You Response should directly starts from SQL query nothing else.\"\"\"\n",
    "# Initialize an empty context\n",
    "\n",
    "def generate_SQL_Query(user_question):\n",
    "    global context\n",
    "    # Append the new question to the context\n",
    "    full_prompt = context + \"\\nQuestion:\\n\" + user_question + \"\\nAnswer:\"\n",
    "    \n",
    "    # Send the query to Azure OpenAI\n",
    "    response = client.completions.create(\n",
    "        model=deployment_name,\n",
    "        prompt=full_prompt,\n",
    "        max_tokens=500,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Extract the generated SQL query\n",
    "    sql_query = response.choices[0].text.strip()\n",
    "    \n",
    "    # Update context with the latest interaction\n",
    "    context += \"\\nQuestion:\\n\" + user_question + \"\\nAnswer:\\n\" + sql_query\n",
    "    \n",
    "    return sql_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42bdf206-a6b9-43ab-b9fa-22698aaaaea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting Top Operator to Limit Operator as pandasql doesn't support Top\n",
    "def convert_top_to_limit(sql):\n",
    "    tokens = sql.upper().split()\n",
    "    is_top_used = False\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == 'TOP':\n",
    "            is_top_used = True\n",
    "            if i + 1 < len(tokens) and tokens[i + 1].isdigit():\n",
    "                limit_value = tokens[i + 1]\n",
    "                # Remove TOP and insert LIMIT and value at the end\n",
    "                del tokens[i:i + 2]\n",
    "                tokens.insert(len(tokens), 'LIMIT')\n",
    "                tokens.insert(len(tokens), limit_value)\n",
    "                break  # Exit loop after successful conversion\n",
    "            else:\n",
    "                raise ValueError(\"TOP operator should be followed by a number\")\n",
    "\n",
    "    return ' '.join(tokens) if is_top_used else sql\n",
    "\n",
    "\n",
    "def process_tablename(sql, table_name):\n",
    "    x = sql.upper()\n",
    "    query = x.replace(table_name.upper(), table_name)\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a52a46e-63b7-4dd0-914f-4924f7aa5269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Month', 'Country', 'OEMGROUP', 'SUBFORMFACTOR', 'GAMINGPRODUCTS',\n",
       "       'SCREEN_SIZE_INCHES', 'PRICE_BRAND_USD_3', 'OS_VERSION',\n",
       "       'Operating_System_Summary', 'Sales_Units', 'Sales_Value', 'ASP',\n",
       "       'Series', 'Specs_Combination'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RCR_Sales_Data = pd.read_csv('RCR Sales Data Sample V2.csv')\n",
    "RCR_Sales_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061c6bb6-1ae7-4de4-86db-29ee695f7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What ASP for Surface Laptop Go\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "170087b1-d5eb-4edc-90e1-84226262a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = generate_SQL_Query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "6071686e-c009-4d6c-b7b8-1a75ef02c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT (SUM(SALES_VALUE) / SUM(SALES_UNITS)) AS ASP\n",
      "FROM RCR_Sales_Data\n",
      "WHERE\n",
      "SERIES LIKE '%SURFACE LAPTOP GO%'\n",
      "AND ASP >= 0\n",
      "AND SALES_UNITS <> 0;\n"
     ]
    }
   ],
   "source": [
    "SQL_Query = convert_top_to_limit(a)\n",
    "SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "print(SQL_Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "3862aa2b-b68b-48dc-bb84-2445c06d851b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ps.sqldf(SQL_Query, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "86613c27-b6bb-4771-83b5-a23175629548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>653.236509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ASP\n",
       "0  653.236509"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d8aac7f9-f87b-464f-a56d-93aae0b0f05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"How is Surface Laptop Go 2 performing in the market\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "72f0a689-dd50-4668-8d94-cff98fd2ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Device Images.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "bb847cad-fc87-49c5-8ed1-3517c1fc329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_image():\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    for i in df['Device Name']:\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "    link = df[df['Device Name']==dev]['Link'][0]\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "d6b61680-d8e9-469a-adcb-cae97966d735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://m.media-amazon.com/images/I/41JM2AxnD9L.jpg\n"
     ]
    }
   ],
   "source": [
    "get_device_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e2f0ba-98ef-4bb3-a27f-795f60094c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca3877a-af09-40bc-af4e-b9af7e9e44a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f02e2-9b04-48ec-9798-06ec3276ac37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052a6d2e-57a0-4fd6-adbc-11d8a66b0fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a055a8e2-7a43-497b-b3f4-5085189cd641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad24aef2-69b2-4ec6-86c8-fbc252b89c82",
   "metadata": {},
   "source": [
    "# Code to get sales units for a device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "efeef561-6e42-4800-adf7-dcb4a91e2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales_units(device_name):\n",
    "    question = \"Totals Sales Units for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name = data.columns[0]\n",
    "    total_sales = data[col_name][0]\n",
    "    total_sales = str(round(total_sales,2)) + \"K\"\n",
    "    return total_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "2304ebba-c60f-4481-bc79-5d4d17123c79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'271.32K'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = get_sales_units(\"Surface Laptop Go\")\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "3905a62c-49b7-44c8-a900-066295521c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ASP(device_name):\n",
    "    question = \"What's ASP for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name = data.columns[0]\n",
    "    asp = data[col_name][0]\n",
    "    asp = \"$\" + str(int(round(asp,0)))\n",
    "    return asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f749d1a7-7890-4967-919b-fc306ed88705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$653'"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = get_ASP(\"Surface Laptop Go\")\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f91e2c6-4d57-4791-a97f-f8c4a84ff41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_selling_specs(device_name):\n",
    "    question = \"What's highest selling Specs Combination for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name1 = data.columns[0]\n",
    "    col_name2 = data.columns[1]\n",
    "    specs = data[col_name1][0]\n",
    "    sales_unit = data[col_name2][0]\n",
    "    sales_unit = str(round(sales_unit,2)) + \"K\"\n",
    "    return specs,sales_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ecc92f3-7885-41bf-ab17-809561230453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MACBOOK AIR M1 | M1 | 8 GB | 256 SSD | 13\"  -  2621.18K\n"
     ]
    }
   ],
   "source": [
    "abc,su = get_highest_selling_specs(\"Macbook Air\")\n",
    "print(abc,\" - \",su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "fe5aebb7-3ce9-45a5-858f-82fe8581c5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compete_device(device_name):\n",
    "    question = \"What are the compete device for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    SQL_Query = SQL_Query.replace('APPLE','Apple')\n",
    "    SQL_Query = SQL_Query.replace('GOOGLE','Google')\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name1 = data.columns[0]\n",
    "    devices = list(data[col_name1])\n",
    "    return devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f54ebaee-b2f9-4f3f-a4d4-1fc46ba03a6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compete_device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m abc \u001b[38;5;241m=\u001b[39m compete_device(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurface Laptop Go\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m abc\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compete_device' is not defined"
     ]
    }
   ],
   "source": [
    "abc = compete_device(\"Surface Laptop Go\")\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6554ea4a-390a-41b5-b9e1-8e36a7e828d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"672370cd6ca440f2a0327351d4f4d2bf\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"https://hulk-openai.openai.azure.com/\")\n",
    "    )\n",
    "    \n",
    "deployment_name='SurfaceGenAI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71cf6ff2-edb5-4c2b-9eba-ae3fce62f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_summary_template_prompt = \"\"\"Provide a detailed consumer review summary for the [device_name] with aspect-wise net sentiment. Please mention what consumers like and dislike about the device, focusing on Performance, Design, and Display.\n",
    "Overall, the [device_name] is well-received by consumers, with its performance, design, and display being the standout features. However, there are some minor criticisms regarding performance issues and display brightness.\n",
    "Aspect: Performance\n",
    "Net Sentiment: +70%\n",
    "Likes: Users appreciate the smooth performance of the device, noting its fast processing speed and ability to handle multitasking with ease.\n",
    "Dislikes: Some users have reported occasional lag or slowdowns, especially when running demanding applications or games.\n",
    "\n",
    "Aspect: Design\n",
    "Net Sentiment: +85%\n",
    "Likes: Consumers love the sleek and compact design of the device, praising its lightweight build and premium look and feel.\n",
    "Dislikes: A few users find the design too simplistic and wish for more color options or customizable features.\n",
    "\n",
    "Aspect: Display\n",
    "Net Sentiment: +75%\n",
    "Likes: Users are impressed with the vibrant and sharp display of the device, noting its accurate colors and wide viewing angles.\n",
    "Dislikes: Some users feel that the display could be brighter, especially when using the device outdoors or in brightly lit environments.\n",
    "\n",
    "Mention the need for Improvement as well in detail\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04107394-713d-4d08-b3ef-118710ad7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.completions.create(\n",
    "        model=deployment_name,\n",
    "        prompt=template_prompt,\n",
    "        max_tokens=1000,\n",
    "        temperature=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4d445e-048c-4a07-a2bc-dfeb35f0a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44a9e0f4-b763-4215-870d-43d5eee50506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n\\nThe Microsoft Surface Laptop Go has received mixed reviews from consumers, with a net sentiment of 60%. While some aspects of the device have been praised, others have been criticized.\\n\\nPerformance:\\nThe performance of the Surface Laptop Go has received a positive sentiment of 70%. Many users have appreciated the device's fast processing speed and smooth performance. The 10th generation Intel Core processor has been praised for its ability to handle multiple tasks without any lag. However, some users have reported occasional crashes and slow boot-up times, which has brought down the overall sentiment.\\n\\nDesign:\\nThe design of the Surface Laptop Go has received a high sentiment of 80%. The sleek and lightweight design has been praised by users, making it easy to carry around. The device also has a premium look and feel, with its aluminum chassis and vibrant color options. However, some users have expressed disappointment with the lack of ports, as the device only has one USB-C and one USB-A port.\\n\\nDisplay:\\nThe display of the Surface Laptop Go has received a sentiment of 60%. The 12.4-inch PixelSense touchscreen has been praised for its vibrant colors and sharp resolution. The aspect ratio of 3:2 has also been appreciated by users, as it allows for more vertical screen space. However, some users have reported issues with the brightness levels, with the display being too dim in certain lighting conditions.\\n\\nOverall, the Microsoft Surface Laptop Go has received a mixed response from consumers. While the design and performance have been praised, the lack of ports and occasional performance issues have brought down the overall sentiment. However, with its affordable price point and premium features, the Surface Laptop Go is still a popular choice among consumers.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a565fe3d-ee97-4ec7-8eb8-b87c95a0bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_summary(user_imput):\n",
    "    response = client.completions.create(\n",
    "        model=deployment_name,\n",
    "        prompt=template_prompt+user_imput,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    output = response.choices[0].text\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e728167e-1c26-48e3-b549-dd4f482eb19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nOverall, the Surface Laptop Go 2 has received positive reviews from consumers, with its performance, design, and display being the standout features. However, there are some areas that could use improvement, such as battery life and storage capacity.\\n\\nAspect: Performance\\nNet Sentiment: +80%\\nLikes: Users are impressed with the performance of the Surface Laptop Go 2, noting its fast processing speed and ability to handle multiple tasks without any lag.\\nDislikes: Some users have reported occasional slowdowns or crashes, especially when running demanding applications or multitasking with multiple programs open.\\n\\nAspect: Design\\nNet Sentiment: +90%\\nLikes: Consumers love the sleek and lightweight design of the Surface Laptop Go 2, praising its portability and premium look and feel.\\nDislikes: A few users wish for more color options or a more durable build, as some have reported minor scratches or dents on the device.\\n\\nAspect: Display\\nNet Sentiment: +75%\\nLikes: Users appreciate the vibrant and clear display of the Surface Laptop Go 2, noting its accurate colors and wide viewing angles.\\nDislikes: Some users feel that the display could be brighter, especially when using the device outdoors or in brightly lit environments.\\n\\nNeed for Improvement:\\n1. Battery Life: Some users have reported that the battery life of the Surface Laptop Go 2 is not as long as they had hoped, with the device needing to be charged frequently throughout the day.\\n2. Storage Capacity: While the device offers various storage options, some users feel that the base storage capacity is not enough and wish for more storage space.\\n3. Price: A few users have mentioned that the price of the Surface Laptop Go 2 is on the higher side, especially when compared to other laptops with similar specifications. '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = get_detailed_summary(\"GIve me detailed Summary for Surface Laptop Go 2\")\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fabb37d3-c0b6-4af2-85cd-63df5c7c87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device_image(user_input):\n",
    "    print(\"User I\",user_input)\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    for i in df['Device Name']:\n",
    "        print(i)\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "            link = df[df['Device Name']==dev]['Link'][0]\n",
    "        else:\n",
    "            dev = None\n",
    "            link = None\n",
    "    return (dev, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8b1b7b8-9e1a-4b26-a777-564d2a48219f",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_devices = ['CHROMEBOOK FLEX 5',\n",
    "                'HP CHROMEBOOK X2',\n",
    "                'IDEAPAD CHROMEBOOK FLEX',\n",
    "                'MACBOOK AIR',\n",
    "                'MACBOOK AIR INTEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "77d3cbd6-9974-47c4-83dc-44032cddb462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Macbook Air': 'https://store.storeimages.cdn-apple.com/4668/as-images.apple.com/is/mba13-midnight-select-202402?wid=904&hei=840&fmt=jpeg&qlt=90&.v=1708367688034'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comp_devices = ['CHROMEBOOK FLEX 5',\n",
    "                'HP CHROMEBOOK X2',\n",
    "                'IDEAPAD CHROMEBOOK FLEX',\n",
    "                'MACBOOK AIR',\n",
    "                'MACBOOK AIR INTEL']\n",
    "\n",
    "def get_device_image(user_input):\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    dev = None\n",
    "    for i in df['Device Name']:\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "            break  # Exit the loop once a match is found\n",
    "    if dev is None:\n",
    "        return None, None  # Return None if no matching device is found\n",
    "    link = df[df['Device Name']==dev]['Link'].values[0]  # Using .values[0] to get the link\n",
    "    return dev, link\n",
    "\n",
    "device_links = {}\n",
    "for device in comp_devices:\n",
    "    dev, link = get_device_image(device)\n",
    "    if dev is not None:\n",
    "        device_links[dev] = link\n",
    "\n",
    "print(device_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "baefcd62-b036-459f-87be-006b55308684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from QuantitativeSummaryFinal import Sentiment_Score_Derivation, get_final_df,custom_color_gradient, query_detailed, get_conversational_chain_detailed, query_detailed_summary, get_conversational_chain_detailed_summary, query_quant, get_conversational_chain_quant, process_tablename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70dc0aa1-b2d8-467b-9e8d-1fa1406e6e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = \"Hp laptop 15\"\n",
    "device = device_name\n",
    "\n",
    "def get_detailed_summary(device_name):\n",
    "    if device_name:\n",
    "        data = query_quant(\"Summarize the reviews of \"+ device_name, [])\n",
    "        total_reviews = data.loc[data['ASPECT'] == 'TOTAL', 'REVIEW_COUNT'].iloc[0]\n",
    "        data['REVIEW_PERCENTAGE'] = data['REVIEW_COUNT'] / total_reviews * 100\n",
    "        dataframe_as_dict = data.to_dict(orient='records')\n",
    "        data_new = data\n",
    "        data_new = data_new.dropna(subset=['ASPECT_SENTIMENT'])\n",
    "        data_new = data_new[~data_new[\"ASPECT\"].isin([\"Generic\", \"Account\", \"Customer-Service\", \"Browser\"])]\n",
    "        vmin = data_new['ASPECT_SENTIMENT'].min()\n",
    "        vmax = data_new['ASPECT_SENTIMENT'].max()\n",
    "        styled_df = data_new.style.applymap(lambda x: custom_color_gradient(x, vmin, vmax), subset=['ASPECT_SENTIMENT'])\n",
    "        data_filtered = data_new[data_new['ASPECT'] != 'TOTAL']\n",
    "        data_sorted = data_filtered.sort_values(by='REVIEW_COUNT', ascending=False)\n",
    "        top_four_aspects = data_sorted.head(4)\n",
    "        aspects_list = top_four_aspects['ASPECT'].to_list()\n",
    "        aspects_list\n",
    "        formatted_aspects = ', '.join(f\"'{aspect}'\" for aspect in aspects_list)\n",
    "        key_df = get_final_df(aspects_list, device_name)\n",
    "        b =  key_df.to_dict(orient='records')\n",
    "        su = query_detailed_summary(\"Summarize reviews of\" + device + \"for \" +  formatted_aspects +  \"Aspects which have following \"+str(dataframe_as_dict)+ str(b) + \"Reviews: \",[])\n",
    "    return su"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "219b55fb-c52c-449b-acfe-a26e214928c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_detailed_summary(\"Surface Laptop Go\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "13132009-7e02-42de-8f19-4dfe45919f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentiment_Data = pd.read_csv('Windows_Data_116K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2355ebc-e919-43a9-ad10-e07a7b1f1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import streamlit as st\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "import pyodbc\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from pandasai import SmartDataframe\n",
    "import pandas as pd\n",
    "# from pandasai.llm import AzureOpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import base64\n",
    "import pandasql as ps\n",
    "from openai import AzureOpenAI\n",
    "from QuantitativeSummaryFinal import Sentiment_Score_Derivation, get_final_df,custom_color_gradient, query_detailed, get_conversational_chain_detailed, query_detailed_summary, get_conversational_chain_detailed_summary, query_quant, get_conversational_chain_quant, process_tablename\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"672370cd6ca440f2a0327351d4f4d2bf\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://hulk-openai.openai.azure.com/\"\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"672370cd6ca440f2a0327351d4f4d2bf\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"https://hulk-openai.openai.azure.com/\")\n",
    "    )\n",
    "    \n",
    "deployment_name='SurfaceGenAI'\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "    1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.\n",
    "    2. There is only one table with table name RCR_Sales_Data where each row has. The table has 20 columns, they are:\n",
    "        Month: Contains dates for the records\n",
    "        Country: From where the sales has happened. It contains following values: 'Turkey','India','Brazil','Germany','Philippines','France','Netherlands','Spain','United Arab Emirates','Czech Republic','Norway','Belgium','Finland','Canada','Mexico','Russia','Austria','Poland','United States','Switzerland','Italy','Colombia','Japan','Chile','Sweden','Vietnam','Saudi Arabia','South Africa','Peru','Indonesia','Taiwan','Thailand','Ireland','Korea','Hong Kong SAR','Malaysia','Denmark','New Zealand','China' and 'Australia'.\n",
    "        Geography: From which Country or Region the review was given. It contains following values: 'Unknown', 'Brazil', 'Australia', 'Canada', 'China', 'Germany','France'.\n",
    "        OEMGROUP: OEM or Manufacturer of the Device. It contains following values: 'Lenovo','Acer','Asus','HP','All Other OEMs', 'Microsoft' and 'Samsung'\n",
    "        SUBFORMFACTOR: Formfactor of the device. It contains following values: 'Ultraslim Notebook'.\n",
    "        GAMINGPRODUCTS: Flag whether Device is a gaming device or not. It contains following values: 'GAMING', 'NO GAMING' and 'N.A.'.\n",
    "        SCREEN_SIZE_INCHES: Screen Size of the Device.\n",
    "        PRICE_BRAND_USD_3: Band of the price at which the device is selling. It contains following values: '0-300', '300-500', '500-800' and '800+.\n",
    "        OS_VERSION: Operating System version intall on the device. It contains following values: 'Windows 11', 'Chrome', 'Mac OS'.\n",
    "        Operating_System_Summary: Operating System installed on the device. This is at uber level. It contains following values: 'Windows', 'Google OS', 'Apple OS'.\n",
    "        Sales_Units: Number of Devices sold for that device in a prticular month and country.\n",
    "        Sales_Value: Revenue Generated by the devices sold.\n",
    "        Series: Family of the device such as IdeaPad 1, HP Laptop 15 etc.\n",
    "        Specs_Combination: Its contains the combination of Series, Processor, RAM , Storage and Screen Size. For Example: SURFACE LAPTOP GO | Ci5 | 8 GB | 256.0 SSD | 12\" .\n",
    "        Chassis_Segment: It contains following values: 'SMB_Upper','Mainstream_Lower','SMB_Lower','Enterprise Fleet_Lower','Entry','Mainstream_Upper','Premium Mobility_Upper','Enterprise Fleet_Upper','Premium Mobility_Lower','Creation_Lower','UNDEFINED','Premium_Mobility_Upper','Enterprise Work Station','Unknown','Gaming_Musclebook','Entry_Gaming','Creation_Upper','Mainstrean_Lower'\n",
    "    3.  When Asked for Price Range you have to use ASP Column to get minimum and Maxium value. Do not consider Negative Values. Also Consider Sales Units it shouldn't be 0.\n",
    "        Exaple Query:\n",
    "            SELECT MIN(ASP) AS Lowest_Value, MAX(ASP) AS Highest_Value\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE\n",
    "            Series = 'Device Name'\n",
    "            AND ASP >= 0\n",
    "            AND Sales_Units <> 0;\n",
    "    4. Total Sales_Units Should Always be in Thousands. \n",
    "        Example Query:\n",
    "            SELECT (SUM(Sales_Units) / 1000) AS \"TOTAL SALES UNITS\"\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE\n",
    "            SERIES LIKE '%SURFACE LAPTOP GO%';\n",
    "    5. Average Selling Price (ASP): It is calculated by sum of SUM(Sales_Value)/SUM(Sales_Units)\n",
    "    6. Total Sales Units across countries or across regions is sum of sales_units for those country. It should be in thousand of million hence add \"K\" or \"M\" after the number.\n",
    "        Example to calculate sales units across country:\n",
    "            SELECT Country, (SUM(Sales_Units) / 1000) AS \"Sales_Units(In Thousands)\"\n",
    "            FROM RCR_Sales_Data\n",
    "            GROUP BY Country\n",
    "            ORDER BY Sales_Units DESC\n",
    "    7. Total Sales Units across column \"X\" or across regions is sum of sales_units for those country. It should be in thousand of million hence add \"K\" or \"M\" after the number.\n",
    "        Example to calculate sales units across country:\n",
    "            SELECT \"X\", (SUM(Sales_Units) / 1000) AS \"Sales_Units(In Thousands)\"\n",
    "            FROM RCR_Sales_Data\n",
    "            GROUP BY \"X\"\n",
    "            ORDER BY Sales_Units DESC\n",
    "    8. If asked about the highest selling Specs Combination. \n",
    "        Example Query:\n",
    "            SELECT Specs_Combination, (SUM(Sales_Units) / 1000) AS \"TOTAL SALES UNITS\"\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE SERIES LIKE '%Macbook AIR%'\n",
    "            AND SALES_UNITS <> 0\n",
    "            GROUP BY Specs_Combination\n",
    "            ORDER BY \"TOTAL SALES UNITS\" DESC\n",
    "            LIMIT 1;\n",
    "    9. If asked about similar compete devices.\n",
    "    Example Query: WITH DeviceNameASP AS (\n",
    "                SELECT\n",
    "                    'Device Name' AS Series,\n",
    "                    SUM(Sales_Value) / SUM(Sales_Units) AS ASP\n",
    "                FROM\n",
    "                    RCR_Sales_Data\n",
    "                WHERE\n",
    "                    Series LIKE '%Device Name%'\n",
    "            ),\n",
    "            CompetitorASP AS (\n",
    "                SELECT\n",
    "                    Series,\n",
    "                    SUM(Sales_Value) / SUM(Sales_Units) AS ASP\n",
    "                FROM\n",
    "                    RCR_Sales_Data\n",
    "                WHERE\n",
    "                    Operating_System_Summary IN ('Apple OS', 'Google OS')\n",
    "                GROUP BY\n",
    "                    Series\n",
    "            )\n",
    "            SELECT\n",
    "                C.Series,\n",
    "                C.ASP AS CompetitorASP\n",
    "            FROM\n",
    "                CompetitorASP C\n",
    "            JOIN\n",
    "                SurfaceLaptopGoASP S\n",
    "            ON\n",
    "                ABS(C.ASP - S.ASP) <= 200;\n",
    "    10. If asked about dates or year SUBSTR() function instead of Year() or Month()\n",
    "    11. Convert numerical outputs to float upto 2 decimal point.\n",
    "    12. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.\n",
    "    13. Always use 'LIKE' operator whenever they mention about any Country, Series. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.\n",
    "    14. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.\n",
    "    15. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.\n",
    "    16. Always use LIKE function instead of = Symbol while generating SQL Query\n",
    "    17. Important: User can ask question about any categories including Country, OEMGROUP,OS_VERSION etc etc. Hence, include the in SQL Query if someone ask it.\n",
    "    18. Important: Use the correct column names listed above. There should not be Case Sensitivity issue. \n",
    "    19. Important: The values in OPERATING_SYSTEM_SUMMARY are ('Apple OS', 'Google OS') not ('APPLE OS', 'GOOGLE OS'). So use exact values. Not everything should be capital letters.\n",
    "    20. Important: You Response should directly starts from SQL query nothing else.\"\"\"\n",
    "# Initialize an empty context\n",
    "detail_summary_template_prompt = \"\"\"Provide a detailed consumer review summary for the [device_name] with aspect-wise net sentiment. Please mention what consumers like and dislike about the device, focusing on Performance, Design, and Display.\n",
    "Overall, the [device_name] is well-received by consumers, with its performance, design, and display being the standout features. However, there are some minor criticisms regarding performance issues and display brightness.\n",
    "Aspect: Performance\n",
    "Net Sentiment: +70%\n",
    "Likes: Users appreciate the smooth performance of the device, noting its fast processing speed and ability to handle multitasking with ease.\n",
    "Dislikes: Some users have reported occasional lag or slowdowns, especially when running demanding applications or games.\n",
    "\n",
    "Aspect: Design\n",
    "Net Sentiment: +85%\n",
    "Likes: Consumers love the sleek and compact design of the device, praising its lightweight build and premium look and feel.\n",
    "Dislikes: A few users find the design too simplistic and wish for more color options or customizable features.\n",
    "\n",
    "Aspect: Display\n",
    "Net Sentiment: +75%\n",
    "Likes: Users are impressed with the vibrant and sharp display of the device, noting its accurate colors and wide viewing angles.\n",
    "Dislikes: Some users feel that the display could be brighter, especially when using the device outdoors or in brightly lit environments.\n",
    "\n",
    "Mention the need for Improvement as well in detail\"\"\"\n",
    "def generate_SQL_Query(user_question):\n",
    "    global context\n",
    "    # Append the new question to the context\n",
    "    full_prompt = context + \"\\nQuestion:\\n\" + user_question + \"\\nAnswer:\"\n",
    "    \n",
    "    # Send the query to Azure OpenAI\n",
    "    response = client.completions.create(\n",
    "        model=deployment_name,\n",
    "        prompt=full_prompt,\n",
    "        max_tokens=500,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Extract the generated SQL query\n",
    "    sql_query = response.choices[0].text.strip()\n",
    "    \n",
    "    # Update context with the latest interaction\n",
    "    context += \"\\nQuestion:\\n\" + user_question + \"\\nAnswer:\\n\" + sql_query\n",
    "    \n",
    "    return sql_query\n",
    "\n",
    "#Converting Top Operator to Limit Operator as pandasql doesn't support Top\n",
    "def convert_top_to_limit(sql):\n",
    "    tokens = sql.upper().split()\n",
    "    is_top_used = False\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == 'TOP':\n",
    "            is_top_used = True\n",
    "            if i + 1 < len(tokens) and tokens[i + 1].isdigit():\n",
    "                limit_value = tokens[i + 1]\n",
    "                # Remove TOP and insert LIMIT and value at the end\n",
    "                del tokens[i:i + 2]\n",
    "                tokens.insert(len(tokens), 'LIMIT')\n",
    "                tokens.insert(len(tokens), limit_value)\n",
    "                break  # Exit loop after successful conversion\n",
    "            else:\n",
    "                raise ValueError(\"TOP operator should be followed by a number\")\n",
    "\n",
    "    return ' '.join(tokens) if is_top_used else sql\n",
    "\n",
    "\n",
    "def process_tablename(sql, table_name):\n",
    "    x = sql.upper()\n",
    "    query = x.replace(table_name.upper(), table_name)\n",
    "    return query\n",
    "\n",
    "RCR_Sales_Data = pd.read_csv('RCR Sales Data Sample V2.csv')\n",
    "\n",
    "\n",
    "def get_sales_units(device_name):\n",
    "    question = \"Totals Sales Units for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name = data.columns[0]\n",
    "    total_sales = data[col_name][0]\n",
    "    total_sales = str(round(total_sales,2)) + \"K\"\n",
    "    return total_sales\n",
    "\n",
    "\n",
    "def get_ASP(device_name):\n",
    "    question = \"What's ASP for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name = data.columns[0]\n",
    "    asp = data[col_name][0]\n",
    "    asp = \"$\" + str(int(round(asp,0)))\n",
    "    return asp\n",
    "\n",
    "def get_highest_selling_specs(device_name):\n",
    "    question = \"What's highest selling Specs Combination for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name1 = data.columns[0]\n",
    "    col_name2 = data.columns[1]\n",
    "    specs = data[col_name1][0]\n",
    "    sales_unit = data[col_name2][0]\n",
    "    sales_unit = str(round(sales_unit,2)) + \"K\"\n",
    "    return specs,sales_unit\n",
    "\n",
    "def compete_device(device_name):\n",
    "    question = \"What are the compete device for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    SQL_Query = SQL_Query.replace('APPLE','Apple')\n",
    "    SQL_Query = SQL_Query.replace('GOOGLE','Google')\n",
    "    print(SQL_Query)\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name1 = data.columns[0]\n",
    "    devices = list(data[col_name1])\n",
    "    return devices\n",
    "    \n",
    "def get_detailed_summary(user_imput):\n",
    "    response = client.completions.create(\n",
    "        model=deployment_name,\n",
    "        prompt=detail_summary_template_prompt+user_imput,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    output = response.choices[0].text\n",
    "    return output\n",
    "\n",
    "def get_device_image(user_input):\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    for i in df['Device Name']:\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "    link = df[df['Device Name']==dev]['Link'].values[0]\n",
    "    return (dev, link)\n",
    "\n",
    "def get_comp_device_image(user_input):\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    dev = None\n",
    "    for i in df['Device Name']:\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "            break  # Exit the loop once a match is found\n",
    "    if dev is None:\n",
    "        return None, None  # Return None if no matching device is found\n",
    "    link = df[df['Device Name']==dev]['Link'].values[0]  # Using .values[0] to get the link\n",
    "    return dev, link\n",
    "    \n",
    "def get_detailed_summary(device_name):\n",
    "    if device_name:\n",
    "        data = query_quant(\"Summarize the reviews of \"+ device_name, [])\n",
    "        total_reviews = data.loc[data['ASPECT'] == 'TOTAL', 'REVIEW_COUNT'].iloc[0]\n",
    "        data['REVIEW_PERCENTAGE'] = data['REVIEW_COUNT'] / total_reviews * 100\n",
    "        dataframe_as_dict = data.to_dict(orient='records')\n",
    "        data_new = data\n",
    "        data_new = data_new.dropna(subset=['ASPECT_SENTIMENT'])\n",
    "        data_new = data_new[~data_new[\"ASPECT\"].isin([\"Generic\", \"Account\", \"Customer-Service\", \"Browser\"])]\n",
    "        vmin = data_new['ASPECT_SENTIMENT'].min()\n",
    "        vmax = data_new['ASPECT_SENTIMENT'].max()\n",
    "        styled_df = data_new.style.applymap(lambda x: custom_color_gradient(x, vmin, vmax), subset=['ASPECT_SENTIMENT'])\n",
    "        data_filtered = data_new[data_new['ASPECT'] != 'TOTAL']\n",
    "        data_sorted = data_filtered.sort_values(by='REVIEW_COUNT', ascending=False)\n",
    "        top_four_aspects = data_sorted.head(4)\n",
    "        aspects_list = top_four_aspects['ASPECT'].to_list()\n",
    "        formatted_aspects = ', '.join(f\"'{aspect}'\" for aspect in aspects_list)\n",
    "        key_df = get_final_df(aspects_list, device_name)\n",
    "        b =  key_df.to_dict(orient='records')\n",
    "        su = query_detailed_summary(\"Summarize reviews of\" + device_name + \"for \" +  formatted_aspects +  \"Aspects which have following \"+str(dataframe_as_dict)+ str(b) + \"Reviews: \",[])\n",
    "    return su\n",
    "    \n",
    "# def main():\n",
    "#     try:\n",
    "#     # Chat history state management\n",
    "#         if 'chat_history' not in st.session_state:\n",
    "#             st.session_state['chat_history'] = []\n",
    "\n",
    "#         # Create a container for logos and title with horizontal layout\n",
    "#         col1, col2, col3 = st.columns([1, 2, 1])\n",
    "      \n",
    "#         # Display logo on the left\n",
    "#         with col1:\n",
    "#             st.image(\"microsoft_logo.png\", width=50)  # Adjust width as needed\n",
    "\n",
    "#         # Display title in the center\n",
    "#         with col2:\n",
    "#             st.header(\"Consumer Reviews Synthesizer\")\n",
    "\n",
    "#         # Display logo on the right\n",
    "#         with col3:\n",
    "#             st.image(\"copilot_logo.svg\", width=50)  # Align the logo to the right\n",
    "      \n",
    "#         # User input section\n",
    "#         user_input = st.text_input(\"Enter your text:\", placeholder=\"What would you like to process?\")\n",
    "#         if st.button(\"Process\"):\n",
    "#             sales_info = \"\"\"\n",
    "#             Total Devices Sold: 695.39K<br>\n",
    "#             Average Selling Price: $1190<br>\n",
    "#             Highest Selling Specs: SURFACE PRO | Ci5 | 8 GB | 256 SSD | 13\" - 171.18K\n",
    "#             \"\"\"\n",
    "#             device_name, img_link = get_device_image(user_input)\n",
    "#             total_sales = get_sales_units(device_name)\n",
    "#             asp = get_ASP(device_name)\n",
    "#             high_specs, sale = get_highest_selling_specs(device_name)\n",
    "#             html_code = f\"\"\"\n",
    "#             <div style=\"background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1); display: flex; align-items: center;\">\n",
    "#                 <div style=\"flex: 1; text-align: center;\">\n",
    "#                     <img src=\"{img_link}\" style=\"width: 150px; display: block; margin: 0 auto;\">\n",
    "#                     <p style=\"color: black; font-size: 18px;\">{device_name}</p>\n",
    "#                 </div>\n",
    "#                 <div style=\"width: 2px; height: 150px; border-left: 2px dotted #ccc; margin: 0 20px;\"></div>\n",
    "#                 <div style=\"flex: 2; color: black; font-size: 18px;\">\n",
    "#                     <p>Total Devices Sold: <strong>{total_sales}</strong></p>\n",
    "#                     <p>Average Selling Price: <strong>{asp}</strong></p>\n",
    "#                     <p>Highest Selling Specs: <strong>{high_specs}</strong> - <strong>{sale}</strong></p>\n",
    "#                 </div>\n",
    "#             </div>\n",
    "#             \"\"\"\n",
    "#             st.markdown(html_code, unsafe_allow_html=True)\n",
    "            \n",
    "#             st.write(r\"$\\textsf{\\Large Detailed Summary}$\")\n",
    "#             summ = get_detailed_summary(user_input)\n",
    "#             st.write(summ)\n",
    "#             # st.write(r\"$\\textsf{\\Large Compete Devices}$\")\n",
    "#             comp_devices = compete_device(device_name)\n",
    "#             device_links = {}\n",
    "#             for device in comp_devices:\n",
    "#                 dev, link = get_comp_device_image(device)\n",
    "#                 if dev is not None:\n",
    "#                     device_links[dev] = link\n",
    "            \n",
    "#             col7, col8, col9 = st.columns([1, 2, 1])\n",
    "#             for com_device_name, link in device_links.items():\n",
    "#                 with col7:\n",
    "#                     st.image(link,width = 150)\n",
    "#                     if st.button(com_device_name):\n",
    "#                         col10,col11 = st.columns([2,2])\n",
    "#                         with col10:\n",
    "#                             st.image(img_link,width = 150)\n",
    "#                             st.write(device_name)\n",
    "#                         with col11:\n",
    "#                             st.image(link,width = 150)\n",
    "#                             st.write(com_device_name)\n",
    "                            \n",
    "                \n",
    "                                     \n",
    "#     except Exception as e:\n",
    "#         err = f\"An error occurred while calling the final function: {e}\"\n",
    "#         print(err)\n",
    "#         return err\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3754ac-ccf0-4009-9d56-aacca1f08425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH SURFACEPROASP AS (\n",
      "                SELECT\n",
      "                    'SURFACE PRO' AS SERIES,\n",
      "                    SUM(SALES_VALUE) / SUM(SALES_UNITS) AS ASP\n",
      "                FROM\n",
      "                    RCR_Sales_Data\n",
      "                WHERE\n",
      "                    SERIES LIKE '%SURFACE PRO%'\n",
      "            ),\n",
      "            COMPETITORASP AS (\n",
      "                SELECT\n",
      "                    SERIES,\n",
      "                    SUM(SALES_VALUE) / SUM(SALES_UNITS) AS ASP\n",
      "                FROM\n",
      "                    RCR_Sales_Data\n",
      "                WHERE\n",
      "                    OPERATING_SYSTEM_SUMMARY IN ('Apple OS', 'Google OS')\n",
      "                GROUP BY\n",
      "                    SERIES\n",
      "            )\n",
      "            SELECT\n",
      "                C.SERIES,\n",
      "                C.ASP AS COMPETITORASP\n",
      "            FROM\n",
      "                COMPETITORASP C\n",
      "            JOIN\n",
      "                SURFACEPROASP S\n",
      "            ON\n",
      "                ABS(C.ASP - S.ASP) <= 200;\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MACBOOK AIR M2', 'MACBOOK PRO 13']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compete_device(\"Microsoft Surface Pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35875a6a-d1e0-44e3-b395-a3c1fafcea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "SQL = \"\"\"WITH DeviceNameASP AS (\n",
    "    SELECT\n",
    "        'Surface Pro' AS Series,\n",
    "        SUM(Sales_Value) / SUM(Sales_Units) AS ASP,\n",
    "        Chassis_Segment,\n",
    "        SUM(Sales_Units) AS Sales_Units\n",
    "    FROM\n",
    "        RCR_Sales_Data\n",
    "    WHERE\n",
    "        Series LIKE '%Surface Pro%'\n",
    "    GROUP BY\n",
    "        Chassis_Segment\n",
    "),\n",
    "CompetitorASP AS (\n",
    "    SELECT\n",
    "        Series,\n",
    "        SUM(Sales_Value) / SUM(Sales_Units) AS ASP,\n",
    "        Chassis_Segment,\n",
    "        SUM(Sales_Units) AS Sales_Units\n",
    "    FROM\n",
    "        RCR_Sales_Data\n",
    "    WHERE\n",
    "        Operating_System_Summary IN ('Apple OS', 'Google OS','Windows OS')\n",
    "        AND SERIES NOT LIKE '%SURFACE PRO%'\n",
    "    GROUP BY\n",
    "        Series, Chassis_Segment\n",
    "),\n",
    "RankedCompetitors AS (\n",
    "    SELECT\n",
    "        C.Series,\n",
    "        C.ASP,\n",
    "        C.Chassis_Segment,\n",
    "        C.Sales_Units,\n",
    "        ROW_NUMBER() OVER (PARTITION BY C.Chassis_Segment ORDER BY C.Sales_Units DESC) AS rank\n",
    "    FROM\n",
    "        CompetitorASP C\n",
    "    JOIN\n",
    "        DeviceNameASP S\n",
    "    ON\n",
    "        ABS(C.ASP - S.ASP) <= 100\n",
    "        AND C.Chassis_Segment = S.Chassis_Segment\n",
    ")\n",
    "SELECT\n",
    "    Series,\n",
    "    ASP AS CompetitorASP,\n",
    "    Sales_Units\n",
    "FROM\n",
    "    RankedCompetitors\n",
    "WHERE\n",
    "    rank <= 4;\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e7142b2-d617-4795-a9a0-ca4c3c777ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH DEVICENAMEASP AS (\n",
      "    SELECT\n",
      "        'SURFACE PRO' AS SERIES,\n",
      "        SUM(SALES_VALUE) / SUM(SALES_UNITS) AS ASP,\n",
      "        CHASSIS_SEGMENT,\n",
      "        SUM(SALES_UNITS) AS SALES_UNITS\n",
      "    FROM\n",
      "        RCR_Sales_Data\n",
      "    WHERE\n",
      "        SERIES LIKE '%SURFACE PRO%'\n",
      "    GROUP BY\n",
      "        CHASSIS_SEGMENT\n",
      "),\n",
      "COMPETITORASP AS (\n",
      "    SELECT\n",
      "        SERIES,\n",
      "        SUM(SALES_VALUE) / SUM(SALES_UNITS) AS ASP,\n",
      "        CHASSIS_SEGMENT,\n",
      "        SUM(SALES_UNITS) AS SALES_UNITS\n",
      "    FROM\n",
      "        RCR_Sales_Data\n",
      "    WHERE\n",
      "        OPERATING_SYSTEM_SUMMARY IN ('Apple OS', 'Google OS','Windows OS')\n",
      "        AND SERIES NOT LIKE '%SURFACE PRO%'\n",
      "    GROUP BY\n",
      "        SERIES, CHASSIS_SEGMENT\n",
      "),\n",
      "RANKEDCOMPETITORS AS (\n",
      "    SELECT\n",
      "        C.SERIES,\n",
      "        C.ASP,\n",
      "        C.CHASSIS_SEGMENT,\n",
      "        C.SALES_UNITS,\n",
      "        ROW_NUMBER() OVER (PARTITION BY C.CHASSIS_SEGMENT ORDER BY C.SALES_UNITS DESC) AS RANK\n",
      "    FROM\n",
      "        COMPETITORASP C\n",
      "    JOIN\n",
      "        DEVICENAMEASP S\n",
      "    ON\n",
      "        ABS(C.ASP - S.ASP) <= 100\n",
      "        AND C.CHASSIS_SEGMENT = S.CHASSIS_SEGMENT\n",
      ")\n",
      "SELECT\n",
      "    SERIES,\n",
      "    ASP AS COMPETITORASP,\n",
      "    SALES_UNITS\n",
      "FROM\n",
      "    RANKEDCOMPETITORS\n",
      "WHERE\n",
      "    RANK <= 4;\n"
     ]
    }
   ],
   "source": [
    "SQL_Query = convert_top_to_limit(SQL)\n",
    "SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "SQL_Query = SQL_Query.replace('APPLE','Apple')\n",
    "SQL_Query = SQL_Query.replace('GOOGLE','Google')\n",
    "SQL_Query = SQL_Query.replace('WINDOWS','Windows')\n",
    "print(SQL_Query)\n",
    "data = ps.sqldf(SQL_Query, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3615758-51b7-4ac4-b1ff-5848c6fe233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RCR_Sales_Data = pd.read_csv('RCR Sales Data Sample V3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59c07535-c999-4700-bed2-6479892298d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIES</th>\n",
       "      <th>COMPETITORASP</th>\n",
       "      <th>SALES_UNITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MACBOOK AIR M2</td>\n",
       "      <td>1265.175216</td>\n",
       "      <td>4633171.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SURFACE LAPTOP</td>\n",
       "      <td>1090.244301</td>\n",
       "      <td>412640.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENVY 17</td>\n",
       "      <td>1123.894939</td>\n",
       "      <td>93183.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPECTRE X360</td>\n",
       "      <td>1156.078007</td>\n",
       "      <td>66308.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SERIES  COMPETITORASP  SALES_UNITS\n",
       "0  MACBOOK AIR M2    1265.175216   4633171.84\n",
       "1  SURFACE LAPTOP    1090.244301    412640.10\n",
       "2         ENVY 17    1123.894939     93183.19\n",
       "3    SPECTRE X360    1156.078007     66308.91"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81e5ccad-fc96-4f08-ae39-22d7a2679eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIES</th>\n",
       "      <th>COMPETITORASP</th>\n",
       "      <th>SALES_UNITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MACBOOK AIR M2</td>\n",
       "      <td>1265.175216</td>\n",
       "      <td>4633171.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SURFACE LAPTOP</td>\n",
       "      <td>1090.244301</td>\n",
       "      <td>412640.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENVY 17</td>\n",
       "      <td>1123.894939</td>\n",
       "      <td>93183.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPECTRE X360</td>\n",
       "      <td>1156.078007</td>\n",
       "      <td>66308.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SERIES  COMPETITORASP  SALES_UNITS\n",
       "0  MACBOOK AIR M2    1265.175216   4633171.84\n",
       "1  SURFACE LAPTOP    1090.244301    412640.10\n",
       "2         ENVY 17    1123.894939     93183.19\n",
       "3    SPECTRE X360    1156.078007     66308.91"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6e19b02-99f2-4a0e-bba2-63becbe788f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compete_device(device_name):\n",
    "    # question = \"What are the compete device for \" + device_name\n",
    "    # a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(SQL)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    SQL_Query = SQL_Query.replace('APPLE','Apple')\n",
    "    SQL_Query = SQL_Query.replace('GOOGLE','Google')\n",
    "    SQL_Query = SQL_Query.replace('WINDOWS','Windows')\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99616848-5605-4231-aa31-280a516bc630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = compete_device(\"Microsoft Surface Pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e9c324a-aee8-4446-acff-38e926499312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIES</th>\n",
       "      <th>COMPETITORASP</th>\n",
       "      <th>SALES_UNITS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MACBOOK AIR M2</td>\n",
       "      <td>1265.175216</td>\n",
       "      <td>4633171.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SURFACE LAPTOP</td>\n",
       "      <td>1090.244301</td>\n",
       "      <td>412640.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENVY 17</td>\n",
       "      <td>1123.894939</td>\n",
       "      <td>93183.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SPECTRE X360</td>\n",
       "      <td>1156.078007</td>\n",
       "      <td>66308.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SERIES  COMPETITORASP  SALES_UNITS\n",
       "0  MACBOOK AIR M2    1265.175216   4633171.84\n",
       "1  SURFACE LAPTOP    1090.244301    412640.10\n",
       "2         ENVY 17    1123.894939     93183.19\n",
       "3    SPECTRE X360    1156.078007     66308.91"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "edc1e43b-d6f8-41ad-9ea2-2965ab90f456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comp_device_details(user_input, df1):\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    dev = None\n",
    "    for i in df['Device Name']:\n",
    "        print(i)\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "            break  # Exit the loop once a match is found\n",
    "    \n",
    "    if dev is None:\n",
    "        return None, None, None, None  # Return None if no matching device is found\n",
    "    \n",
    "    link = df[df['Device Name'] == dev]['Link'].values[0]  # Using .values[0] to get the link\n",
    "    df1['SERIES'] = df1['SERIES'].str.upper()\n",
    "    dev = dev.upper()\n",
    "    sales_data = df1[df1['SERIES'] == dev]\n",
    "    if sales_data.empty:\n",
    "        return dev, link, None, None  # Return dev and link, but None for sales and ASP if no matching SERIES is found\n",
    "    \n",
    "    sales = str(round(float(sales_data['SALES_UNITS'].values[0]) / 1000, 2)) + \"K\"\n",
    "    ASP = \"$\" + str(int(sales_data['COMPETITORASP'].values[0]))\n",
    "    \n",
    "    return dev, link, sales, ASP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1ce2515a-c81d-4ab9-a8cc-36cdb47d13e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_sentiment(device_name):\n",
    "    a = query_quant(device_name,[])\n",
    "    try:\n",
    "        Net_Sentiment = float(a[a['ASPECT']=='TOTAL']['ASPECT_SENTIMENT'].values[0])\n",
    "    except:\n",
    "        Net_Sentiment = None\n",
    "    return Net_Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11e9be75-f8ab-495a-ab7a-cb86835990f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ASPECT ASPECT_SENTIMENT REVIEW_COUNT\n",
      "0  TOTAL             None         None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m get_net_sentiment(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMacbook Air M2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m a\n",
      "Cell \u001b[1;32mIn[67], line 4\u001b[0m, in \u001b[0;36mget_net_sentiment\u001b[1;34m(device_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m query_quant(device_name,[])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m----> 4\u001b[0m Net_Sentiment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(a[a[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASPECT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTOTAL\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mASPECT_SENTIMENT\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Net_Sentiment\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "a = get_net_sentiment('Macbook Air M2')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0973ce87-2194-40d6-b16c-8d2475355c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft Surface Pro\n",
      "Microsoft Surface Book 3 \n",
      "Acer Aspire\n",
      "Microsoft Surface Go 3 \n",
      "Mackbook Pro 13\n",
      "Microsoft Surface Laptop Go \n",
      "Microsoft Surface Pro 7 \n",
      "hp pavilion 15\n",
      "dell inspiron 15\n",
      "lenovo ideapad slim 3\n",
      "Microsoft Surface Go 2\n",
      "Microsoft Surface Laptop 3\n",
      "Microsoft Surface Laptop 4\n",
      "Microsoft Surface Laptop 5\n",
      "Microsoft Surface Laptop Studio\n",
      "Microsoft Surface Pro 7 \n",
      "Microsoft Surface Pro 8\n",
      "Microsoft Surface Pro 9\n",
      "Microsoft Surface Studio 2\n",
      "Macbook Air M2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('MACBOOK AIR M2',\n",
       " 'https://store.storeimages.cdn-apple.com/4668/as-images.apple.com/is/mba13-midnight-select-202402?wid=904&hei=840&fmt=jpeg&qlt=90&.v=1708367688034',\n",
       " '4633.17K',\n",
       " '$1265')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comp_device_details(\"macbook Air M2\", df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27305fa-b264-4145-9105-77bb3dbf3271",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_devices = compete_device(device_name)\n",
    "device_links = {}\n",
    "for device in comp_devices:\n",
    "    dev, link = get_comp_device_details(device)\n",
    "    if dev is not None:\n",
    "        device_links[dev] = link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
