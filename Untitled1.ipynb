{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66cdc06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-26 17:01:50.591 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2024-05-26 17:01:51.202 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Anaconda3\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#Import Required Libraries\n",
    "import streamlit as st\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "# from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "import pyodbc\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from pandasai import SmartDataframe\n",
    "import pandas as pd\n",
    "# from pandasai.llm import AzureOpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import base64\n",
    "import pandasql as ps\n",
    "from openai import AzureOpenAI\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import io\n",
    "from QuantitativeSummaryFinal import Sentiment_Score_Derivation, get_final_df,custom_color_gradient, query_detailed, get_conversational_chain_detailed, query_detailed_summary, get_conversational_chain_detailed_summary, query_quant, get_conversational_chain_quant, process_tablename\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"672370cd6ca440f2a0327351d4f4d2bf\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://hulk-openai.openai.azure.com/\"\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_key=os.getenv(\"672370cd6ca440f2a0327351d4f4d2bf\"),  \n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint = os.getenv(\"https://hulk-openai.openai.azure.com/\")\n",
    "    )\n",
    "    \n",
    "deployment_name='SurfaceGenAI'\n",
    "\n",
    "\n",
    "context = \"\"\"\n",
    "    1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.\n",
    "    2. There is only one table with table name RCR_Sales_Data where each row has. The table has 20 columns, they are:\n",
    "        Month: Contains dates for the records\n",
    "        Country: From where the sales has happened. It contains following values: 'Turkey','India','Brazil','Germany','Philippines','France','Netherlands','Spain','United Arab Emirates','Czech Republic','Norway','Belgium','Finland','Canada','Mexico','Russia','Austria','Poland','United States','Switzerland','Italy','Colombia','Japan','Chile','Sweden','Vietnam','Saudi Arabia','South Africa','Peru','Indonesia','Taiwan','Thailand','Ireland','Korea','Hong Kong SAR','Malaysia','Denmark','New Zealand','China' and 'Australia'.\n",
    "        Geography: From which Country or Region the review was given. It contains following values: 'Unknown', 'Brazil', 'Australia', 'Canada', 'China', 'Germany','France'.\n",
    "        OEMGROUP: OEM or Manufacturer of the Device. It contains following values: 'Lenovo','Acer','Asus','HP','All Other OEMs', 'Microsoft' and 'Samsung'\n",
    "        SUBFORMFACTOR: Formfactor of the device. It contains following values: 'Ultraslim Notebook'.\n",
    "        GAMINGPRODUCTS: Flag whether Device is a gaming device or not. It contains following values: 'GAMING', 'NO GAMING' and 'N.A.'.\n",
    "        SCREEN_SIZE_INCHES: Screen Size of the Device.\n",
    "        PRICE_BRAND_USD_3: Band of the price at which the device is selling. It contains following values: '0-300', '300-500', '500-800' and '800+.\n",
    "        OS_VERSION: Operating System version intall on the device. It contains following values: 'Windows 11', 'Chrome', 'Mac OS'.\n",
    "        Operating_System_Summary: Operating System installed on the device. This is at uber level. It contains following values: 'Windows', 'Google OS', 'Apple OS'.\n",
    "        Sales_Units: Number of Devices sold for that device in a prticular month and country.\n",
    "        Sales_Value: Revenue Generated by the devices sold.\n",
    "        Series: Family of the device such as IdeaPad 1, HP Laptop 15 etc.\n",
    "        Specs_Combination: Its contains the combination of Series, Processor, RAM , Storage and Screen Size. For Example: SURFACE LAPTOP GO | Ci5 | 8 GB | 256.0 SSD | 12\" .\n",
    "        Chassis Segment: It contains following values: 'SMB_Upper','Mainstream_Lower','SMB_Lower','Enterprise Fleet_Lower','Entry','Mainstream_Upper','Premium Mobility_Upper','Enterprise Fleet_Upper','Premium Mobility_Lower','Creation_Lower','UNDEFINED','Premium_Mobility_Upper','Enterprise Work Station','Unknown','Gaming_Musclebook','Entry_Gaming','Creation_Upper','Mainstrean_Lower'\n",
    "        \n",
    "    3.  When Asked for Price Range you have to use ASP Column to get minimum and Maxium value. Do not consider Negative Values. Also Consider Sales Units it shouldn't be 0.\n",
    "        Exaple Query:\n",
    "            SELECT MIN(ASP) AS Lowest_Value, MAX(ASP) AS Highest_Value\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE\n",
    "            Series = 'Device Name'\n",
    "            AND ASP >= 0\n",
    "            AND Sales_Units <> 0;\n",
    "    4. Total Sales_Units Should Always be in Thousands. \n",
    "        Example Query:\n",
    "            SELECT (SUM(Sales_Units) / 1000) AS \"TOTAL SALES UNITS\"\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE\n",
    "            SERIES LIKE '%SURFACE LAPTOP GO%';\n",
    "    5. Average Selling Price (ASP): It is calculated by sum of SUM(Sales_Value)/SUM(Sales_Units)\n",
    "    6. Total Sales Units across countries or across regions is sum of sales_units for those country. It should be in thousand of million hence add \"K\" or \"M\" after the number.\n",
    "        Example to calculate sales units across country:\n",
    "            SELECT Country, (SUM(Sales_Units) / 1000) AS \"Sales_Units(In Thousands)\"\n",
    "            FROM RCR_Sales_Data\n",
    "            GROUP BY Country\n",
    "            ORDER BY Sales_Units DESC\n",
    "    7. Total Sales Units across column \"X\" or across regions is sum of sales_units for those country. It should be in thousand of million hence add \"K\" or \"M\" after the number.\n",
    "        Example to calculate sales units across country:\n",
    "            SELECT \"X\", (SUM(Sales_Units) / 1000) AS \"Sales_Units(In Thousands)\"\n",
    "            FROM RCR_Sales_Data\n",
    "            GROUP BY \"X\"\n",
    "            ORDER BY Sales_Units DESC\n",
    "    8. If asked about the highest selling Specs Combination. \n",
    "        Example Query:\n",
    "            SELECT Specs_Combination, (SUM(Sales_Units) / 1000) AS \"TOTAL SALES UNITS\"\n",
    "            FROM RCR_Sales_Data\n",
    "            WHERE SERIES LIKE '%Macbook AIR%'\n",
    "            AND SALES_UNITS <> 0\n",
    "            GROUP BY Specs_Combination\n",
    "            ORDER BY \"TOTAL SALES UNITS\" DESC\n",
    "            LIMIT 1;\n",
    "    9. If asked about similar compete devices.\n",
    "    Example Query:\n",
    "            SQL = WITH DeviceNameASP AS (\n",
    "                    SELECT\n",
    "                        'Device Name' AS Series,\n",
    "                        SUM(Sales_Value) / SUM(Sales_Units) AS ASP,\n",
    "                        Chassis_Segment,\n",
    "                        SUM(Sales_Units) AS Sales_Units\n",
    "                    FROM\n",
    "                        RCR_Sales_Data\n",
    "                    WHERE\n",
    "                        Series LIKE '%Device Name%'\n",
    "                    GROUP BY\n",
    "                        Chassis_Segment\n",
    "                ),\n",
    "                CompetitorASP AS (\n",
    "                    SELECT\n",
    "                        Series,\n",
    "                        SUM(Sales_Value) / SUM(Sales_Units) AS ASP,\n",
    "                        Chassis_Segment,\n",
    "                        SUM(Sales_Units) AS Sales_Units\n",
    "                    FROM\n",
    "                        RCR_Sales_Data\n",
    "                    WHERE\n",
    "                        Operating_System_Summary IN ('Apple OS', 'Google OS','Windows OS')\n",
    "                        AND SERIES NOT LIKE '%Device Name%'\n",
    "                    GROUP BY\n",
    "                        Series, Chassis_Segment\n",
    "                ),\n",
    "                RankedCompetitors AS (\n",
    "                    SELECT\n",
    "                        C.Series,\n",
    "                        C.ASP,\n",
    "                        C.Chassis_Segment,\n",
    "                        C.Sales_Units,\n",
    "                        ROW_NUMBER() OVER (PARTITION BY C.Chassis_Segment ORDER BY C.Sales_Units DESC) AS rank\n",
    "                    FROM\n",
    "                        CompetitorASP C\n",
    "                    JOIN\n",
    "                        DeviceNameASP S\n",
    "                    ON\n",
    "                        ABS(C.ASP - S.ASP) <= 100\n",
    "                        AND C.Chassis_Segment = S.Chassis_Segment\n",
    "                )\n",
    "                SELECT\n",
    "                    Series,\n",
    "                    ASP AS CompetitorASP,\n",
    "                    Sales_Units\n",
    "                FROM\n",
    "                    RankedCompetitors\n",
    "                WHERE\n",
    "                    rank <= 4;\n",
    "\n",
    "    10. If asked about dates or year SUBSTR() function instead of Year() or Month()\n",
    "    11. Convert numerical outputs to float upto 2 decimal point.\n",
    "    12. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.\n",
    "    13. Always use 'LIKE' operator whenever they mention about any Country, Series. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.\n",
    "    14. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.\n",
    "    15. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.\n",
    "    16. Always use LIKE function instead of = Symbol while generating SQL Query\n",
    "    17. Important: User can ask question about any categories including Country, OEMGROUP,OS_VERSION etc etc. Hence, include the in SQL Query if someone ask it.\n",
    "    18. Important: Use the correct column names listed above. There should not be Case Sensitivity issue. \n",
    "    19. Important: The values in OPERATING_SYSTEM_SUMMARY are ('Apple OS', 'Google OS') not ('APPLE OS', 'GOOGLE OS'). So use exact values. Not everything should be capital letters.\n",
    "    20. Important: You Response should directly starts from SQL query nothing else.\"\"\"\n",
    "# Initialize an empty context\n",
    "\n",
    "def generate_SQL_Query(user_question):\n",
    "    global context\n",
    "    # Append the new question to the context\n",
    "    full_prompt = context + \"\\nQuestion:\\n\" + user_question + \"\\nAnswer:\"\n",
    "    \n",
    "    # Send the query to Azure OpenAI\n",
    "    response = client.completions.create(\n",
    "        model=deployment_name,\n",
    "        prompt=full_prompt,\n",
    "        max_tokens=500,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Extract the generated SQL query\n",
    "    sql_query = response.choices[0].text.strip()\n",
    "    \n",
    "    # Update context with the latest interaction\n",
    "    context += \"\\nQuestion:\\n\" + user_question + \"\\nAnswer:\\n\" + sql_query\n",
    "    \n",
    "    return sql_query\n",
    "\n",
    "def get_conversational_chain_summary():\n",
    "    prompt_template = \"\"\"\n",
    "    Your task is to analyze the reviews of Windows products and generate a summary of the pros and cons for each product based on the provided dataset.Provide an overall summary. focus only on listing the pros and cons. \n",
    "    Use the format below for your response:\n",
    "\n",
    "    Pros and Cons of [Product Name]:\n",
    "\n",
    "    Pros:\n",
    "\n",
    "    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]\n",
    "    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]\n",
    "    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]\n",
    "    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]\n",
    "    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]\n",
    "    Cons:\n",
    "\n",
    "    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]\n",
    "    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]\n",
    "    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]\n",
    "    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]\n",
    "    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]\n",
    "    \n",
    "    [Overall Summary]: [Brief summary of overall feedback regarding all aspect.]\n",
    "    The dataset includes the following columns:\n",
    "\n",
    "    Review: Review of the Windows product.\n",
    "    Data_Source: Source of the review, containing different retailers.\n",
    "    Geography: Country or region of the review.\n",
    "    Title: Title of the review.\n",
    "    Review_Date: Date the review was posted.\n",
    "    Product: Product the review corresponds to, with values: \"Windows 11 (Preinstall)\", \"Windows 10\".\n",
    "    Product_Family: Version or type of the corresponding product.\n",
    "    Sentiment: Sentiment of the review, with values: 'Positive', 'Neutral', 'Negative'.\n",
    "    Aspect: Aspect or feature of the product discussed in the review, with values: \"Audio-Microphone\", \"Software\", \"Performance\", \"Storage/Memory\", \"Keyboard\", \"Browser\", \"Connectivity\", \"Hardware\", \"Display\", \"Graphics\", \"Battery\", \"Gaming\", \"Design\", \"Ports\", \"Price\", \"Camera\", \"Customer-Service\", \"Touchpad\", \"Account\", \"Generic\".\n",
    "    Keywords: Keywords mentioned in the review.\n",
    "    Review_Count: Will be 1 for each review or row.\n",
    "    Sentiment_Score: Will be 1, 0, or -1 based on the sentiment.\n",
    "    Please ensure that the response is based on the analysis of the provided dataset, summarizing both positive and negative aspects of each product. \n",
    "     \n",
    "        \n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    " \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    model = AzureChatOpenAI(\n",
    "    azure_deployment=\"Thruxton_R\",\n",
    "    api_version='2023-12-01-preview',temperature = 0)\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "    return chain\n",
    "\n",
    "def query_to_embedding_summarize(user_question, txt_file_path):\n",
    "    text = get_txt_text(txt_file_path)\n",
    "    chunks = get_text_chunks(text)\n",
    "    get_vector_store(chunks)\n",
    "    embeddings = AzureOpenAIEmbeddings(azure_deployment=\"Mv_Agusta\")\n",
    "    \n",
    "    # Load the vector store with the embeddings model\n",
    "    new_db = FAISS.load_local(\"faiss-index\", embeddings, allow_dangerous_deserialization=True)\n",
    "    docs = new_db.similarity_search(user_question)\n",
    "    chain = get_conversational_chain_summary()\n",
    "    response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
    "    return response['output_text']\n",
    "\n",
    "#Converting Top Operator to Limit Operator as pandasql doesn't support Top\n",
    "def convert_top_to_limit(sql):\n",
    "    tokens = sql.upper().split()\n",
    "    is_top_used = False\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token == 'TOP':\n",
    "            is_top_used = True\n",
    "            if i + 1 < len(tokens) and tokens[i + 1].isdigit():\n",
    "                limit_value = tokens[i + 1]\n",
    "                # Remove TOP and insert LIMIT and value at the end\n",
    "                del tokens[i:i + 2]\n",
    "                tokens.insert(len(tokens), 'LIMIT')\n",
    "                tokens.insert(len(tokens), limit_value)\n",
    "                break  # Exit loop after successful conversion\n",
    "            else:\n",
    "                raise ValueError(\"TOP operator should be followed by a number\")\n",
    "\n",
    "    return ' '.join(tokens) if is_top_used else sql\n",
    "\n",
    "\n",
    "def process_tablename(sql, table_name):\n",
    "    x = sql.upper()\n",
    "    query = x.replace(table_name.upper(), table_name)\n",
    "    return query\n",
    "\n",
    "RCR_Sales_Data = pd.read_csv('RCR Sales Data Sample V3.csv')\n",
    "\n",
    "\n",
    "def get_sales_units(device_name):\n",
    "    question = \"Totals Sales Units for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name = data.columns[0]\n",
    "    total_sales = data[col_name][0]\n",
    "    total_sales = str(round(total_sales,2)) + \"K\"\n",
    "    return total_sales\n",
    "\n",
    "\n",
    "def get_ASP(device_name):\n",
    "    question = \"What's ASP for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name = data.columns[0]\n",
    "    asp = data[col_name][0]\n",
    "    asp = \"$\" + str(int(round(asp,0)))\n",
    "    return asp\n",
    "\n",
    "def get_highest_selling_specs(device_name):\n",
    "    question = \"What's highest selling Specs Combination for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    col_name1 = data.columns[0]\n",
    "    col_name2 = data.columns[1]\n",
    "    specs = data[col_name1][0]\n",
    "    sales_unit = data[col_name2][0]\n",
    "    sales_unit = str(round(sales_unit,2)) + \"K\"\n",
    "    return specs,sales_unit\n",
    "\n",
    "def compete_device(device_name):\n",
    "    question = \"What are the compete device for \" + device_name\n",
    "    a = generate_SQL_Query(question)\n",
    "    SQL_Query = convert_top_to_limit(a)\n",
    "    SQL_Query = process_tablename(SQL_Query,\"RCR_Sales_Data\")\n",
    "    SQL_Query = SQL_Query.replace('APPLE','Apple')\n",
    "    SQL_Query = SQL_Query.replace('GOOGLE','Google')\n",
    "    SQL_Query = SQL_Query.replace('WINDOWS','Windows')\n",
    "    data = ps.sqldf(SQL_Query, globals())\n",
    "    return data\n",
    "    \n",
    "def get_detailed_summary(user_imput):\n",
    "    response = client.completions.create(\n",
    "        model=deployment_name,\n",
    "        prompt=detail_summary_template_prompt+user_imput,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.2\n",
    "    )\n",
    "    output = response.choices[0].text\n",
    "    return output\n",
    "\n",
    "def get_device_image(user_input):\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    for i in df['Device Name']:\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "    link = df[df['Device Name']==dev]['Link'].values[0]\n",
    "    return (dev, link)\n",
    "\n",
    "def get_comp_device_image(user_input):\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    dev = None\n",
    "    for i in df['Device Name']:\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "            break  # Exit the loop once a match is found\n",
    "    if dev is None:\n",
    "        return None, None  # Return None if no matching device is found\n",
    "    link = df[df['Device Name']==dev]['Link'].values[0]  # Using .values[0] to get the link\n",
    "    return dev, link\n",
    "    \n",
    "def get_net_sentiment(device_name):\n",
    "    a = query_quant(device_name,[])\n",
    "    try:\n",
    "        Net_Sentiment = float(a[a['ASPECT']=='TOTAL']['ASPECT_SENTIMENT'].values[0])\n",
    "        aspects = a[\"ASPECT\"].unique()\n",
    "        if \"Performance\" in aspects:\n",
    "            Performance_Sentiment = float(a[a['ASPECT']=='Performance']['ASPECT_SENTIMENT'].values[0])\n",
    "        else:\n",
    "            Performance_Sentiment = 0\n",
    "        \n",
    "        if \"Design\" in aspects:\n",
    "            Design_Sentiment = float(a[a['ASPECT']=='Design']['ASPECT_SENTIMENT'].values[0])\n",
    "        else:\n",
    "            Design_Sentiment = 0\n",
    "        \n",
    "        if \"Display\" in aspects:\n",
    "            Display_Sentiment = float(a[a['ASPECT']=='Display']['ASPECT_SENTIMENT'].values[0])\n",
    "        else:\n",
    "            Display_Sentiment = 0\n",
    "        \n",
    "        if \"Battery\" in aspects:\n",
    "            Battery_Sentiment = float(a[a['ASPECT']=='Battery']['ASPECT_SENTIMENT'].values[0])\n",
    "        else:\n",
    "            Battery_Sentiment = 0\n",
    "        \n",
    "        if \"Price\" in aspects:\n",
    "            Price_Sentiment = float(a[a['ASPECT']=='Price']['ASPECT_SENTIMENT'].values[0])\n",
    "        else:\n",
    "            Price_Sentiment = 0\n",
    "        \n",
    "        if \"Software\" in aspects:\n",
    "            Software_Sentiment = float(a[a['ASPECT']=='Software']['ASPECT_SENTIMENT'].values[0])\n",
    "        else:\n",
    "            Software_Sentiment = 0\n",
    "            \n",
    "        aspect_sentiment = list((Performance_Sentiment, Design_Sentiment, Display_Sentiment, Battery_Sentiment, Price_Sentiment, Software_Sentiment))\n",
    "                                 \n",
    "    except:\n",
    "        Net_Sentiment = None\n",
    "        aspect_sentiment = None                     \n",
    "    return Net_Sentiment, aspect_sentiment\n",
    "\n",
    "\n",
    "\n",
    "def get_comp_device_details(user_input, df1):\n",
    "    df = pd.read_csv('Device Images.csv')\n",
    "    dev = None\n",
    "    for i in df['Device Name']:\n",
    "        if str.lower(i) in str.lower(user_input):\n",
    "            dev = i\n",
    "            break  # Exit the loop once a match is found\n",
    "    \n",
    "    if dev is None:\n",
    "        return None, None, None, None, None  # Return None if no matching device is found\n",
    "    \n",
    "    link = df[df['Device Name'] == dev]['Link'].values[0]  # Using .values[0] to get the link\n",
    "    df1['SERIES'] = df1['SERIES'].str.upper()\n",
    "    dev = dev.upper()\n",
    "    sales_data = df1[df1['SERIES'] == dev]\n",
    "    if sales_data.empty:\n",
    "        return dev, link, None, None, None  # Return dev and link, but None for sales and ASP if no matching SERIES is found\n",
    "    \n",
    "    try:\n",
    "        sales = str(round(float(sales_data['SALES_UNITS'].values[0]) / 1000, 2)) + \"K\"\n",
    "    except:\n",
    "        sales = \"NA\"\n",
    "    try:\n",
    "        ASP = \"$\" + str(int(sales_data['COMPETITORASP'].values[0]))\n",
    "    except:\n",
    "        ASP = \"NA\"\n",
    "    net_sentiment,aspect_sentiment = get_net_sentiment(dev)\n",
    "    return dev, link, sales, ASP, net_sentiment\n",
    "    \n",
    "def get_star_rating_html(net_sentiment):\n",
    "    try:\n",
    "    # Normalize net sentiment from -100 to 100 to 0 to 10 for star ratings\n",
    "        normalized_rating = (net_sentiment + 100) / 40\n",
    "    \n",
    "        # Determine the number of full and half stars\n",
    "        full_stars = int(normalized_rating)\n",
    "        half_star = 1 if normalized_rating - full_stars >= 0.5 else 0\n",
    "    \n",
    "        # Generate the HTML for the stars\n",
    "        star_html = '<span style=\"color: gold;\">'\n",
    "        star_html += '★' * full_stars\n",
    "        star_html += '½' * half_star\n",
    "        star_html += '☆' * (5 - full_stars - half_star)\n",
    "        star_html += '</span>'\n",
    "        return star_html\n",
    "    except:\n",
    "        return \"NA\"\n",
    "        \n",
    "def get_detailed_summary(device_name):\n",
    "    if device_name:\n",
    "        data = query_quant(\"Summarize the reviews of \"+ device_name, [])\n",
    "        total_reviews = data.loc[data['ASPECT'] == 'TOTAL', 'REVIEW_COUNT'].iloc[0]\n",
    "        data['REVIEW_PERCENTAGE'] = data['REVIEW_COUNT'] / total_reviews * 100\n",
    "        dataframe_as_dict = data.to_dict(orient='records')\n",
    "        data_new = data\n",
    "        data_new = data_new.dropna(subset=['ASPECT_SENTIMENT'])\n",
    "        data_new = data_new[~data_new[\"ASPECT\"].isin([\"Generic\", \"Account\", \"Customer-Service\", \"Browser\"])]\n",
    "        vmin = data_new['ASPECT_SENTIMENT'].min()\n",
    "        vmax = data_new['ASPECT_SENTIMENT'].max()\n",
    "        styled_df = data_new.style.applymap(lambda x: custom_color_gradient(x, vmin, vmax), subset=['ASPECT_SENTIMENT'])\n",
    "        data_filtered = data_new[data_new['ASPECT'] != 'TOTAL']\n",
    "        data_sorted = data_filtered.sort_values(by='REVIEW_COUNT', ascending=False)\n",
    "        top_four_aspects = data_sorted.head(4)\n",
    "        aspects_list = top_four_aspects['ASPECT'].to_list()\n",
    "        formatted_aspects = ', '.join(f\"'{aspect}'\" for aspect in aspects_list)\n",
    "        key_df = get_final_df(aspects_list, device_name)\n",
    "        b =  key_df.to_dict(orient='records')\n",
    "        su = query_detailed_summary(\"Summarize reviews of\" + device_name + \"for \" +  formatted_aspects +  \"Aspects which have following \"+str(dataframe_as_dict)+ str(b) + \"Reviews: \",[])\n",
    "    return su\n",
    "\n",
    "def generate_device_details(device_input):\n",
    "    device_name, img_link = get_device_image(device_input)\n",
    "    net_Sentiment,aspect_sentiment = get_net_sentiment(device_name)\n",
    "    total_sales = get_sales_units(device_name)\n",
    "    asp = get_ASP(device_name)\n",
    "    high_specs, sale = get_highest_selling_specs(device_name)\n",
    "    star_rating_html = get_star_rating_html(net_Sentiment)\n",
    "    comp_devices = compete_device(device_name)\n",
    "    return device_name, img_link, net_Sentiment, aspect_sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices\n",
    "\n",
    "def load_and_resize_image(url, new_height):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        aspect_ratio = img.width / img.height\n",
    "        new_width = int(aspect_ratio * new_height)\n",
    "        resized_img = img.resize((new_width, new_height))\n",
    "        return resized_img  # Return the resized PIL image object\n",
    "    except Exception as e:\n",
    "        st.write(\"Image not available for this product.\")\n",
    "        st.write(f\"Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "def get_txt_text(txt_file_path):\n",
    "    with io.open(txt_file_path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "def get_vector_store(chunks):\n",
    "    embeddings = AzureOpenAIEmbeddings(azure_deployment=\"Mv_Agusta\")\n",
    "    vector_store = FAISS.from_texts(chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss-index\")\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def main():\n",
    "    try:\n",
    "    # Chat history state management\n",
    "        if 'chat_history' not in st.session_state:\n",
    "            st.session_state['chat_history'] = []\n",
    "        if 'selected_device_comparison' not in st.session_state:\n",
    "            st.session_state['selected_device_comparison'] = None\n",
    "\n",
    "        # Create a container for logos and title with horizontal layout\n",
    "        col1, col2, col3 = st.columns([1, 2, 1])\n",
    "      \n",
    "        # Display logo on the left\n",
    "        with col1:\n",
    "            st.image(\"microsoft_logo.png\", width=50)  # Adjust width as needed\n",
    "\n",
    "        # Display title in the center\n",
    "        with col2:\n",
    "            st.header(\"Consumer Reviews Synthesizer\")\n",
    "\n",
    "        # Display logo on the right\n",
    "        with col3:\n",
    "            st.image(\"copilot_logo.svg\", width=50)  # Align the logo to the right\n",
    "      \n",
    "        # User input section\n",
    "        user_input = st.text_input(\"Enter your text:\", placeholder=\"What would you like to process?\")\n",
    "        if user_input:\n",
    "            inp = user_input\n",
    "            if not st.session_state['chat_history']:\n",
    "                device_name, img_link, net_Sentiment, aspect_sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices = generate_device_details(inp)\n",
    "#                 summ = get_detailed_summary(inp)\n",
    "                summ = \"Summary Placeholder\"\n",
    "                st.session_state['chat_history'].append((inp, device_name, img_link, net_Sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices, summ, aspect_sentiment))\n",
    "            elif inp != st.session_state['chat_history'][-1][0]:\n",
    "                device_name, img_link, net_Sentiment, aspect_sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices = generate_device_details(inp)\n",
    "#                 summ = get_detailed_summary(inp)\n",
    "                summ = \"Summary Placeholder\"\n",
    "                st.session_state['chat_history'].append((inp, device_name, img_link, net_Sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices, summ, aspect_sentiment))\n",
    "            else:\n",
    "                device_name = st.session_state['chat_history'][-1][1]\n",
    "                img_link = st.session_state['chat_history'][-1][2]\n",
    "                net_Sentiment = st.session_state['chat_history'][-1][3]\n",
    "                total_sales = st.session_state['chat_history'][-1][4]\n",
    "                asp = st.session_state['chat_history'][-1][5]\n",
    "                high_specs = st.session_state['chat_history'][-1][6]\n",
    "                sale = st.session_state['chat_history'][-1][7]\n",
    "                star_rating_html = st.session_state['chat_history'][-1][8]\n",
    "                comp_devices = st.session_state['chat_history'][-1][9]\n",
    "                summ = st.session_state['chat_history'][-1][10]\n",
    "                aspect_sentiment = st.session_state['chat_history'][-1][11]\n",
    "            html_code = f\"\"\"\n",
    "            <div style=\"background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1); display: flex; align-items: center;\">\n",
    "                <div style=\"flex: 1; text-align: center;\">\n",
    "                    <img src=\"{img_link}\" style=\"width: 150px; display: block; margin: 0 auto;\">\n",
    "                    <p style=\"color: black; font-size: 18px;\">{device_name}</p>\n",
    "                    <p>{star_rating_html}</p>\n",
    "                </div>\n",
    "                <div style=\"width: 2px; height: 150px; border-left: 2px dotted #ccc; margin: 0 20px;\"></div>\n",
    "                <div style=\"flex: 2; color: black; font-size: 18px;\">\n",
    "                    <p>Total Devices Sold: <strong>{total_sales}</strong></p>\n",
    "                    <p>Average Selling Price: <strong>{asp}</strong></p>\n",
    "                    <p>Highest Selling Specs: <strong>{high_specs}</strong> - <strong>{sale}</strong></p>\n",
    "                </div>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            st.markdown(html_code, unsafe_allow_html=True)\n",
    "            st.write(r\"$\\textsf{\\Large Detailed Summary}$\")\n",
    "            st.write(summ)\n",
    "            st.write(r\"$\\textsf{\\Large Compare with Similar Devices}$\")\n",
    "            inp = False\n",
    "            \n",
    "            checkbox_state = []\n",
    "            \n",
    "            html_content = \"\"\n",
    "            #From this point\n",
    "            for device in comp_devices['SERIES']:\n",
    "                com_device_name, link, com_sales, ASP, net_sentiment = get_comp_device_details(device, comp_devices)\n",
    "                com_star_rating_html = get_star_rating_html(net_sentiment)\n",
    "                \n",
    "                html_content += f\"\"\"\n",
    "                    <div style=\"text-align: center; padding: 10px; border: 1px solid #ccc; display: inline-block; border-radius: 5px; margin: 10px;\">\n",
    "                        <img src=\"{link}\" width=\"150\" style=\"margin-bottom: 10px;\">\n",
    "                        <div style=\"font-size: 16px; color: #333;\">{com_device_name}</div>\n",
    "                        <div style=\"font-size: 14px; color: #666;\">Sales: {com_sales}</div>\n",
    "                        <div style=\"font-size: 14px; color: #666;\">Average Selling Price: {ASP}</div>\n",
    "                        <p>{com_star_rating_html}</p>\n",
    "                    </div>\n",
    "                \"\"\"\n",
    "                checkbox_state.append(False)\n",
    "            #To this point can be moved to a function to reduce time. To be tested later\n",
    "                \n",
    "            st.markdown(html_content, unsafe_allow_html=True)\n",
    "            comp_devices_list = comp_devices['SERIES'].tolist()\n",
    "            for i in range(len(comp_devices_list)):\n",
    "                checkbox_state[i] = st.checkbox(comp_devices_list[i])\n",
    "            \n",
    "            for i in range(len(checkbox_state)):\n",
    "                if checkbox_state[i]:\n",
    "                    st.session_state['selected_device_comparison'] = comp_devices_list[i]\n",
    "                    st.write(f\"You have selected device {comp_devices_list[i]}\")\n",
    "                    break\n",
    "                st.session_state['selected_device_comparison'] = None\n",
    "            \n",
    "            if st.session_state['selected_device_comparison']:\n",
    "                device_name2, img_link2, net_Sentiment2, aspect_sentiment2, total_sales2, asp2, high_specs2, sale2, star_rating_html2, comp_devices2 = generate_device_details(st.session_state['selected_device_comparison'])\n",
    "                \n",
    "                st.write(r\"$\\textsf{\\Large Device Comparison}$\")\n",
    "                col4, col5 = st.columns(2)\n",
    "                \n",
    "                aspects = ['Performance', 'Design', 'Display', 'Battery', 'Price', 'Software']\n",
    "                \n",
    "                # Container for the first device\n",
    "                with col4:\n",
    "                    with st.container():\n",
    "                        if device_name:\n",
    "                            if img_link:\n",
    "                                image1 = load_and_resize_image(img_link, 150)\n",
    "                                st.image(image1)\n",
    "                            else:\n",
    "                                st.write(\"Image not available for this product.\")\n",
    "#                             \n",
    "                            # Display aspect-wise ratings\n",
    "                            if aspect_sentiment:\n",
    "                                st.subheader('Aspect Ratings')\n",
    "                                asp_rating = []\n",
    "                                for i in aspect_sentiment:\n",
    "                                    asp_rating.append(get_star_rating_html(i))\n",
    "                                for aspect, stars in zip(aspects, asp_rating):\n",
    "                                    st.markdown(f\"{aspect}: {stars}\",unsafe_allow_html=True)\n",
    "                            data_1 = query_quant(\"Give me all the reviews of \" + device_name,[])\n",
    "                            a = device_name + \"_Reviews.txt\"\n",
    "                            data_1.to_csv(a, sep='\\t')\n",
    "                            summary_1 = query_to_embedding_summarize(\"Give me the pros and cons of \" + device_name, a)\n",
    "                            st.subheader(device_name)\n",
    "                            st.write(summary_1)\n",
    "                            \n",
    "                with col5:\n",
    "                    with st.container():\n",
    "                        if device_name2:\n",
    "                            if img_link2:\n",
    "                                image2 = load_and_resize_image(img_link2, 150)\n",
    "                                st.image(image2)\n",
    "                            else:\n",
    "                                st.write(\"Image not available for this product.\")\n",
    "#                             \n",
    "                            # Display aspect-wise ratings\n",
    "                            if aspect_sentiment2:\n",
    "                                st.subheader('Aspect Ratings')\n",
    "                                asp_rating2 = []\n",
    "                                for i in aspect_sentiment2:\n",
    "                                    asp_rating2.append(get_star_rating_html(i))\n",
    "                                for aspect, stars in zip(aspects, asp_rating2):\n",
    "                                    st.markdown(f\"{aspect}: {stars}\",unsafe_allow_html=True)\n",
    "                            data_2 = query_quant(\"Give me all the reviews of \" + device_name2,[])\n",
    "                            a2 = device_name2 + \"_Reviews.txt\"\n",
    "                            data_2.to_csv(a2, sep='\\t')\n",
    "                            summary_2 = query_to_embedding_summarize(\"Give me the pros and cons of \" + device_name2, a2)\n",
    "                            st.subheader(device_name2)\n",
    "                            st.write(summary_2)\n",
    "            \n",
    "            \n",
    "                                        \n",
    "                            \n",
    "                                     \n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while calling the final function: {e}\"\n",
    "        print(err)\n",
    "        return err\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37d6ca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "device_name, img_link, net_Sentiment, aspect_sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices = generate_device_details(\"Microsoft Surface Pro\")\n",
    "x = query_quant(\"Give me all the reviews of \" + device_name,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60b4b03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data_Source</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Product</th>\n",
       "      <th>Review</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Product_Family</th>\n",
       "      <th>Title</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Review_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>3/1/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>the surface be an incredible device.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 9 13</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>3/4/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>Crisp new Pro.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 9 13</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>3/15/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>love the flexibility of the the surface.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 9 13</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>3/4/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>Microsoft Surface be a good laptop.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 7 Plus 12</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>3/9/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>love my new surface pro.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 7 Plus 12</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>1/7/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>do everything I need and more.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 9 13</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>1/19/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>\"great product, exactly what I need while on t...</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 9 13</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>1/19/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>easy to use.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 7 Plus 12</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>1/6/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>perfect option for my boy to take to school.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 7 Plus 12</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>BestBuy</td>\n",
       "      <td>1/12/2024 0:00</td>\n",
       "      <td>Positive</td>\n",
       "      <td>US</td>\n",
       "      <td>Windows 11 (Preinstall)</td>\n",
       "      <td>super easy to use for any age.</td>\n",
       "      <td>None</td>\n",
       "      <td>Generic</td>\n",
       "      <td>Microsoft Surface Pro 7 Plus 12</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1676 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Data_Source     Review_Date Sentiment Geography                  Product  \\\n",
       "0        BestBuy   3/1/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "1        BestBuy   3/4/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "2        BestBuy  3/15/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "3        BestBuy   3/4/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "4        BestBuy   3/9/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "...          ...             ...       ...       ...                      ...   \n",
       "1671     BestBuy   1/7/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "1672     BestBuy  1/19/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "1673     BestBuy  1/19/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "1674     BestBuy   1/6/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "1675     BestBuy  1/12/2024 0:00  Positive        US  Windows 11 (Preinstall)   \n",
       "\n",
       "                                                 Review Keywords   Aspect  \\\n",
       "0                  the surface be an incredible device.     None  Generic   \n",
       "1                                        Crisp new Pro.     None  Generic   \n",
       "2              love the flexibility of the the surface.     None  Generic   \n",
       "3                   Microsoft Surface be a good laptop.     None  Generic   \n",
       "4                              love my new surface pro.     None  Generic   \n",
       "...                                                 ...      ...      ...   \n",
       "1671                     do everything I need and more.     None  Generic   \n",
       "1672  \"great product, exactly what I need while on t...     None  Generic   \n",
       "1673                                       easy to use.     None  Generic   \n",
       "1674       perfect option for my boy to take to school.     None  Generic   \n",
       "1675                     super easy to use for any age.     None  Generic   \n",
       "\n",
       "                       Product_Family Title  Sentiment_Score  Review_Count  \n",
       "0          Microsoft Surface Pro 9 13  None                1           1.0  \n",
       "1          Microsoft Surface Pro 9 13  None                1           1.0  \n",
       "2          Microsoft Surface Pro 9 13  None                1           1.0  \n",
       "3     Microsoft Surface Pro 7 Plus 12  None                1           1.0  \n",
       "4     Microsoft Surface Pro 7 Plus 12  None                1           1.0  \n",
       "...                               ...   ...              ...           ...  \n",
       "1671       Microsoft Surface Pro 9 13  None                1           1.0  \n",
       "1672       Microsoft Surface Pro 9 13  None                1           1.0  \n",
       "1673  Microsoft Surface Pro 7 Plus 12  None                1           1.0  \n",
       "1674  Microsoft Surface Pro 7 Plus 12  None                1           1.0  \n",
       "1675  Microsoft Surface Pro 7 Plus 12  None                1           1.0  \n",
       "\n",
       "[1676 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5241ddbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m a \u001b[38;5;241m=\u001b[39m device_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_Reviews.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m data_1\u001b[38;5;241m.\u001b[39mto_csv(a, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m summary_1 \u001b[38;5;241m=\u001b[39m query_to_embedding_summarize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me the pros and cons of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m device_name, a)\n",
      "Cell \u001b[1;32mIn[1], line 247\u001b[0m, in \u001b[0;36mquery_to_embedding_summarize\u001b[1;34m(user_question, txt_file_path)\u001b[0m\n\u001b[0;32m    245\u001b[0m text \u001b[38;5;241m=\u001b[39m get_txt_text(txt_file_path)\n\u001b[0;32m    246\u001b[0m chunks \u001b[38;5;241m=\u001b[39m get_text_chunks(text)\n\u001b[1;32m--> 247\u001b[0m get_vector_store(chunks)\n\u001b[0;32m    248\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m AzureOpenAIEmbeddings(azure_deployment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMv_Agusta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# Load the vector store with the embeddings model\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 512\u001b[0m, in \u001b[0;36mget_vector_store\u001b[1;34m(chunks)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vector_store\u001b[39m(chunks):\n\u001b[0;32m    511\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m AzureOpenAIEmbeddings(azure_deployment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMv_Agusta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 512\u001b[0m     vector_store \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_texts(chunks, embedding\u001b[38;5;241m=\u001b[39membeddings)\n\u001b[0;32m    513\u001b[0m     vector_store\u001b[38;5;241m.\u001b[39msave_local(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfaiss-index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:930\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    911\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m    912\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \n\u001b[0;32m    914\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m    929\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 930\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m    932\u001b[0m         texts,\n\u001b[0;32m    933\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    938\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:517\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;66;03m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;66;03m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m engine \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeployment)\n\u001b[1;32m--> 517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_len_safe_embeddings(texts, engine\u001b[38;5;241m=\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py:333\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    331\u001b[0m batched_embeddings: List[List[\u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m _iter:\n\u001b[1;32m--> 333\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mtokens[i : i \u001b[38;5;241m+\u001b[39m _chunk_size], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invocation_params\n\u001b[0;32m    335\u001b[0m     )\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    337\u001b[0m         response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mmodel_dump()\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\openai\\resources\\embeddings.py:113\u001b[0m, in \u001b[0;36mEmbeddings.create\u001b[1;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    107\u001b[0m         embedding\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfrombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[0;32m    108\u001b[0m             base64\u001b[38;5;241m.\u001b[39mb64decode(data), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m         )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    115\u001b[0m     body\u001b[38;5;241m=\u001b[39mmaybe_transform(params, embedding_create_params\u001b[38;5;241m.\u001b[39mEmbeddingCreateParams),\n\u001b[0;32m    116\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    117\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers,\n\u001b[0;32m    118\u001b[0m         extra_query\u001b[38;5;241m=\u001b[39mextra_query,\n\u001b[0;32m    119\u001b[0m         extra_body\u001b[38;5;241m=\u001b[39mextra_body,\n\u001b[0;32m    120\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    121\u001b[0m         post_parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    122\u001b[0m     ),\n\u001b[0;32m    123\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mCreateEmbeddingResponse,\n\u001b[0;32m    124\u001b[0m )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1213\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1200\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1201\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1208\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1210\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1211\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1212\u001b[0m     )\n\u001b[1;32m-> 1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\openai\\_base_client.py:902\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    895\u001b[0m     cast_to: Type[ResponseT],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    900\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    901\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m--> 902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    903\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    904\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    905\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    906\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    907\u001b[0m         remaining_retries\u001b[38;5;241m=\u001b[39mremaining_retries,\n\u001b[0;32m    908\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Anaconda3\\Lib\\site-packages\\openai\\_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    990\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    992\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 993\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m    996\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    997\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1001\u001b[0m )\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}"
     ]
    }
   ],
   "source": [
    "data_1 = query_quant(\"Give me all the reviews of \" + device_name,[])\n",
    "a = device_name + \"_Reviews.txt\"\n",
    "data_1.to_csv(a, sep='\\t')\n",
    "summary_1 = query_to_embedding_summarize(\"Give me the pros and cons of \" + device_name, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91dfd17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Microsoft Surface Pro'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c555d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def device_details(device):\n",
    "    device_name, img_link, net_Sentiment, aspect_sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices = generate_device_details(device)\n",
    "    aspects = ['Performance', 'Design', 'Display', 'Battery', 'Price', 'Software']\n",
    "    with st.container():\n",
    "        if device_name:\n",
    "            if img_link:\n",
    "                image1 = load_and_resize_image(img_link, 150)\n",
    "                st.image(image1)\n",
    "            else:\n",
    "                st.write(\"Image not available for this product.\")\n",
    "            st.header(device_name)\n",
    "            st.markdown(star_rating_html, unsafe_allow_html=True)\n",
    "            st.write(f\"Total Devices Sold: {total_sales}\")\n",
    "            st.write(f\"Average Selling Price: {asp}\")\n",
    "            st.write(f\"Highest Selling Specs: {high_specs} - {sale}\")\n",
    "            st.subheader('Aspect Ratings')\n",
    "            asp_rating = []\n",
    "            for i in aspect_sentiment:\n",
    "                asp_rating.append(get_star_rating_html(i))\n",
    "            for aspect, stars in zip(aspects, asp_rating):\n",
    "                st.markdown(f\"{aspect}: {stars}\",unsafe_allow_html=True)\n",
    "            data_1 = query_quant(\"Give me all the reviews of \" + device_name,[])\n",
    "            a = device_name + \"_Reviews.txt\"\n",
    "            data_1.to_csv(a, sep='\\t')\n",
    "#             summary_1 = query_to_embedding_summarize(\"Give me the pros and cons of \" + device_name, a)\n",
    "            summary_1 = \"Placeholder Summary\"\n",
    "            st.subheader(device_name)\n",
    "            st.write(summary_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19621ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_view(device1, device2):\n",
    "    st.write(r\"$\\textsf{\\Large Device Comparison}$\")\n",
    "    col1, col2 = st.columns(2)\n",
    "    with col1:\n",
    "        device_details(device1)\n",
    "    with col2:\n",
    "        device_details(device2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
