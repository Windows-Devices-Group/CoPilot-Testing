import streamlit as st
from azure.core.credentials import AzureKeyCredential
from langchain.text_splitter import RecursiveCharacterTextSplitter
import numpy as np
import faiss
import plotly.express as px
from langchain_community.vectorstores import FAISS
from langchain_core.vectorstores import VectorStoreRetriever
from langchain.chains import RetrievalQA
from openai import AzureOpenAI
from langchain_openai import AzureOpenAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain.chains.question_answering import load_qa_chain
from langchain_core.messages import HumanMessage
from langchain_openai import AzureChatOpenAI
import openai
import pyodbc
import urllib
from sqlalchemy import create_engine
import pandas as pd
from azure.identity import InteractiveBrowserCredential
from pandasai import SmartDataframe
import pandas as pd
import matplotlib.pyplot as plt
import os
import time
from PIL import Image
import base64
import pandasql as ps
import matplotlib.pyplot as plt
import seaborn as sns
import re

os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
#Initializing API Keys to use LLM
os.environ["AZURE_OPENAI_API_KEY"] = "a22e367d483f4718b9e96b1f52ce6d53"
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://hulk-openai.openai.azure.com/"

from openai import AzureOpenAI
client = AzureOpenAI(
    api_key=os.getenv("672370cd6ca440f2a0327351d4f4d2bf"),  
    api_version="2024-02-01",
    azure_endpoint = os.getenv("https://hulk-openai.openai.azure.com/")
    )
    
deployment_name='SurfaceGenAI'


RCR_context = """
    1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.
    2. There is only one table with table name RCR_Sales_Data where each row has. The table has 20 columns, they are:
        Month: Contains dates for the records
        Country: From where the sales has happened. It contains following values: 'Turkey','India','Brazil','Germany','Philippines','France','Netherlands','Spain','United Arab Emirates','Czech Republic','Norway','Belgium','Finland','Canada','Mexico','Russia','Austria','Poland','United States','Switzerland','Italy','Colombia','Japan','Chile','Sweden','Vietnam','Saudi Arabia','South Africa','Peru','Indonesia','Taiwan','Thailand','Ireland','Korea','Hong Kong SAR','Malaysia','Denmark','New Zealand','China' and 'Australia'.
        Geography: From which Country or Region the review was given. It contains following values: 'Unknown', 'Brazil', 'Australia', 'Canada', 'China', 'Germany','France'.
        OEMGROUP: OEM or Manufacturer of the Device. It contains following values: 'Lenovo','Acer','Asus','HP','All Other OEMs', 'Microsoft' and 'Samsung'
        SUBFORMFACTOR: Formfactor of the device. It contains following values: 'Ultraslim Notebook'.
        GAMINGPRODUCTS: Flag whether Device is a gaming device or not. It contains following values: 'GAMING', 'NO GAMING' and 'N.A.'.
        SCREEN_SIZE_INCHES: Screen Size of the Device.
        PRICE_BRAND_USD_3: Band of the price at which the device is selling. It contains following values: '0-300', '300-500', '500-800' and '800+.
        OS_VERSION: Operating System version intall on the device. It contains following values: 'Windows 11', 'Chrome', 'Mac OS'.
        Operating_System_Summary: Operating System installed on the device. This is at uber level. It contains following values: 'Windows', 'Google OS', 'Apple OS'.
        Sales_Units: Number of Devices sold for that device in a prticular month and country.
        Sales_Value: Revenue Generated by the devices sold.
        Series: Family of the device such as IdeaPad 1, HP Laptop 15 etc.
        Specs_Combination: Its contains the combination of Series, Processor, RAM , Storage and Screen Size. For Example: SURFACE LAPTOP GO | Ci5 | 8 GB | 256.0 SSD | 12" .
        Chassis Segment: It contains following values: 'SMB_Upper','Mainstream_Lower','SMB_Lower','Enterprise Fleet_Lower','Entry','Mainstream_Upper','Premium Mobility_Upper','Enterprise Fleet_Upper','Premium Mobility_Lower','Creation_Lower','UNDEFINED','Premium_Mobility_Upper','Enterprise Work Station','Unknown','Gaming_Musclebook','Entry_Gaming','Creation_Upper','Mainstrean_Lower'
        
    3.  When Asked for Price Range you have to use ASP Column to get minimum and Maxium value. Do not consider Negative Values. Also Consider Sales Units it shouldn't be 0.
        Exaple Query:
            SELECT MIN(ASP) AS Lowest_Value, MAX(ASP) AS Highest_Value
            FROM RCR_Sales_Data
            WHERE
            Series = 'Device Name'
            AND ASP >= 0
            AND Sales_Units <> 0;
    4. Total Sales_Units Should Always be in Thousands. 
        Example Query:
            SELECT (SUM(Sales_Units) / 1000) AS "TOTAL SALES UNITS"
            FROM RCR_Sales_Data
            WHERE
            SERIES LIKE '%SURFACE LAPTOP GO%';
    5. Average Selling Price (ASP): It is calculated by sum of SUM(Sales_Value)/SUM(Sales_Units)
    6. Total Sales Units across countries or across regions is sum of sales_units for those country. It should be in thousand of million hence add "K" or "M" after the number.
        Example to calculate sales units across country:
            SELECT Country, (SUM(Sales_Units) / 1000) AS "Sales_Units(In Thousands)"
            FROM RCR_Sales_Data
            GROUP BY Country
            ORDER BY Sales_Units DESC
    7. Total Sales Units across column "X" or across regions is sum of sales_units for those country. It should be in thousand of million hence add "K" or "M" after the number.
        Example to calculate sales units across country:
            SELECT "X", (SUM(Sales_Units) / 1000) AS "Sales_Units(In Thousands)"
            FROM RCR_Sales_Data
            GROUP BY "X"
            ORDER BY Sales_Units DESC
    8. If asked about the highest selling Specs Combination. 
        Example Query:
            SELECT Specs_Combination, (SUM(Sales_Units) / 1000) AS "TOTAL SALES UNITS"
            FROM RCR_Sales_Data
            WHERE SERIES LIKE '%Macbook AIR%'
            AND SALES_UNITS <> 0
            GROUP BY Specs_Combination
            ORDER BY "TOTAL SALES UNITS" DESC
            LIMIT 1;
    9. If asked about similar compete devices.
    Example Query:
            SQL = WITH DeviceNameASP AS (
                    SELECT
                        'Device Name' AS Series,
                        SUM(Sales_Value) / SUM(Sales_Units) AS ASP,
                        Chassis_Segment,
                        SUM(Sales_Units) AS Sales_Units
                    FROM
                        RCR_Sales_Data
                    WHERE
                        Series LIKE '%Device Name%'
                    GROUP BY
                        Chassis_Segment
                ),
                CompetitorASP AS (
                    SELECT
                        Series,
                        SUM(Sales_Value) / SUM(Sales_Units) AS ASP,
                        Chassis_Segment,
                        SUM(Sales_Units) AS Sales_Units
                    FROM
                        RCR_Sales_Data
                    WHERE
                        Operating_System_Summary IN ('Apple OS', 'Google OS','Windows OS')
                        AND SERIES NOT LIKE '%Device Name%'
                    GROUP BY
                        Series, Chassis_Segment
                ),
                RankedCompetitors AS (
                    SELECT
                        C.Series,
                        C.ASP,
                        C.Chassis_Segment,
                        C.Sales_Units,
                        ROW_NUMBER() OVER (PARTITION BY C.Chassis_Segment ORDER BY C.Sales_Units DESC) AS rank
                    FROM
                        CompetitorASP C
                    JOIN
                        DeviceNameASP S
                    ON
                        ABS(C.ASP - S.ASP) <= 400
                        AND C.Chassis_Segment = S.Chassis_Segment
                )
                SELECT
                    Series,
                    ASP AS CompetitorASP,
                    Sales_Units
                FROM
                    RankedCompetitors
                WHERE
                    rank <= 3;

    10. If asked about dates or year SUBSTR() function instead of Year() or Month()
    11. Convert numerical outputs to float upto 2 decimal point.
    12. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.
    13. Always use 'LIKE' operator whenever they mention about any Country, Series. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.
    14. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.
    15. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.
    16. Always use LIKE function instead of = Symbol while generating SQL Query
    17. Important: User can ask question about any categories including Country, OEMGROUP,OS_VERSION etc etc. Hence, include the in SQL Query if someone ask it.
    18. Important: Use the correct column names listed above. There should not be Case Sensitivity issue. 
    19. Important: The values in OPERATING_SYSTEM_SUMMARY are ('Apple OS', 'Google OS') not ('APPLE OS', 'GOOGLE OS'). So use exact values. Not everything should be capital letters.
    20. Important: You Response should directly starts from SQL query nothing else."""

interaction = ""

# Initialize an empty context

def generate_SQL_Query(user_question):
    global RCR_context, interaction
    # Append the new question to the context
    full_prompt = RCR_context + interaction + "\nQuestion:\n" + user_question + "\nAnswer:"
    
    # Send the query to Azure OpenAI
    response = client.completions.create(
        model=deployment_name,
        prompt=full_prompt,
        max_tokens=500,
        temperature=0
    )
    
    # Extract the generated SQL query
    sql_query = response.choices[0].text.strip()
    
    # Update context with the latest interaction
    interaction += "\nQuestion:\n" + user_question + "\nAnswer:\n" + sql_query
    
    return sql_query

#Converting Top Operator to Limit Operator as pandasql doesn't support Top
def convert_top_to_limit(sql):
    tokens = sql.upper().split()
    is_top_used = False

    for i, token in enumerate(tokens):
        if token == 'TOP':
            is_top_used = True
            if i + 1 < len(tokens) and tokens[i + 1].isdigit():
                limit_value = tokens[i + 1]
                # Remove TOP and insert LIMIT and value at the end
                del tokens[i:i + 2]
                tokens.insert(len(tokens), 'LIMIT')
                tokens.insert(len(tokens), limit_value)
                break  # Exit loop after successful conversion
            else:
                raise ValueError("TOP operator should be followed by a number")

    return ' '.join(tokens) if is_top_used else sql


def process_tablename(sql, table_name):
    x = sql.upper()
    query = x.replace(table_name.upper(), table_name)
    return query

RCR_Sales_Data = pd.read_csv('RCR Sales Data Sample V4.csv')


def get_sales_units(device_name):
    try:
        question = "Totals Sales Units for " + device_name
        a = generate_SQL_Query(question)
        SQL_Query = convert_top_to_limit(a)
        SQL_Query = process_tablename(SQL_Query,"RCR_Sales_Data")
        data = ps.sqldf(SQL_Query, globals())
        col_name = data.columns[0]
        total_sales = data[col_name][0]
        total_sales = str(round(total_sales,2)) + "K"
    except exception as e:
        print(e)
        total_sales = "NA"
        
    return total_sales


def get_ASP(device_name):
    try:
        question = "What's ASP for " + device_name
        a = generate_SQL_Query(question)
        SQL_Query = convert_top_to_limit(a)
        SQL_Query = process_tablename(SQL_Query,"RCR_Sales_Data")
        data = ps.sqldf(SQL_Query, globals())
        col_name = data.columns[0]
        asp = data[col_name][0]
        asp = "$" + str(int(round(asp,0)))
    except:
        asp = "NA"
    return asp

def get_highest_selling_specs(device_name):
    try:
        question = "What's highest selling Specs Combination for " + device_name
        a = generate_SQL_Query(question)
        SQL_Query = convert_top_to_limit(a)
        SQL_Query = process_tablename(SQL_Query,"RCR_Sales_Data")
        data = ps.sqldf(SQL_Query, globals())
        col_name1 = data.columns[0]
        col_name2 = data.columns[1]
        specs = data[col_name1][0]
        sales_unit = data[col_name2][0]
        sales_unit = str(round(sales_unit,2)) + "K"
    except:
        specs = "NA"
        sales_unit = "NA"
    return specs,sales_unit

def compete_device(device_name):
    try:
        question = "What are the compete device for " + device_name
        a = generate_SQL_Query(question)
        SQL_Query = convert_top_to_limit(a)
        SQL_Query = process_tablename(SQL_Query,"RCR_Sales_Data")
        SQL_Query = SQL_Query.replace('APPLE','Apple')
        SQL_Query = SQL_Query.replace('GOOGLE','Google')
        SQL_Query = SQL_Query.replace('WINDOWS','Windows')
        data = ps.sqldf(SQL_Query, globals())
        
    except:
        data = None
    print(data)
    return data
    
def get_sales_device_name(input_device):
    try:
        dev_mapping = pd.read_csv('SalesSentimentMapping.csv')
        sales_device_name = dev_mapping[dev_mapping['SentimentDevice']==input_device]['SalesDevice'].values[0]
    except:
        sales_device_name = None
    return sales_device_name
    
def get_device_image(user_input):
    dev = user_input
    try:
        # Assuming the images are in a folder named 'Device Images'
        img_folder = 'Device Images'
        img_path = os.path.join(img_folder, f"{dev}.jpg")
        if not os.path.exists(img_path):
            img_path = None
    except Exception as e:
        print(e)
        img_path = None
    return (dev, img_path)

# def get_comp_device_image(user_input):
#     df = pd.read_csv('Device Images.csv')
#     dev = None
#     for i in df['Device Name']:
#         if str.lower(i) in str.lower(user_input):
#             dev = i
#             break  # Exit the loop once a match is found
#     if dev is None:
#         return None, None  # Return None if no matching device is found
#     link = df[df['Device Name']==dev]['Link'].values[0]  # Using .values[0] to get the link
#     return dev, link
    
def get_net_sentiment(device_name):
    a = query_quant_devices(device_name,[])
    try:
        Net_Sentiment = float(a[a['ASPECT']=='TOTAL']['ASPECT_SENTIMENT'].values[0])
        aspects = a["ASPECT"].unique()
        if "Performance" in aspects:
            Performance_Sentiment = float(a[a['ASPECT']=='Performance']['ASPECT_SENTIMENT'].values[0])
        else:
            Performance_Sentiment = 0
        
        if "Design" in aspects:
            Design_Sentiment = float(a[a['ASPECT']=='Design']['ASPECT_SENTIMENT'].values[0])
        else:
            Design_Sentiment = 0
        
        if "Display" in aspects:
            Display_Sentiment = float(a[a['ASPECT']=='Display']['ASPECT_SENTIMENT'].values[0])
        else:
            Display_Sentiment = 0
        
        if "Battery" in aspects:
            Battery_Sentiment = float(a[a['ASPECT']=='Battery']['ASPECT_SENTIMENT'].values[0])
        else:
            Battery_Sentiment = 0
        
        if "Price" in aspects:
            Price_Sentiment = float(a[a['ASPECT']=='Price']['ASPECT_SENTIMENT'].values[0])
        else:
            Price_Sentiment = 0
        
        if "Software" in aspects:
            Software_Sentiment = float(a[a['ASPECT']=='Software']['ASPECT_SENTIMENT'].values[0])
        else:
            Software_Sentiment = 0
            
            
        aspect_sentiment = list((Performance_Sentiment, Design_Sentiment, Display_Sentiment, Battery_Sentiment, Price_Sentiment, Software_Sentiment))
                                 
    except:
        Net_Sentiment = None
        aspect_sentiment = None     
    return Net_Sentiment, aspect_sentiment

def get_comp_device_details(user_input, df1):
    df1['SERIES'] = df1['SERIES'].str.upper()
    sales_data = df1[df1['SERIES'] == user_input]
    dev = user_input
    try:
        dev_mapping = pd.read_csv('SalesSentimentMapping.csv')
        dev_mapping['SalesDevice'] = dev_mapping['SalesDevice'].str.upper()
        sentiment_device_name = dev_mapping[dev_mapping['SalesDevice']==user_input]
        sentiment_device_name = list(sentiment_device_name['SentimentDevice'].unique())[0]
    except Exception as e:
        sentiment_device_name = None
    try:
        # Assuming the images are in a folder named 'Device Images'
        img_folder = 'Device Images'
        img_path = os.path.join(img_folder, f"{sentiment_device_name}.jpg")
        if not os.path.exists(img_path):
            img_not_found = "Image Not Found"
            img_path = os.path.join(img_folder, f"{img_not_found}.jpg")
    except Exception as e:
        print(e)
    if sales_data.empty:
        return user_input, img_path, None, None, None  # Return dev and link, but None for sales and ASP if no matching SERIES is found
    
    try:
        sales = str(round(float(sales_data['SALES_UNITS'].values[0]) / 1000, 2)) + "K"
    except:
        sales = "NA"
    try:
        ASP = "$" + str(int(sales_data['COMPETITORASP'].values[0]))
    except:
        ASP = "NA"
    net_sentiment,aspect_sentiment = get_net_sentiment(sentiment_device_name)
    return dev, img_path, sales, ASP, net_sentiment
    
def get_star_rating_html(net_sentiment):
    try:
    # Normalize net sentiment from -100 to 100 to 0 to 10 for star ratings
        normalized_rating = (net_sentiment + 100) / 40
    
        # Determine the number of full and half stars
        full_stars = int(normalized_rating)
        half_star = 1 if normalized_rating - full_stars >= 0.5 else 0
    
        # Generate the HTML for the stars
        star_html = '<span style="color: gold;">'
        star_html += '★' * full_stars
        star_html += '½' * half_star
        star_html += '☆' * (5 - full_stars - half_star)
        star_html += '</span>'
        return star_html
    except:
        return "NA"
        
def get_detailed_summary(device_name):
    try:
        if device_name:
            data = query_quant_devices("Summarize the reviews of "+ device_name, [])
            total_reviews = data.loc[data['ASPECT'] == 'TOTAL', 'REVIEW_COUNT'].iloc[0]
            data['REVIEW_PERCENTAGE'] = data['REVIEW_COUNT'] / total_reviews * 100
            dataframe_as_dict = data.to_dict(orient='records')
            data_new = data
            data_new = data_new.dropna(subset=['ASPECT_SENTIMENT'])
            data_new = data_new[~data_new["ASPECT"].isin(["Generic", "Account", "Customer-Service", "Browser"])]
            vmin = data_new['ASPECT_SENTIMENT'].min()
            vmax = data_new['ASPECT_SENTIMENT'].max()
            styled_df = data_new.style.applymap(lambda x: custom_color_gradient(x, vmin, vmax), subset=['ASPECT_SENTIMENT'])
            data_filtered = data_new[data_new['ASPECT'] != 'TOTAL']
            data_sorted = data_filtered.sort_values(by='REVIEW_COUNT', ascending=False)
            top_four_aspects = data_sorted.head(4)
            aspects_list = top_four_aspects['ASPECT'].to_list()
            formatted_aspects = ', '.join(f"'{aspect}'" for aspect in aspects_list)
            key_df = get_final_df_devices(aspects_list, device_name)
            b =  key_df.to_dict(orient='records')
            su = query_detailed_summary_devices("Summarize reviews of" + device_name + "for " +  formatted_aspects +  "Aspects which have following "+str(dataframe_as_dict)+ str(b) + "Reviews: ",[])
    except:
        su = "I don't have sufficient data to provide a complete and accurate response at this time. Please provide more details or context."
    return su

def get_conversational_chain_summary():
    
    prompt_template = """
    Your task is to analyze the reviews of Windows products and generate a summary of the pros and cons for each product based on the provided dataset.Provide an overall summary. focus only on listing the pros and cons. 
    Use the format below for your response:

    Pros and Cons of [Product Name]:

    Pros:

    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]
    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]
    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]
    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]
    [Aspect]: [Brief summary of positive feedback regarding this aspect. Include specific examples if available.]
    Cons:

    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]
    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]
    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]
    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]
    [Aspect]: [Brief summary of negative feedback regarding this aspect. Include specific examples if available.]
    
    [Overall Summary]: [Brief summary of overall feedback regarding all aspect.]
    The dataset includes the following columns:

    Review: Review of the Windows product.
    Data_Source: Source of the review, containing different retailers.
    Geography: Country or region of the review.
    Title: Title of the review.
    Review_Date: Date the review was posted.
    Product: Product the review corresponds to, with values: "Windows 11 (Preinstall)", "Windows 10".
    Product_Family: Version or type of the corresponding product.
    Sentiment: Sentiment of the review, with values: 'Positive', 'Neutral', 'Negative'.
    Aspect: Aspect or feature of the product discussed in the review, with values: "Audio-Microphone", "Software", "Performance", "Storage/Memory", "Keyboard", "Browser", "Connectivity", "Hardware", "Display", "Graphics", "Battery", "Gaming", "Design", "Ports", "Price", "Camera", "Customer-Service", "Touchpad", "Account", "Generic".
    Keywords: Keywords mentioned in the review.
    Review_Count: Will be 1 for each review or row.
    Sentiment_Score: Will be 1, 0, or -1 based on the sentiment.
    Please ensure that the response is based on the analysis of the provided dataset, summarizing both positive and negative aspects of each product. 
     
        
    Context:\n {context}?\n
    Question: \n{question}\n
 
    Answer:
    """
    model = AzureChatOpenAI(
    azure_deployment="Verbatim-Synthesis",
    api_version='2023-12-01-preview',temperature = 0)
    prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
    return chain

def query_to_embedding_summarize(user_question, txt_file_path):
    text = get_txt_text(txt_file_path)
    chunks = get_text_chunks(text)
    get_vector_store(chunks)
    embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
    
    # Load the vector store with the embeddings model
    new_db = FAISS.load_local("faiss-index", embeddings, allow_dangerous_deserialization=True)
    docs = new_db.similarity_search(user_question)
    chain = get_conversational_chain_summary()
    response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
    return response['output_text']

def generate_device_details(device_input):
    global interaction
    device_name, img_link = get_device_image(device_input)
    net_Sentiment,aspect_sentiment = get_net_sentiment(device_name)
    sales_device_name = get_sales_device_name(device_name)
    total_sales = get_sales_units(sales_device_name)
    asp = get_ASP(sales_device_name)
    high_specs, sale = get_highest_selling_specs(sales_device_name)
    star_rating_html = get_star_rating_html(net_Sentiment)
    comp_devices = compete_device(sales_device_name)
    interaction = ""
    return device_name, img_link, net_Sentiment, aspect_sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices

def load_and_resize_image(url, new_height):
    try:
        response = requests.get(url)
        img = Image.open(BytesIO(response.content))
        aspect_ratio = img.width / img.height
        new_width = int(aspect_ratio * new_height)
        resized_img = img.resize((new_width, new_height))
        return resized_img  # Return the resized PIL image object
    except Exception as e:
        st.write("Image not available for this product.")
        st.write(f"Error: {e}")
        return None
    
def get_txt_text(txt_file_path):
    with io.open(txt_file_path, 'r', encoding='utf-8') as f:
        text = f.read()
    return text

def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000)
    chunks = text_splitter.split_text(text)
    return chunks

def get_vector_store(chunks):
    embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
    vector_store = FAISS.from_texts(chunks, embedding=embeddings)
    vector_store.save_local("faiss-index")
    
def device_details(device):
    device_name, img_link, net_Sentiment, aspect_sentiment, total_sales, asp, high_specs, sale, star_rating_html, comp_devices = generate_device_details(device)
    aspects = ['Performance', 'Design', 'Display', 'Battery', 'Price', 'Software']
    with st.container(border = True):
        if device_name:
            with st.container(border = False):
                if img_link:
                    image1 = load_and_resize_image(img_link, 150)
                    st.image(image1)
                else:
                    st.write("Image not available for this product.")
            with st.container(height=120, border = False):
                st.header(device_name)
            with st.container(height=50, border = False):
                st.markdown(star_rating_html, unsafe_allow_html=True)
            with st.container(height=165, border = False):
                st.write(f"Total Devices Sold: {total_sales}")
                st.write(f"Average Selling Price: {asp}")
                st.write(f"Highest Selling Specs: {high_specs} - {sale}")
            with st.container(height=300, border = False):
                st.subheader('Aspect Ratings')
                asp_rating = []
                for i in aspect_sentiment:
                    asp_rating.append(get_star_rating_html(i))
                for aspect, stars in zip(aspects, asp_rating):
                    st.markdown(f"{aspect}: {stars}",unsafe_allow_html=True)
            data_1 = query_quant_devices("Give me all the reviews of " + device_name,[])
            a = device_name + "_Reviews.txt"
            data_1.to_csv(a, sep='\t')
            summary_1 = query_to_embedding_summarize("Give me the pros and cons of " + device_name, a)
#             summary_1 = "Placeholder Summary"
            st.write(summary_1)

def comparison_view(device1, device2):
    st.write(r"$\textsf{\Large Device Comparison}$")
    col1, col2 = st.columns(2)
    with col1:
        device_details(device1)
    with col2:
        device_details(device2)
        
        
        
import streamlit as st
from fuzzywuzzy import process
from rapidfuzz import process, fuzz

def identify_devices(input_string):
    global full_response
    # First, check if any device in the list is exactly in the input string
    df = pd.read_csv('Windows_Data_116K.csv')
    devices_list = list(df['Product_Family'].unique())
    for device in devices_list:
        if device in input_string:
            return device
    
    # If no exact match is found, use fuzzy matching
    most_matching_device = process.extractOne(input_string, devices_list, scorer=fuzz.token_set_ratio)
    
    # Check the matching score
    if most_matching_device[1] >= 60:
        return most_matching_device[0]
    else:
        return "Device not available"
        
def device_summarization(user_input):
    global full_response
    if user_input == "Device not availabe":
        message = "I don't have sufficient data to provide a complete and accurate response at this time. Please provide more details or context."
        st.write(message)
        full_response += message
    else:
        device_name, img_path = get_device_image(user_input)
        net_Sentiment,aspect_sentiment = get_net_sentiment(device_name)
        sales_device_name = get_sales_device_name(device_name)
        total_sales = get_sales_units(sales_device_name)
        asp = get_ASP(sales_device_name)
        high_specs, sale = get_highest_selling_specs(sales_device_name)
        star_rating_html = get_star_rating_html(net_Sentiment)
        html_code = f"""
        <div style="background-color: white; padding: 20px; border-radius: 10px; box-shadow: 0px 0px 10px rgba(0, 0, 0, 0.1); display: flex; align-items: center;">
            <div style="flex: 1; text-align: center;">
                <img src="data:image/jpeg;base64,{base64.b64encode(open(img_path, "rb").read()).decode()}"  style="width: 150px; display: block; margin: 0 auto;">
                <p style="color: black; font-size: 18px;">{device_name}</p>
                <p>{star_rating_html}</p>
            </div>
            <div style="width: 2px; height: 150px; border-left: 2px dotted #ccc; margin: 0 20px;"></div>
            <div style="flex: 2; color: black; font-size: 18px;">
                <p>Total Devices Sold: <strong>{total_sales}</strong></p>
                <p>Average Selling Price: <strong>{asp}</strong></p>
                <p>Highest Selling Specs: <strong>{high_specs}</strong> - <strong>{sale}</strong></p>
            </div>
        </div>
        """
        st.markdown(html_code, unsafe_allow_html=True)
        st.write(r"$\textsf{\Large Detailed Summary}$")
        summ = get_detailed_summary(user_input)
        st.write(summ)
        full_response += summ
        st.write(r"$\textsf{\Large Compete Devices}$")
        comp_devices = compete_device(sales_device_name)
        html_content = ""
        for device in comp_devices['SERIES']:
            com_device_name, img_path, com_sales, ASP, net_sentiment = get_comp_device_details(device, comp_devices)
            com_star_rating_html = get_star_rating_html(net_sentiment)
            html_content += f"""
                <div style="text-align: center; padding: 10px; border: 1px solid #ccc; display: inline-block; border-radius: 5px; margin: 10px;">
                    <img src="data:image/jpeg;base64,{base64.b64encode(open(img_path, "rb").read()).decode()}" width="150" style="margin-bottom: 10px;">
                    <div style="font-size: 16px; color: #333;">{com_device_name}</div>
                    <div style="font-size: 14px; color: #666;">Sales: {com_sales}</div>
                    <div style="font-size: 14px; color: #666;">Average Selling Price: {ASP}</div>
                    <p>{com_star_rating_html}</p>
                </div>
            """
        st.markdown(html_content, unsafe_allow_html=True)


Devices_Sentiment_Data  = pd.read_csv("Windows_Data_116K.csv")


# In[51]:


def Sentiment_Score_Derivation(value):
    try:
        if value == "Positive":
            return 1
        elif value == "Negative":
            return -1
        else:
            return 0
    except Exception as e:
        err = f"An error occurred while deriving Sentiment Score: {e}"
        return err    

#Deriving Sentiment Score and Review Count columns into the dataset
Devices_Sentiment_Data["Sentiment_Score"] = Devices_Sentiment_Data["Sentiment"].apply(Sentiment_Score_Derivation)
Devices_Sentiment_Data["Review_Count"] = 1.0


# In[52]:


def convert_top_to_limit(sql):
    try:
        tokens = sql.upper().split()
        is_top_used = False

        for i, token in enumerate(tokens):
            if token == 'TOP':
                is_top_used = True
                if i + 1 < len(tokens) and tokens[i + 1].isdigit():
                    limit_value = tokens[i + 1]
                    # Remove TOP and insert LIMIT and value at the end
                    del tokens[i:i + 2]
                    tokens.insert(len(tokens), 'LIMIT')
                    tokens.insert(len(tokens), limit_value)
                    break  # Exit loop after successful conversion
                else:
                    raise ValueError("TOP operator should be followed by a number")

        return ' '.join(tokens) if is_top_used else sql
    except Exception as e:
        err = f"An error occurred while converting Top to Limit in SQL Query: {e}"
        return err


# In[53]:


def process_tablename(sql, table_name):
    try:
        x = sql.upper()
        query = x.replace(table_name.upper(), table_name)
        return query
    except Exception as e:
        err = f"An error occurred while processing table name in SQL query: {e}"
        return err


# In[54]:


def get_conversational_chain_quant_devices(history):
    try:
        hist = """"""
        for i in history:
            hist = hist+"\nUser: "+i[0]
            if isinstance(i[1],pd.DataFrame):
                x = i[1].to_string()
            else:
                x = i[1]
            hist = hist+"\nResponse: "+x
        prompt_template = """
        
        If an user is asking for Summarize reviews of any product. Note that user is not seeking for reviews, user is seeking for all the Quantitative things of the product(Net Sentiment & Review Count) and also (Aspect wise sentiment and Aspect wise review count)
        So choose to Provide Net Sentiment and Review Count and Aspect wise sentiment and their respective review count and Union them in single table
        
        Example : If the user Quesiton is "Summarize reviews of CoPilot Produt"
        
        User seeks for net sentiment and aspect wise net sentiment of "Windows 10" Product and their respective review count in a single table
        
        Your response should be : Overall Sentiment is nothing but the net sentiment and overall review count of the product
        
                        Aspect Aspect_SENTIMENT REVIEW_COUNT
                    0 TOTAL 40 15000.0
                    1 Performance 31.8 2302.0
                    2 Gaming 20.2 570.0
                    3 Display 58.9 397.0
                    4 Design -1.2 345.0
                    5 Touchpad 20.1 288.0
                    6 Storage/Memory -22.9 271.0
                    7 Audio-Microphone -43.7 247.0
                    8 Software -28.6 185.0
                    9 Hardware 52.9 170.0
                    10 Keyboard 19.1 157.0
                    11 Account -44.7 152.0
                    12 Price 29.5 95.0
                    13 Graphics 18.9 90.0 and so on
                    
                    The Query has to be like this 
                    
                SELECT 'TOTAL' AS Aspect, 
                ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, 
                SUM(Review_Count) AS Review_Count
                FROM Devices_Sentiment_Data
                WHERE Product_Family LIKE '%Asus Rog Zephyrus%'

                UNION

                SELECT Aspect, 
                ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, 
                SUM(Review_Count) AS Review_Count
                FROM Devices_Sentiment_Data
                WHERE Product_Family LIKE '%Asus Rog Zephyrus%'
                GROUP BY Aspect

                ORDER BY Review_Count DESC

                    
                    
                IMPORTANT : if any particular Aspect "Performance" in user prompt:
                    

                        SELECT 'TOTAL' AS Aspect, 
                        ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, 
                        SUM(Review_Count) AS Review_Count
                        FROM Devices_Sentiment_Data
                        WHERE Product_Family LIKE '%Asus Rog Zephyrus%'

                        UNION

                        SELECT Aspect, 
                        ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, 
                        SUM(Review_Count) AS Review_Count
                        FROM Devices_Sentiment_Data
                        WHERE Product_Family LIKE '%Asus Rog Zephyrus%'
                        GROUP BY Aspect
                        HAVING Aspect LIKE %'Performance'%

                        ORDER BY Review_Count DESC


        
        IMPORTANT : IT has to be Net sentiment and Aspect Sentiment. Create 2 SQL Query and UNION them
        
        1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.
            2. There is only one table with table name Devices_Sentiment_Data where each row is a user review. The table has 10 columns, they are:
                Review: Review of the Copilot Product
                Data_Source: From where is the review taken. It contains different retailers
                Geography: From which Country or Region the review was given. It contains different Grography.
                Title: What is the title of the review
                Review_Date: The date on which the review was posted
                Product: Corresponding product for the review. It contains following values: "Windows 11 (Preinstall)", "Windows 10"
                Product_Family: Which version or type of the corresponding Product was the review posted for. Different Device Names
                Sentiment: What is the sentiment of the review. It contains following values: 'Positive', 'Neutral', 'Negative'.
                Aspect: The review is talking about which aspect or feature of the product. It contains following values: "Audio-Microphone","Software","Performance","Storage/Memory","Keyboard","Browser","Connectivity","Hardware","Display","Graphics","Battery","Gaming","Design","Ports","Price","Camera","Customer-Service","Touchpad","Account","Generic"
                Keyword: What are the keywords mentioned in the product
                Review_Count - It will be 1 for each review or each row
                Sentiment_Score - It will be 1, 0 or -1 based on the Sentiment.
                
            3. Sentiment mark is calculated by sum of Sentiment_Score.
            4. Net sentiment is calculcated by sum of Sentiment_Score divided by sum of Review_Count. It should be in percentage. Example:
                    SELECT ((SUM(Sentiment_Score)*1.0)/(SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment 
                    FROM Devices_Sentiment_Data
                    ORDER BY Net_Sentiment DESC
            5. Net sentiment across country or across region is sentiment mark of a country divided by total reviews of that country. It should be in percentage.
                Example to calculate net sentiment across country:
                    SELECT Geography, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment
                    FROM Devices_Sentiment_Data
                    GROUP BY Geography
                    ORDER BY Net_Sentiment DESC
            6. Net Sentiment across a column "X" is calculcated by Sentiment Mark for each "X" divided by Total Reviews for each "X".
                Example to calculate net sentiment across a column "X":
                    SELECT X, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment
                    FROM Devices_Sentiment_Data
                    GROUP BY X
                    ORDER BY Net_Sentiment DESC
            7. Distribution of sentiment is calculated by sum of Review_Count for each Sentiment divided by overall sum of Review_Count
                Example: 
                    SELECT Sentiment, SUM(ReviewCount)*100/(SELECT SUM(Review_Count) AS Reviews FROM Devices_Sentiment_Data) AS Total_Reviews 
                    FROM Devices_Sentiment_Data 
                    GROUP BY Sentiment
                    ORDER BY Total_Reviews DESC
            8. Convert numerical outputs to float upto 1 decimal point.
            9. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.
            10. Top Country is based on Sentiment_Score i.e., the Country which have highest sum(Sentiment_Score)
            11. Always use 'LIKE' operator whenever they mention about any Country. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.
            12. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.
            13. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.
            14. Important: Always show Net_Sentiment in Percentage upto 1 decimal point. Hence always make use of ROUND function while giving out Net Sentiment and Add % Symbol after it.
            15. Important: User can ask question about any categories including Aspects, Geograpgy, Sentiment etc etc. Hence, include the in SQL Query if someone ask it.
            16. Important: You Response should directly starts from SQL query nothing else.
            17. Important: Always use LIKE keyword instead of = symbol while generating SQL query.
            18. Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.
            19. Sort all Quantifiable outcomes based on review count
        \n Following is the previous conversation from User and Response, use it to get context only:""" + hist + """\n
                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\n
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for quantifiable review summarization: {e}"
        return err

#Function to convert user prompt to quantitative outputs for Copilot Review Summarization
def query_quant_devices(user_question, history, vector_store_path="faiss_index_Windows_116k"):
    try:
        # Initialize the embeddings model
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        
        # Load the vector store with the embeddings model
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        
        # Rest of the function remains unchanged
        chain = get_conversational_chain_quant_devices(history)
        docs = []
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        SQL_Query = response["output_text"]
        SQL_Query = convert_top_to_limit(SQL_Query)
        SQL_Query = process_tablename(SQL_Query,"Devices_Sentiment_Data")
    #     print(SQL_Query)
        data = ps.sqldf(SQL_Query, globals())
        data_1 = data
        html_table = data.to_html(index=False)
    #     return html_table
        return data_1
    except Exception as e:
        err = f"An error occurred while generating response for quantitative review summarization: {e}"
        return err


# In[55]:


def get_conversational_chain_detailed_summary_devices(history):
    try:
        hist = """"""
        for i in history:
            hist = hist+"\nUser: "+i[0]
            if isinstance(i[1],pd.DataFrame):
                x = i[1].to_string()
            else:
                x = i[1]
            hist = hist+"\nResponse: "+ x
        prompt_template = """
        
        
    
        
        1. Your Job is to analyse the Net Sentiment, Aspect wise sentiment and Key word regarding the different aspect and summarize the reviews that user asks for utilizing the reviews and numbers you get. Use maximum use of the numbers and Justify the numbers using the reviews.
        
        Your will receive Aspect wise net sentiment of the device. you have to concentrate on top 4 Aspects.
        For that top 4 Aspect you will get top 2 keywords for each aspect. You will receive each keywords' contribution and +ve mention % and negative mention %
        You will receive reviews of that devices focused on these aspects and keywords.
        
        For Each Aspect
        
        Condition 1 : If the net sentiment is less than aspect sentiment, which means that particular aspect is driving the net sentiment Higher for that device. In this case provide why the aspect sentiment is lower than net sentiment.
        Condition 2 : If the net sentiment is high than aspect sentiment, which means that particular aspect is driving the net sentiment Lower for that device. In this case provide why the aspect sentiment is higher than net sentiment. 

            IMPORTANT: Use only the data provided to you and do not rely on pre-trained documents.

            Your summary should justify the above conditions and tie in with the net sentiment and aspect sentiment and keywords. Mention the difference between Net Sentiment and Aspect Sentiment (e.g., -2% or +2% higher than net sentiment) in your summary and provide justification.
            
            Your response should be : 
            
            For Each Aspect 
                    Net Sentiment of the device and aspect sentiment of that aspect of the device (Mention Performance, Aspect Sentiment) . 
                    Top Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed
                    Top 2nd Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed
                       Limit yourself to top 3 keywords and don't mention as top 1, top 2, top 3 and all. Mention them as pointers
                    Overall Summary
            
            IMPORTANT : Example Template :
            
            ALWAYS FOLLOW THIS TEMPLATE : Don't miss any of the below:
                                    
            Response : "BOLD ALL THE NUMBERS"
            
            IMPOPRTANT : Start with : "These are the 4 major aspects users commented about" and mention their review count contributions
               
                           These are the 4 major aspects users commented about:
                           
                        - Total Review for Vivobook Device is 1200
                        - Price: 13.82% of the reviews mentioned this aspect
                        - Performance: 11.08% of the reviews mentioned this aspect
                        - Software: 9.71% of the reviews mentioned this aspect
                        - Design: 7.37% of the reviews mentioned this aspect

                        Price:
                        - The aspect sentiment for price is 52.8%, which is higher than the net sentiment of 38.5%. This indicates that the aspect of price is driving the net sentiment higher for the Vivobook.
                        -  The top keyword for price is "buy" with a contribution of 28.07%. It has a positive percentage of 13.44% and a negative percentage of 4.48%.
                              - Users mentioned that the Vivobook offers good value for the price and is inexpensive.
                        - Another top keyword for price is "price" with a contribution of 26.89%. It has a positive percentage of 23.35% and a negative percentage of 0.24%.
                            - Users praised the affordable price of the Vivobook and mentioned that it is worth the money.

                        Performance:
                        - The aspect sentiment for performance is 36.5%, which is lower than the net sentiment of 38.5%. This indicates that the aspect of performance is driving the net sentiment lower for the Vivobook.
                        - The top keyword for performance is "fast" with a contribution of 18.24%. It has a positive percentage of 16.76% and a neutral percentage of 1.47%.
                            - Users mentioned that the Vivobook is fast and offers good speed.
                        - Another top keyword for performance is "speed" with a contribution of 12.06%. It has a positive percentage of 9.12% and a negative percentage of 2.06%.
                            - Users praised the speed of the Vivobook and mentioned that it is efficient.
                                            
                                            
                        lIKE THE ABOVE ONE EXPLAIN OTHER 2 ASPECTS

                        Overall Summary:
                        The net sentiment for the Vivobook is 38.5%, while the aspect sentiment for price is 52.8%, performance is 36.5%, software is 32.2%, and design is 61.9%. This indicates that the aspects of price and design are driving the net sentiment higher, while the aspects of performance and software are driving the net sentiment lower for the Vivobook. Users mentioned that the Vivobook offers good value for the price, is fast and efficient in performance, easy to set up and use in terms of software, and has a sleek and high-quality design.
  
                        Some Pros and Cons of the device, 
                        
                        
           IMPORTANT : Do not ever change the above template of Response. Give Spaces accordingly in the response to make it more readable.
           
           A Good Response should contains all the above mentioned poniters in the example. 
               1. Net Sentiment and The Aspect Sentiment
               2. Total % of mentions regarding the Aspect
               3. A Quick Summary of whether the aspect is driving the sentiment high or low
               4. Top Keyword: Gaming (Contribution: 33.22%, Positive: 68.42%, Negative: 6.32%)
                    - Users have praised the gaming experience on the Lenovo Legion, with many mentioning the smooth gameplay and high FPS.
                    - Some users have reported experiencing lag while gaming, but overall, the gaming performance is highly rated.
                    
                Top 3 Keywords : Their Contribution, Postitive mention % and Negative mention % and one ot two positive mentions regarding this keywords in each pointer
                
                5. IMPORTANT : Pros and Cons in pointers (overall, not related to any aspect)
                6. Overall Summary

                    
          Enhance the model’s comprehension to accurately interpret user queries by:
          Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.
          Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).
          Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references
          Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.
          Generate acurate response only, do not provide extra information.
            
            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\n Following is the previous conversation from User and Response, use it to get context only:""" + hist + """\n
                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\n
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0.0)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for detailed review summarization: {e}"
        return err

# Function to handle user queries using the existing vector store
def query_detailed_summary_devices(user_question, history, vector_store_path="faiss_index_Windows_116k"):
    try:
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        chain = get_conversational_chain_detailed_summary_devices(history)
        docs = vector_store.similarity_search(user_question)
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        return response["output_text"]
    except Exception as e:
        err = f"An error occurred while getting LLM response for detailed review summarization: {e}"
        return err


# In[56]:


def get_conversational_chain_detailed_devices(history):
    try:
        hist = """"""
        for i in history:
            hist = hist+"\nUser: "+i[0]
            if isinstance(i[1],pd.DataFrame):
                x = i[1].to_string()
            else:
                x = i[1]
            hist = hist+"\nResponse: "+ x
        prompt_template = """
        
        1. Your Job is to analyse the Net Sentiment Aspect wise sentiment and Key word regarding the aspect and summarize the reviews that user asks for utilizing the reviews and numbers you get. Use maximum use of the numbers and Justify the numbers using the reviews.
        
        Overall Sentiment is the Net Sentiment.
        
        Condition 1 : If the net sentiment is less than aspect sentiment, which means that particular aspect is driving the net sentiment Higher for that device. In this case provide why the aspect sentiment is lower than net sentiment.
        Condition 2 : If the net sentiment is high than aspect sentiment, which means that particular aspect is driving the net sentiment Lower for that device. In this case provide why the aspect sentiment is higher than net sentiment.
            
            You must be receiving keywords information. If there are any keywords which have more keyword_contribution mention that keyword with its contribution percentage and Positive, negative percentages. 
            Give the reviews summarized for this aspect 
            
            Give at least top 2 keyword information - (Contribution , Positive and Negative Percentage) and when summarizing reviews focus on those particular keywords.
            
            

            IMPORTANT: Use only the data provided to you and do not rely on pre-trained documents.

            Your summary should justify the above conditions and tie in with the net sentiment and aspect sentiment and keywords. Mention the difference between Net Sentiment and Aspect Sentiment (e.g., -2% or +2% higher than net sentiment) in your summary and provide justification.
            
            
            Your response should be : 
            Net Sentiment of the device and aspect sentiment of that aspect of the device (Mention Performance, Aspect Sentiment) . 
            Top Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed
            Top 2nd Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed
            Top 3rd Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed
               Limit yourself to top 3 keywords and don't mention as top 1, top 2, top 3 and all. Mention them as pointers
            Pros and 5 Cons
            Overall Summary
            
            IMPORTANT : Example Template :
            
            ALWAYS FOLLOW THIS TEMPLATE : Don't miss any of the below: 1st Template
                        
                        
            Response : "BOLD ALL THE NUMBERS"
            
            
                    Net Sentiment: 41.9%
                    Aspect Sentiment (Gaming): 53.1%

                    75% of the users commented about Gaming on this device. Gaming drives the sentiment high for Lenovo Legion

                    Top Keyword: Gaming (Contribution: 33.22%, Positive: 68.42%, Negative: 6.32%)
                    - Users have praised the gaming experience on the Lenovo Legion, with many mentioning the smooth gameplay and high FPS.
                    - Some users have reported experiencing lag while gaming, but overall, the gaming performance is highly rated.

                    Top 2nd Keyword: Game (Contribution: 33.22%, Positive: 60%, Negative: 8.42%)
                    - Users appreciate the ability to play various games on the Lenovo Legion, mentioning the enjoyable gaming experience.
                    - A few users have mentioned encountering some issues with certain games, but the majority have had a positive experience.

                    Top 3rd Keyword: Play (Contribution: 16.08%, Positive: 56.52%, Negative: 13.04%)
                    - Users mention the ease of playing games on the Lenovo Legion, highlighting the smooth gameplay and enjoyable experience.
                    - Some users have reported difficulties with certain games, experiencing lag or other performance issues.

                    Pros:
                    1. Smooth gameplay experience
                    2. High FPS and enjoyable gaming performance
                    3. Wide range of games available
                    4. Positive feedback on gaming experience
                    5. Ease of playing games

                    Cons:
                    1. Some users have reported lag or performance issues while gaming
                    2. Occasional difficulties with certain games

                    Overall Summary:
                    The net sentiment for the Lenovo Legion is 41.9%, while the aspect sentiment for gaming is 53.1%. This indicates that the gaming aspect is driving the net sentiment higher for the device. Users have praised the smooth gameplay, high FPS, and enjoyable gaming experience on the Lenovo Legion. The top keywords related to gaming contribute significantly to the aspect sentiment, with positive percentages ranging from 56.52% to 68.42%. However, there are some reports of lag and performance issues with certain games. Overall, the Lenovo Legion is highly regarded for its gaming capabilities, but there is room for improvement in addressing performance issues for a seamless gaming experience.
               
           IMPORTANT : Do not ever change the above template of Response. Give Spaces accordingly in the response to make it more readable.
           
           A Good Response should contains all the above mentioned poniters in the example. 
               1. Net Sentiment and The Aspect Sentiment
               2. Total % of mentions regarding the Aspect
               3. A Quick Summary of whether the aspect is driving the sentiment high or low
               4. Top Keyword: Gaming (Contribution: 33.22%, Positive: 68.42%, Negative: 6.32%)
                    - Users have praised the gaming experience on the Lenovo Legion, with many mentioning the smooth gameplay and high FPS.
                    - Some users have reported experiencing lag while gaming, but overall, the gaming performance is highly rated.
                    
                Top 3 Keywords : Their Contribution, Postitive mention % and Negative mention % and one ot two positive mentions regarding this keywords in each pointer
                
                5. Pros and Cons in pointers
                6. Overall Summary. 
                
        Only follow this template.

                    
          Enhance the model’s comprehension to accurately interpret user queries by:
          Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.
          Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).
          Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references
          Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.
          Generate acurate response only, do not provide extra information.
            
            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\n Following is the previous conversation from User and Response, use it to get context only:""" + hist + """\n
                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\n
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0.0)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for detailed review summarization: {e}"
        return err

# Function to handle user queries using the existing vector store
def query_detailed_devices(user_question, history, vector_store_path="faiss_index_Windows_116k"):
    try:
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        chain = get_conversational_chain_detailed_devices(history)
        docs = vector_store.similarity_search(user_question)
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        return response["output_text"]
    except Exception as e:
        err = f"An error occurred while getting LLM response for detailed review summarization: {e}"
        return err


# In[57]:


import numpy as np

def custom_color_gradient(val, vmin, vmax):
    green_hex = '#347c47'
    middle_hex = '#dcdcdc'
    lower_hex = '#b0343c'
    
    # Adjust the normalization to set the middle value as 0
    try:
        normalized_val = (val - vmin) / (vmax - vmin) if vmax != vmin else 0.5
    except ZeroDivisionError:
        normalized_val = 0.5
    
    normalized_val = (normalized_val - 0.5) * 2  # Scale and shift to set middle value as 0
    
    if normalized_val <= 0:
        # Interpolate between lower_hex and middle_hex for values <= 0
        r = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[1:3], 16), int(middle_hex[1:3], 16)]))
        g = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[3:5], 16), int(middle_hex[3:5], 16)]))
        b = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[5:7], 16), int(middle_hex[5:7], 16)]))
    else:
        # Interpolate between middle_hex and green_hex for values > 0
        r = int(np.interp(normalized_val, [0, 1], [int(middle_hex[1:3], 16), int(green_hex[1:3], 16)]))
        g = int(np.interp(normalized_val, [0, 1], [int(middle_hex[3:5], 16), int(green_hex[3:5], 16)]))
        b = int(np.interp(normalized_val, [0, 1], [int(middle_hex[5:7], 16), int(green_hex[5:7], 16)]))
    
    # Convert interpolated RGB values to hex format for CSS color styling
    hex_color = f'#{r:02x}{g:02x}{b:02x}'
    
    return f'background-color: {hex_color}; color: black;'


# In[58]:


def get_final_df_devices(aspects_list,device):
    final_df = pd.DataFrame()
    device = device
    aspects_list = aspects_list
    # Iterate over each aspect and execute the query
    for aspect in aspects_list:
        # Construct the SQL query for the current aspect
        query = f"""
        SELECT Keywords,
               COUNT(CASE WHEN Sentiment = 'Positive' THEN 1 END) AS Positive_Count,
               COUNT(CASE WHEN Sentiment = 'Negative' THEN 1 END) AS Negative_Count,
               COUNT(CASE WHEN Sentiment = 'Neutral' THEN 1 END) AS Neutral_Count,
               COUNT(*) as Total_Count
        FROM Devices_Sentiment_Data
        WHERE Aspect = '{aspect}' AND Product_Family LIKE '%{device}%'
        GROUP BY Keywords
        ORDER BY Total_Count DESC;
        """

        # Execute the query and get the result in 'key_df'
        key_df = ps.sqldf(query, globals())

        # Calculate percentages and keyword contribution
        total_aspect_count = key_df['Total_Count'].sum()
        key_df['Positive_Percentage'] = (key_df['Positive_Count'] / total_aspect_count) * 100
        key_df['Negative_Percentage'] = (key_df['Negative_Count'] / total_aspect_count) * 100
        key_df['Neutral_Percentage'] = (key_df['Neutral_Count'] / total_aspect_count) * 100
        key_df['Keyword_Contribution'] = (key_df['Total_Count'] / total_aspect_count) * 100

        # Drop the count columns
        key_df = key_df.drop(['Positive_Count', 'Negative_Count', 'Neutral_Count', 'Total_Count'], axis=1)

        # Add the current aspect to the DataFrame
        key_df['Aspect'] = aspect

        # Sort by 'Keyword_Contribution' and select the top 2 for the current aspect
        key_df = key_df.sort_values(by='Keyword_Contribution', ascending=False).head(2)

        # Append the results to the final DataFrame
        final_df = pd.concat([final_df, key_df], ignore_index=True)
        
    return final_df

#Reading the dataset
Copilot_Sentiment_Data  = pd.read_csv("New_CoPilot_Data.csv")


def Sentiment_Score_Derivation(value):
    try:
        if value == "positive":
            return 1
        elif value == "negative":
            return -1
        else:
            return 0
    except Exception as e:
        err = f"An error occurred while deriving Sentiment Score: {e}"
        return err    

#Deriving Sentiment Score and Review Count columns into the dataset
Copilot_Sentiment_Data["Sentiment_Score"] = Copilot_Sentiment_Data["Sentiment"].apply(Sentiment_Score_Derivation)
Copilot_Sentiment_Data["Review_Count"] = 1.0

overall_net_sentiment=round(sum(Copilot_Sentiment_Data["Sentiment_Score"])*100/sum(Copilot_Sentiment_Data["Review_Count"]),1)
overall_review_count=sum(Copilot_Sentiment_Data["Review_Count"])


# In[4]:


def convert_top_to_limit(sql):
    try:
        tokens = sql.upper().split()
        is_top_used = False

        for i, token in enumerate(tokens):
            if token == 'TOP':
                is_top_used = True
                if i + 1 < len(tokens) and tokens[i + 1].isdigit():
                    limit_value = tokens[i + 1]
                    # Remove TOP and insert LIMIT and value at the end
                    del tokens[i:i + 2]
                    tokens.insert(len(tokens), 'LIMIT')
                    tokens.insert(len(tokens), limit_value)
                    break  # Exit loop after successful conversion
                else:
                    raise ValueError("TOP operator should be followed by a number")

        return ' '.join(tokens) if is_top_used else sql
    except Exception as e:
        err = f"An error occurred while converting Top to Limit in SQL Query: {e}"
        return err


# In[5]:


def process_tablename(sql, table_name):
    try:
        x = sql.upper()
        query = x.replace(table_name.upper(), table_name)
        
        if '!=' in query or '=' in query:
            query = query.replace("!="," NOT LIKE ")
            query = query.replace("="," LIKE ")
            
            pattern = r"LIKE\s'([^']*)'"
            def add_percentage_signs(match):
                return f"LIKE '%{match.group(1)}%'"
            query = re.sub(pattern, add_percentage_signs, query)
        
        return query
    except Exception as e:
        err = f"An error occurred while processing table name in SQL query: {e}"
        return err


# In[6]:


def get_conversational_chain_quant(history):
    try:
        hist = """"""
        for i in history:
            hist = hist+"\nUser: "+i[0]
            if isinstance(i[1],pd.DataFrame):
                x = i[1].to_string()
            else:
                x = i[1]
            hist = hist+"\nResponse: "+x
        prompt_template = """
        
        If an user is asking for Summarize reviews of any product. Note that user is not seeking for reviews, user is seeking for all the Quantitative things of the product(Net Sentiment & Review Count) and also (Aspect wise sentiment and Aspect wise review count)
        So choose to Provide Net Sentiment and Review Count and Aspect wise sentiment and their respective review count and Union them in single table
        
        Example : If the user Quesiton is "Summarize reviews of CoPilot Produt"
        
        User seeks for net sentiment and aspect wise net sentiment of "CoPilot" Product and their respective review count in a single table

        Product - "CoPilot"
        Different Product_Family = Microsoft Copilot, Windows CoPilot, Copilot, Github Copilot , Copilot for Security, Copilot Pro, Copilot for Microsoft 365, Copilot for Mobile
        These are the different aspects : 'Interface', 'Connectivity', 'Privacy','Compatibility', 'Generic', 'Innovation', 'Reliability','Productivity', 'Price', 'Text Summarization/Generation','Code Generation', 'Ease of Use', 'Performance','Personalization/Customization','Accessibility'.

        CoPilot is Overall Product and Product_Family are different versions of CoPilot.
        
        IMPORTANT : IMPLEMENT 'LIKE' OPERATOR where every it is possible.
        
        Your response should be : Overall Sentiment is nothing but the net sentiment and overall review count of the product
        
                        Aspect Aspect_SENTIMENT REVIEW_COUNT
                    0 TOTAL 40 15000.0
                    1 Generic 31.8 2302.0
                    3 Productivity 58.9 397.0
                    4 Code Generation -1.2 345.0
                    5 Ease of Use 20.1 288.0
                    6 Interface -22.9 271.0
                    7 Connectivity -43.7 247.0
                    8 Compatibility -28.6 185.0
                    9 Innovation 52.9 170.0
                    10 Text Summarization/Generation 19.1 157.0
                    11 Reliability -44.7 152.0
                    12 Price 29.5 95.0
                    13 Customization/Personalization 18.9 90.0
                    14 Security/Privacy -41.3 75.0
                    15 Accessibility 16.7 6.0
                    
                    The Query has to be like this 
                    
                SELECT 'TOTAL' AS Aspect, 
                ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, 
                SUM(Review_Count) AS Review_Count
                FROM Copilot_Sentiment_Data
                WHERE Product_Family LIKE '%CoPilot for Mobile%'

                UNION

                SELECT Aspect, 
                ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, 
                SUM(Review_Count) AS Review_Count
                FROM Copilot_Sentiment_Data
                WHERE Product_Family LIKE '%CoPilot for Mobile%'
                GROUP BY Aspect

                ORDER BY Review_Count DESC

                    
                    
                IMPORTANT : if any particular Aspect "Code Generation" in user prompt:
                    

                        SELECT 'TOTAL' AS Aspect, 
                        ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, 
                        SUM(Review_Count) AS Review_Count
                        FROM Copilot_Sentiment_Data
                        WHERE Product_Family LIKE '%CoPilot for Mobile%'

                        UNION

                        SELECT Aspect, 
                        ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, 
                        SUM(Review_Count) AS Review_Count
                        FROM Copilot_Sentiment_Data
                        WHERE Product_Family LIKE '%CoPilot for Mobile%'
                        GROUP BY Aspect
                        HAVING Aspect LIKE %'Code Generation'%

                        ORDER BY Review_Count DESC
                
                
        This is aspect wise summary. If a user wants in Geography level 
        
        SELECT 'TOTAL' AS Geography, 
                        ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Net Sentiment, 
                        SUM(Review_Count) AS Review_Count
                        FROM Copilot_Sentiment_Data
                        WHERE Product_Family LIKE '%CoPilot for Mobile%'
                        
            UNION
        
        
            SELECT Geography, 
                        ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Net Sentiment, 
                        SUM(Review_Count) AS Review_Count
                        FROM Copilot_Sentiment_Data
                        WHERE Product_Family LIKE '%CoPilot for Mobile%'
                        GROUP BY Geography

                        ORDER BY Review_Count DESC
                        
            You shold respond like this. Same Goes for all the segregation
            
        It the user wants to compare features of 2 different ProductFamily, let's say "Github CoPilot" and "CoPilot for Microsoft 365". I want the aspect wise sentiment of both the devices in one table.
        
        IMPORTANT : Example USE THIS Query for COMPARISION -  "Compare different features of CoPilot for Mobile and GitHub CoPilot" 
        
        Query: 
        
                    SELECT 'GITHUB COPILOT' AS ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT
                    FROM Copilot_Sentiment_Data
                    WHERE PRODUCT_FAMILY LIKE '%GITHUB COPILOT%'

                    UNION All

                    SELECT ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT
                    FROM Copilot_Sentiment_Data
                    WHERE PRODUCT_FAMILY LIKE '%GITHUB COPILOT%'
                    GROUP BY ASPECT

                    UNION All

                    SELECT 'COPILOT FOR MICROSOFT 365' AS ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT
                    FROM Copilot_Sentiment_Data
                    WHERE PRODUCT_FAMILY LIKE '%COPILOT FOR MICROSOFT 365%'

                    UNION All

                    SELECT ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT
                    FROM Copilot_Sentiment_Data
                    WHERE PRODUCT_FAMILY LIKE '%COPILOT FOR MICROSOFT 365%'
                    GROUP BY ASPECT
                    
        IMPORTANT : Example USE THIS Query for COMPARISION Query - :  if only one aspect (Use always 'LIKE' OPERATOR) for ASPECT, GEOGRAPHY, PRODUCT_FAMILY, PRODUCT and so on while performing where condition. 
        
                    SELECT 'GITHUB COPILOT' AS ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT
                    FROM Copilot_Sentiment_Data
                    WHERE PRODUCT_FAMILY LIKE '%GITHUB COPILOT%'

                    UNION All

                    SELECT ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT
                    FROM Copilot_Sentiment_Data
                    WHERE PRODUCT_FAMILY LIKE '%GITHUB COPILOT%'
                    GROUP BY ASPECT
                    HAVING ASPECT LIKE '%CODE GENERATION%'

                    UNION All

                    SELECT 'COPILOT FOR MICROSOFT 365' AS ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT
                    FROM Copilot_Sentiment_Data
                    WHERE PRODUCT_FAMILY LIKE '%COPILOT FOR MICROSOFT 365%'

                    UNION All

                    SELECT ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT
                    FROM Copilot_Sentiment_Data
                    WHERE PRODUCT_FAMILY LIKE '%COPILOT FOR MICROSOFT 365%'
                    GROUP BY ASPECT
                    HAVING ASPECT LIKE '%CODE GENERATION%'
                    
                    
                    IMPORTANT : Do not use Order By here.
                    
            IMPORTANT : USE UNION ALL Everytime instead of UNION
                    
           If the user question is : Compare "Interface" feature of CoPilot for Mobile and GitHub CoPilot or "Compare the reviews for Github Copilot and Copilot for Microsoft 365 for Interface"
           
           DO NOT respond like :
           
           
            SELECT 'COPILOT FOR MOBILE' AS PRODUCT_FAMILY, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT 
            FROM Copilot_Sentiment_Data 
            WHERE PRODUCT_FAMILY LIKE '%COPILOT FOR MOBILE%' 
            AND ASPECT = 'Interface'

            UNION ALL

            SELECT 'GITHUB COPILOT' AS PRODUCT_FAMILY, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT 
            FROM Copilot_Sentiment_Data WHERE PRODUCT_FAMILY LIKE '%GITHUB COPILOT%' 
            AND ASPECT = 'Interface'
            
            
            Instead respond like : 
            
            
            SELECT 'COPILOT FOR MOBILE' AS ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT 
            FROM Copilot_Sentiment_Data 
            WHERE PRODUCT_FAMILY LIKE '%COPILOT FOR MOBILE%' 
            AND ASPECT = '%Interface%'

            UNION ALL

            SELECT 'GITHUB COPILOT' AS ASPECT, ROUND((SUM(SENTIMENT_SCORE) / SUM(REVIEW_COUNT)) * 100, 1) AS ASPECT_SENTIMENT, SUM(REVIEW_COUNT) AS REVIEW_COUNT 
            FROM Copilot_Sentiment_Data WHERE PRODUCT_FAMILY LIKE '%GITHUB COPILOT%' 
            AND ASPECT LIKE '%Interface%'
            
            IMPORTANT : Do not use Order By here.
            
            CHANGES MADE : USE OF LIKE OPERATOR, ASPECT as alias instead of Product_Family


        IMPORTANT : IT has to be Net sentiment and Aspect Sentiment. Create 2 SQL Query and UNION ALL them
        
        1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.
            2. There is only one table with table name Copilot_Sentiment_Data where each row is a user review. The table has 10 columns, they are:
                Review: Review of the Copilot Product
                Data_Source: From where is the review taken. It contains different retailers
                Geography: From which Country or Region the review was given. It contains different Geography.
                Title: What is the title of the review
                Review_Date: The date on which the review was posted
                Product: Corresponding product for the review. It contains following values: "COPILOT"
                Product_Family: Which version or type of the corresponding Product was the review posted for. Different Device Names
                Sentiment: What is the sentiment of the review. It contains following values: 'Positive', 'Neutral', 'Negative'.
                Aspect: The review is talking about which aspect or feature of the product. It contains following values: "Audio-Microphone","Software","Performance","Storage/Memory","Keyboard","Browser","Connectivity","Hardware","Display","Graphics","Battery","Gaming","Design","Ports","Price","Camera","Customer-Service","Touchpad","Account","Generic"
                Keyword: What are the keywords mentioned in the product
                Review_Count - It will be 1 for each review or each row
                Sentiment_Score - It will be 1, 0 or -1 based on the Sentiment.
                
        ONLY FOLLOW these column names
                
            3. Sentiment mark is calculated by sum of Sentiment_Score.
            4. Net sentiment is calculcated by sum of Sentiment_Score divided by sum of Review_Count. It should be in percentage. Example:
                    SELECT ((SUM(Sentiment_Score)*1.0)/(SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment 
                    FROM Copilot_Sentiment_Data
                    ORDER BY Net_Sentiment DESC
            5. Net sentiment across country or across region is sentiment mark of a country divided by total reviews of that country. It should be in percentage.
                Example to calculate net sentiment across country:
                    SELECT Geography, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment
                    FROM Copilot_Sentiment_Data
                    GROUP BY Geography
                    ORDER BY Net_Sentiment DESC
            6. Net Sentiment across a column "X" is calculcated by Sentiment Mark for each "X" divided by Total Reviews for each "X".
                Example to calculate net sentiment across a column "X":
                    SELECT X, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment
                    FROM Copilot_Sentiment_Data
                    GROUP BY X
                    ORDER BY Net_Sentiment DESC
            7. Distribution of sentiment is calculated by sum of Review_Count for each Sentiment divided by overall sum of Review_Count
                Example: 
                    SELECT Sentiment, SUM(ReviewCount)*100/(SELECT SUM(Review_Count) AS Reviews FROM Copilot_Sentiment_Data) AS Total_Reviews 
                    FROM Copilot_Sentiment_Data 
                    GROUP BY Sentiment
                    ORDER BY Total_Reviews DESC
            
            REMEBER TO USE LIKE OPERATOR whenever you use 'where' clause
                     
                    
            8. Convert numerical outputs to float upto 1 decimal point.
            9. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.
            10. Top Country is based on Sentiment_Score i.e., the Country which have highest sum(Sentiment_Score)
            11. Always use 'LIKE' operator whenever they mention about any Country. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.
            12. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.
            13. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.
            14. Important: Always show Net_Sentiment in Percentage upto 1 decimal point. Hence always make use of ROUND function while giving out Net Sentiment and Add % Symbol after it.
            15. Important: User can ask question about any categories including Aspects, Geograpgy, Sentiment etc etc. Hence, include the in SQL Query if someone ask it.
            16. Important: You Response should directly starts from SQL query nothing else.
            17. Important: Always use LIKE keyword instead of = symbol while generating SQL query.
            18. Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.
            19. Sort all Quantifiable outcomes based on review count
        \n Following is the previous conversation from User and Response, use it to get context only:""" + hist + """\n
                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\n
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for quantifiable review summarization: {e}"
        return err

#Function to convert user prompt to quantitative outputs for Copilot Review Summarization
def query_quant(user_question, history, vector_store_path="faiss_index_CopilotSample"):
    try:
        # Initialize the embeddings model
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        
        # Load the vector store with the embeddings model
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        
        # Rest of the function remains unchanged
        chain = get_conversational_chain_quant(history)
        docs = []
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        SQL_Query = response["output_text"]
        SQL_Query = convert_top_to_limit(SQL_Query)
        SQL_Query = process_tablename(SQL_Query,"Copilot_Sentiment_Data")
        # st.write(SQL_Query)
        data = ps.sqldf(SQL_Query, globals())
        data_1 = data
        html_table = data.to_html(index=False)
    #     return html_table
        return data_1
    except Exception as e:
        err = f"An error occurred while generating response for quantitative review summarization: {e}"
        return err


def get_conversational_chain_aspect_wise_detailed_summary(history):
    try:
        hist = """"""
        for i in history:
            hist = hist+"\nUser: "+i[0]
            if isinstance(i[1],pd.DataFrame):
                x = i[1].to_string()
            else:
                x = i[1]
            hist = hist+"\nResponse: "+ x
        prompt_template = """
        
       
        1. Your Job is to analyse the Net Sentiment, Aspect wise sentiment and Key word regarding the different aspect and summarize the reviews that user asks for utilizing the reviews and numbers you get. Use maximum use of the numbers and Justify the numbers using the reviews.
        
        
        Your will receive Aspect wise net sentiment of the Product. you have to concentrate on top 4 Aspects based on ASPECT_RANKING.
        For that top 4 Aspect you will get top 2 keywords for each aspect. You will receive each keywords' contribution and +ve mention % and negative mention %
        You will receive reviews of that devices focused on these aspects and keywords.

        For Each Aspect

        Condition 1 : If the net sentiment is less than aspect sentiment, which means that particular aspect is driving the net sentiment Higher for that Product. In this case provide why the aspect sentiment is lower than net sentiment.
        Condition 2 : If the net sentiment is high than aspect sentiment, which means that particular aspect is driving the net sentiment Lower for that Product. In this case provide why the aspect sentiment is higher than net sentiment. 

        IMPORTANT: Use only the data provided to you and do not rely on pre-trained documents.

            Your summary should justify the above conditions and tie in with the net sentiment and aspect sentiment and keywords. Mention the difference between Net Sentiment and Aspect Sentiment (e.g., -2% or +2% higher than net sentiment) in your summary and provide justification.

            Your response should be : 

            For Each Aspect 
                    Net Sentiment of the Product and aspect sentiment of that aspect of the Product (Mention Code Generation, Aspect Sentiment) . 
                    Top Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed
                    Top 2nd Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed
                       Limit yourself to top 3 keywords and don't mention as top 1, top 2, top 3 and all. Mention them as pointers
                    Overall Summary

            IMPORTANT : Example Template :

            ALWAYS FOLLOW THIS TEMPLATE : Don't miss any of the below:

            Response : "BOLD ALL THE NUMBERS"

            IMPOPRTANT : Start with : "These are the 4 major aspects users commented about" and mention their review count contributions. These top 4 shold be based on ASPECT_RANKING Column

                           These are the 4 top ranked aspects users commented about - IMPORTANT : These top 4 should be from Aspect Ranking:
                           
                           IMPORTANT : DO NOT CONSIDER GENERIC AS ONE OF THE ASPECTS

                        - Total Review for CoPilot for Mobile Product is 1200
                        - Code Generarion: 4.82% of the reviews mentioned this aspect
                        - Ease of Use: 6% of the reviews mentioned this aspect
                        - Compatibility: 9.71% of the reviews mentioned this aspect
                        - Interface: 7.37% of the reviews mentioned this aspect

                        Code Generation:
                        - The aspect sentiment for price is 52.8%, which is higher than the net sentiment of 38.5%. This indicates that the aspect of price is driving the net sentiment higher for the Vivobook.
                        -  The top keyword for price is "buy" with a contribution of 28.07%. It has a positive percentage of 13.44% and a negative percentage of 4.48%.
                              - Users mentioned that the Vivobook offers good value for the price and is inexpensive.
                        - Another top keyword for price is "price" with a contribution of 26.89%. It has a positive percentage of 23.35% and a negative percentage of 0.24%.
                            - Users praised the affordable price of the Vivobook and mentioned that it is worth the money.

                        Ease of use:
                        - The aspect sentiment for performance is 36.5%, which is lower than the net sentiment of 38.5%. This indicates that the aspect of performance is driving the net sentiment lower for the Vivobook.
                        - The top keyword for performance is "fast" with a contribution of 18.24%. It has a positive percentage of 16.76% and a neutral percentage of 1.47%.
                            - Users mentioned that the Vivobook is fast and offers good speed.
                        - Another top keyword for performance is "speed" with a contribution of 12.06%. It has a positive percentage of 9.12% and a negative percentage of 2.06%.
                            - Users praised the speed of the Vivobook and mentioned that it is efficient.


                        lIKE THE ABOVE ONE EXPLAIN OTHER 2 ASPECTS

                        Overall Summary:
                        The net sentiment for the Vivobook is 38.5%, while the aspect sentiment for price is 52.8%, performance is 36.5%, software is 32.2%, and design is 61.9%. This indicates that the aspects of price and design are driving the net sentiment higher, while the aspects of performance and software are driving the net sentiment lower for the Vivobook. Users mentioned that the Vivobook offers good value for the price, is fast and efficient in performance, easy to set up and use in terms of software, and has a sleek and high-quality design.

                        Some Pros and Cons of the device, 


           IMPORTANT : Do not ever change the above template of Response. Give Spaces accordingly in the response to make it more readable.

           A Good Response should contains all the above mentioned poniters in the example. 
               1. Net Sentiment and The Aspect Sentiment
               2. Total % of mentions regarding the Aspect
               3. A Quick Summary of whether the aspect is driving the sentiment high or low
               4. Top Keyword: "Usable" (Contribution: 33.22%, Positive: 68.42%, Negative: 6.32%)
                    - Users have praised the usable experience on the Cobilot for Mobile, with many mentioning the smooth usage and easy to use
                    - Some users have reported experiencing lag while not very great to use, but overall, the gaming Ease of use is highly rated.

                Top 3 Keywords : Their Contribution, Postitive mention % and Negative mention % and one ot two positive mentions regarding this keywords in each pointer

                5. IMPORTANT : Pros and Cons in pointers (overall, not related to any aspect)
                6. Overall Summary
                    
          Enhance the model’s comprehension to accurately interpret user queries by:
          Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.
          Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).
          Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references
          Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.
          Generate acurate response only, do not provide extra information.
            
            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\n Following is the previous conversation from User and Response, use it to get context only:""" + hist + """\n
                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\n
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0.0)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for detailed review summarization: {e}"
        return err

# Function to handle user queries using the existing vector store
def query_aspect_wise_detailed_summary(user_question, history, vector_store_path="faiss_index_CopilotSample"):
    try:
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        chain = get_conversational_chain_aspect_wise_detailed_summary(history)
        docs = vector_store.similarity_search(user_question)
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        return response["output_text"]
    except Exception as e:
        err = f"An error occurred while getting LLM response for detailed review summarization: {e}"
        return err


# In[8]:


def get_conversational_chain_detailed_compare():
    try:
        prompt_template = """
        
            IMPORTANT: Use only the data provided to you and do not rely on pre-trained documents.
            
        Product = Microsoft Copilot, Copilot in Windows 11, Copilot, Github Copilot , Copilot for Security, Copilot Pro, Copilot for Microsoft 365, Copilot for Mobile

        
        1. Your Job is to Summarize the user reviews and sentiment data you get as an input for 2 different Product that user mentioned.
        
        IMPORTANT : Mention their Positive and Negative of each Product for each aspects (What consumer feels) for each aspect.
        
        Example :
        
        Summary of CoPilot for Mobile and Github Copilot:
        

        Positive:

        CoPilot for Mobile has a high sentiment score for aspects such as Productivity, Ease of Use, and Accessibility.
        Users find it helpful for various tasks and appreciate its quick and informative responses.
        The app is praised for its usefulness in both work and everyday life.
        Negative:

        Some users have reported issues with Connectivity and Reliability, mentioning network problems and automatic closing of the app.
        There are concerns about Security/Privacy, with users mentioning the potential for data misuse.
        Compatibility with certain devices and interfaces is also mentioned as an area for improvement.
        Summary of GitHub CoPilot:

        Positive:

        GitHub CoPilot receives positive sentiment for aspects such as Interface and Innovation.
        Users appreciate its code generation capabilities and find it helpful for their programming tasks.
        The app is praised for its accuracy and ability to provide quick and relevant responses.
        Negative:

        Some users have reported issues with Reliability and Compatibility, mentioning problems with generating images and recognizing certain commands.
        There are concerns about Security/Privacy, with users mentioning the potential for data misuse.
        Users also mention the need for improvements in the app's interface and connectivity.
        Overall, both CoPilot for Mobile and GitHub CoPilot have received positive feedback for their productivity and code generation capabilities. However, there are areas for improvement such as connectivity, reliability, compatibility, and security/privacy. Users appreciate the ease of use and quick responses provided by both apps.
     
        
        IMPORTANT : If user asks to compare any specific aspects of two device, Give detailed summary like how much reviews is being spoken that aspect in each device, net sentiment and theire Pros and cons on that device (Very Detailed).
        
            Summary of Code Generation feature for CoPilot for Mobile:

                    Positive:

                    Users have praised the Code Generation feature of CoPilot for Mobile, with a high sentiment score of 8.5.
                    The feature is described as helpful and efficient in generating code that aligns with project standards and practices.
                    Users appreciate the convenience and time-saving aspect of the Code Generation feature.
                    Negative:

                    No negative reviews or concerns were mentioned specifically for the Code Generation feature of CoPilot for Mobile.
                    Summary of Code Generation feature for GitHub CoPilot:

                    Positive:

                    Users have a positive sentiment towards the Code Generation feature of GitHub CoPilot, with a sentiment score of 5.4.
                    The feature is described as a game-changer for developer productivity.
                    Users appreciate the ability of GitHub CoPilot to generate code that aligns with project standards and practices.
                    Negative:

                    No negative reviews or concerns were mentioned specifically for the Code Generation feature of GitHub CoPilot.
                    Overall, both CoPilot for Mobile and GitHub CoPilot have received positive feedback for their Code Generation capabilities. Users find the feature helpful, efficient, and a game-changer for developer productivity. No negative reviews or concerns were mentioned for the Code Generation feature of either product.
        
        Give a detailed summary for each aspects using the reviews. Use maximum use of the reviews. Do not use your pretrained data. Use the data provided to you. For each aspects. Summary should be 3 ro 4 lines

                    
          Enhance the model’s comprehension to accurately interpret user queries by:
          Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.
          Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).
          Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references
          Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.
          Generate acurate response only, do not provide extra information.
            
            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0.2)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for detailed review summarization: {e}"
        return err

# Function to handle user queries using the existing vector store
def query_detailed_compare(user_question, vector_store_path="faiss_index_CopilotSample"):
    try:
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        chain = get_conversational_chain_detailed_compare()
        docs = vector_store.similarity_search(user_question)
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        return response["output_text"]
    except Exception as e:
        err = f"An error occurred while getting LLM response for detailed review summarization: {e}"
        return err
        
        
        
def get_conversational_chain_generic():
    try:
        prompt_template = """
        
            IMPORTANT: Use only the data provided to you and do not rely on pre-trained documents.

            IMPORTANT : Verbatims is nothing but Review. if user asks for top reviews. Give some important reviews user mentioned.
            IMPORTANT : Different Product Families : List of Product_Families : ["Windows Copilot" , "Microsoft Copilot" , "Github Copilot" , "Copilot Pro" , "Copilot for Security" , "Copilot for Mobile", "Copilot for Microsoft 365"]
            
            Given a dataset with these columns: Review, Data_Source, Geography, Product_Family, Sentiment and Aspect (also called Features)
                      
                      Review: This column contains the opinions and experiences of users regarding different product families across geographies, providing insights into customer satisfaction or complaints and areas for improvement.
                      Data_Source: This column indicates the platform from which the user reviews were collected, such as Reddit, Play Store, App Store, Tech Websites, or YouTube videos.
                      Geography: This column lists the countries of the users who provided the reviews, allowing for an analysis of regional preferences and perceptions of the products.
                      Product_Family: This column identifies the broader category of products to which the review pertains, enabling comparisons and trend analysis across different product families.
                                      List of Product_Families : ["Windows Copilot" , "Microsoft Copilot" , "Github Copilot" , "Copilot Pro" , "Copilot for Security" , "Copilot for Mobile", "Copilot for Microsoft 365"]
                                      
                      If user asks to compare all the ProductFamilies - Compare the reveiws of each Product Families. and if user asks to compare aspects of mulitple Product Families. Do it
                      
                      
                      Sentiment: This column reflects the overall tone of the review, whether positive, negative, or neutral, and is crucial for gauging customer sentiment.
                      Aspect: This column highlights the particular features or attributes of the product that the review discusses, pinpointing areas of strength or concern.
                      
                      Perform the required task from the list below, as per user's query: 
                      1. Review Summarization - Summarize the reviews by filtering the relevant Aspect, Geography, Product_Family, Sentiment or Data_Source, only based on available reviews and their sentiments in the dataset.
                      2. Aspect Comparison - Provide a summarized comparison for each overlapping feature/aspect between the product families or geographies ,  only based on available user reviews and their sentiments in the dataset. Include pointers for each aspect highlighting the key differences between the product families or geographies, along with the positive and negative sentiments as per customer perception.
                      3. New Feature Suggestion/Recommendation - Generate feature suggestions or improvements or recommendations based on the frequency and sentiment of reviews and mentioned aspects and keywords. Show detailed responses to user queries by analyzing review sentiment, specific aspects, and keywords.
                      4. Hypothetical Reviews - Based on varying customer sentiments for the reviews in the existing dataset, generate hypothetical reviews for any existing feature updation or new feature addition in any device family across any geography, by simulating user reactions. Ensure to synthesize realistic reviews that capture all types of sentiments and opinions of users, by considering their hypothetical prior experience working with the new feature and generate output based on data present in dataset only. After these, provide solutions/remedies for negative hypothetical reviews. 
                      
                      Enhance the model’s comprehension to accurately interpret user queries by:
                      Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.
                      Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).
                      Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references
                      Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.
                      Generate acurate response only, do not provide extra information.
            
            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.
            
            IMPORTANT : if user asks for Compare different aspects of different Product Families - Give Pros and cons for each aspect of each ProductFamilies
            IMPORTANT : If user asks summary for each Product Families, Give one line summary for each product name, mentioning their Pros and Cons.
            
            If the user question is not in the data provided. Just mention - "Not in the context". 
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0.2)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for detailed review summarization: {e}"
        return err

# Function to handle user queries using the existing vector store
def query_detailed_generic(user_question, vector_store_path="faiss_index_CopilotSample"):
    try:
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        chain = get_conversational_chain_generic()
        docs = vector_store.similarity_search(user_question)
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        return response["output_text"]
    except Exception as e:
        err = f"An error occurred while getting LLM response for detailed review summarization: {e}"
        return err


# In[9]:


def get_conversational_chain_detailed_summary(history):
    try:
        hist = """"""
        for i in history:
            hist = hist+"\nUser: "+i[0]
            if isinstance(i[1],pd.DataFrame):
                x = i[1].to_string()
            else:
                x = i[1]
            hist = hist+"\nResponse: "+ x
        
        prompt_template = f"""
        Important: You are provided with an input dataset, also you know that the Overall Net Sentiment for all reviews is {overall_net_sentiment} and total reviews are {overall_review_count}.
        Your Job is to analyse the Net Sentiment, Geo-Wise wise sentiment of particular product or Product-wise sentiment and summarize the reviews that user asks, utilizing the reviews and numbers you get from the input data. Ensure maximum utility of the numbers and justify them using the reviews.
        For example, if the data you receive is Geography wise net sentiment data for a particular product-
        First give an overall summary of the data like, from which Geography most of the reviews are and which geographies have the most and least net sentiment, etc. Then, with the help of the reviews, summarize reviews from each geography and provide Pros and Cons about that Product in each Geography. 

        Your response should follow the below templates, based on input data:
            1. Geography wise summary for a particular product -
                Based on the provided sentiment data for Github CoPilot reviews from different geographies, here is a summary:
 
                - Total Sentiment: The overall net sentiment for Github CoPilot is 6.9, based on a total of 3,735 reviews.
 
                - 1st Geography: The net sentiment for reviews with unknown geography is 5.2, based on 2,212 reviews. ('Driving Net sentiment High' if net sentiment for this Geography is greater than {overall_net_sentiment}, else 'Driving Net sentiment Low')
 
                    Overall summary of the Product from that Geography in 5 to 6 lines
                    Give Some Pros and Cons of the Product from the reviews from this Geography
 
                - 2nd Geography: The net sentiment for reviews from the United States is 8.1, based on 1,358 reviews.  ('Driving Net sentiment High' if net sentiment for this Geography is greater than {overall_net_sentiment}, else 'Driving Net sentiment Low')
 
                    Overall summary of the Product from that Geography in 5 to 6 lines
                    Give Some Pros and Cons of the Product from the reviews from this Geography
 
                - 3rd Geography: The net sentiment for reviews from Japan is 20.0, based on 165 reviews.  ('Driving Net sentiment High' if net sentiment for this Geography is greater than {overall_net_sentiment}, else 'Driving Net sentiment Low')
 
                    Overall summary of the Product from that Geography in 5 to 6 lines
                    Give Some Pros and Cons of the Product from the reviews from this Geography

            2. Product Family wise summary -

                Based on the provided sentiment data for different Product Families, here is a summary:
 
                - Total Sentiment: The overall net sentiment for all the reviews is {overall_net_sentiment}, based on a total of {overall_review_count} reviews.
 
                - Copilot for Mobile: The net sentiment for reviews of Copilot for Mobile is 29.5, based on 18,559 reviews. (Mention 'Driving Net sentiment High' if net sentiment for this Product Family is greater than {overall_net_sentiment}, else mention 'Driving Net sentiment Low')
 
                   Overall summary of Copilot for Mobile: Users have highly positive reviews for Copilot for Mobile, praising its functionality and ease of use. They find it extremely helpful in their mobile development tasks and appreciate the regular updates and additions to the toolkit.
 
                - Copilot: The net sentiment for reviews of Copilot is -8.0, based on 10,747 reviews. (Mention 'Driving Net sentiment High' if net sentiment for this Product Family is greater than {overall_net_sentiment}, else mention 'Driving Net sentiment Low')
 
                   Overall summary of Copilot: Reviews for Copilot are mostly negative, with users expressing dissatisfaction with its performance and suggesting improvements. They mention issues with suggestions and accuracy, leading to frustration and disappointment.
 
                - Copilot in Windows 11: The net sentiment for reviews of Copilot in Windows 11 is 8.3, based on 6,107 reviews. (Mention 'Driving Net sentiment High' if net sentiment for this Product Family is greater than {overall_net_sentiment}, else mention 'Driving Net sentiment Low')
 
                   Overall summary of Copilot in Windows 11: Users have positive reviews for Copilot in Windows 11, highlighting its compatibility and ease of use. They find it helpful in their development tasks and appreciate the integration with the Windows 11 operating system.
 
                - Copilot Pro: The net sentiment for reviews of Copilot Pro is 12.7, based on 5,075 reviews. (Mention 'Driving Net sentiment High' if net sentiment for this Product Family is greater than {overall_net_sentiment}, else mention 'Driving Net sentiment Low')
 
                   Overall summary of Copilot Pro: Users have highly positive reviews for Copilot Pro, praising its advanced features and capabilities. They find it valuable for their professional development tasks and appreciate the additional functionalities offered in the Pro version.
 
                - Github Copilot: The net sentiment for reviews of Github Copilot is 6.9, based on 3,735 reviews. (Mention 'Driving Net sentiment High' if net sentiment for this Product Family is greater than {overall_net_sentiment}, else mention 'Driving Net sentiment Low')
 
                   Overall summary of Github Copilot: Users have generally positive reviews for Github Copilot, mentioning its usefulness in their coding tasks. They appreciate the AI-powered suggestions and find it helpful in improving their productivity.
 
                - Microsoft Copilot: The net sentiment for reviews of Microsoft Copilot is -2.4, based on 2,636 reviews. (Mention 'Driving Net sentiment High' if net sentiment for this Product Family is greater than {overall_net_sentiment}, else mention 'Driving Net sentiment Low')
 
                   Overall summary of Microsoft Copilot: Reviews for Microsoft Copilot are mostly negative, with users expressing dissatisfaction with its performance and suggesting improvements. They mention issues with accuracy and compatibility, leading to frustration and disappointment.
 
                - Copilot for Security: The net sentiment for reviews of Copilot for Security is 9.4, based on 2,038 reviews. (Mention 'Driving Net sentiment High' if net sentiment for this Product Family is greater than {overall_net_sentiment}, else mention 'Driving Net sentiment Low')
 
                   Overall summary of Copilot for Security: Users have positive reviews for Copilot for Security, mentioning its effectiveness in enhancing security measures. They find it valuable for protecting sensitive information and appreciate the various customization options offered.
 
                Copilot for Microsoft 365: The net sentiment for reviews of Copilot for Microsoft 365 is 4.0, based on 2,031 reviews. (Mention 'Driving Net sentiment High' if net sentiment for this Product Family is greater than {overall_net_sentiment}, else mention 'Driving Net sentiment Low')
 
                   Overall summary of Copilot for Microsoft 365: Reviews for Copilot for Microsoft 365 are mostly neutral, with users expressing mixed opinions about its functionality. Some find it helpful in their Microsoft 365 tasks, while others mention limitations and suggest improvements.
 
                Based on the sentiment data, it can be observed that Copilot for Mobile, Copilot in Windows 11, Copilot Pro, and Copilot for Security have higher net sentiments, indicating positive user experiences. On the other hand, Copilot, Microsoft Copilot, and Copilot for Microsoft 365 have lower net sentiments, indicating negative or mixed user experiences.
 
        Important: Modify the Geography, Product Family or Product names in the prompt as per given dataset values            
        Important: Enhance the model’s comprehension to accurately interpret user queries by:
          - Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.
          - Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).
          - Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references]
         Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\n Following is the previous conversation from User and Response, use it to get context only:""" + hist + """\n
                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\n
        Context:\n {context}?\n
        Question: \n{question}\n
 
        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0.3)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for detailed review summarization: {e}"
        return err

# Function to handle user queries using the existing vector store
def query_detailed_summary(dataframe_as_dict,user_question, history, vector_store_path="faiss_index_CopilotSample"):
    try:
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        chain = get_conversational_chain_detailed_summary(history)
        docs = vector_store.similarity_search(user_question)
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        return response["output_text"]
    except Exception as e:
        err = generate_chart_insight_llm(dataframe_as_dict)
        return err
    

def generate_chart_insight_llm(user_question):
    try:
        prompt_template = """
        1.Based on the data available in the input, generate meaningful insights using the numbers and summarize them. 
        2.Ensure to include all possible insights and findings that can be extracted, which reveals vital trends and patterns in the data. 
        3.Share the findings or insights in a format which makes more sense to business oriented users, and can generate vital action items for them. 
        4.If any recommendations are possible based on the insights, share them as well - primarily focusing on the areas of concern.
        5.For values like Net_Sentiment score, positive values indicate positive overall sentiment, negative values indicate negative overall sentiment and 0 value indicate neutral overall sentiment. For generating insights around net_sentiment feature, consider this information.
        IMPORTANT: If the maximum numerical value is less than or equal to 100, then the numerical column is indicating percentage results - therefore while referring to numbers in your insights, add % at the end of the number.
        IMPORTANT : Use the data from the input only and do not give information from pre-trained data.
        IMPORTANT : Dont provide any prompt message written here in the response, this is for your understanding purpose
           
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature=0.3)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        response = chain({"input_documents": [], "question": user_question}, return_only_outputs=True)
        #st.write("\n\n",response["output_text"])
        return response["output_text"]
            
    except Exception as e:
        err = "Apologies, unable to generate insights based on the provided input data. Kindly refine your search query and try again!"
        return err
        
    
       

def make_desired_df(data):
    try:
        # Create DataFrame from the dictionary
        df = pd.DataFrame(data)
        
        # Ensure the necessary columns are present
        if 'ASPECT_SENTIMENT' not in df.columns or 'REVIEW_COUNT' not in df.columns or 'ASPECT' not in df.columns:
            raise ValueError("Input data must contain 'ASPECT', 'ASPECT_SENTIMENT' and 'REVIEW_COUNT' columns")
        
        df = df[df['ASPECT_SENTIMENT'] != 0]
        df = df[df['ASPECT'] != 'Generic']

#         df = df[(df['ASPECT_SENTIMENT'] != 0) & (df['ASPECT'] != 'TOTAL') & (df['ASPECT'] != 'Generic')]

        # Compute min and max values for normalization
        min_sentiment = df['ASPECT_SENTIMENT'].min(skipna=True)
        max_sentiment = df['ASPECT_SENTIMENT'].max(skipna=True)
        min_review_count = df['REVIEW_COUNT'].min(skipna=True)
        max_review_count = df['REVIEW_COUNT'].max(skipna=True)

        # Apply min-max normalization for ASPECT_SENTIMENT
        df['NORMALIZED_SENTIMENT'] = df.apply(
            lambda row: (row['ASPECT_SENTIMENT'] - min_sentiment) / (max_sentiment - min_sentiment)
            if pd.notnull(row['ASPECT_SENTIMENT'])
            else None,
            axis=1
        )

        # Apply min-max normalization for REVIEW_COUNT
        df['NORMALIZED_REVIEW_COUNT'] = df.apply(
            lambda row: (row['REVIEW_COUNT'] - min_review_count) / (max_review_count - min_review_count)
            if pd.notnull(row['REVIEW_COUNT'])
            else None,
            axis=1
        )

        # Calculate the aspect ranking based on normalized values
        weight_for_sentiment = 1
        weight_for_review_count = 3
        
#         df['ASPECT_RANKING'] = df.apply(
#             lambda row: (weight_for_review_count * row['NORMALIZED_REVIEW_COUNT'] * (1 - weight_for_review_count*row['NORMALIZED_SENTIMENT'])
#             if pd.notnull(row['NORMALIZED_SENTIMENT']) and pd.notnull(row['NORMALIZED_REVIEW_COUNT'])
#             else None),
#             axis=1
        df['ASPECT_RANKING'] = df.apply(
            lambda row: (weight_for_sentiment * (1 - row['NORMALIZED_SENTIMENT']) + weight_for_review_count * row['NORMALIZED_REVIEW_COUNT'])
            if pd.notnull(row['NORMALIZED_SENTIMENT']) and pd.notnull(row['NORMALIZED_REVIEW_COUNT'])
            else None,
            axis=1
        )
        
        # fg
        # Assign integer rankings based on the 'Aspect_Ranking' score
        df['ASPECT_RANKING'] = df['ASPECT_RANKING'].rank(method='max', ascending=False, na_option='bottom').astype('Int64')

        # Sort the DataFrame based on 'Aspect_Ranking' to get the final ranking
        df_sorted = df.sort_values(by='ASPECT_RANKING')
        df_sorted = df_sorted.drop(columns=['NORMALIZED_SENTIMENT', 'NORMALIZED_REVIEW_COUNT'])
        
        # Extract and display the net sentiment and overall review count
        # try:
            # total_row = df[df['ASPECT'] == 'TOTAL'].iloc[0]
            # net_sentiment = str(int(total_row["ASPECT_SENTIMENT"])) + '%'
            # overall_review_count = int(total_row["REVIEW_COUNT"])
        # except (ValueError, TypeError, IndexError):
            # try:
                # total_row = df[df['ASPECT'] == device_a].iloc[0]
                # net_sentiment = str(int(total_row["ASPECT_SENTIMENT"])) + '%'
                # overall_review_count = int(total_row["REVIEW_COUNT"])
            # except:
                # try:
                    # total_row = df[df['ASPECT'] == device_a].iloc[0]
                    # net_sentiment = str(int(total_row["ASPECT_SENTIMENT"])) + '%'
                    # overall_review_count = int(total_row["REVIEW_COUNT"])
                # except:
                    # st.write("Failed")
                    # net_sentiment = total_row["ASPECT_SENTIMENT"]
                    # overall_review_count = total_row["REVIEW_COUNT"]

        # st.write(f"Net Sentiment: {net_sentiment}")
        # st.write(f"Overall Review Count: {overall_review_count}")

        return df_sorted
    except Exception as e:
        st.error(f"Error in make_desired_df: {str(e)}")
        return pd.DataFrame()


import numpy as np

def custom_color_gradient(val, vmin=-100, vmax=100):
    green_hex = '#347c47'
    middle_hex = '#dcdcdc'
    lower_hex = '#b0343c'
    
    # Adjust the normalization to set the middle value as 0
    try:
        # Normalize the value to be between -1 and 1 with 0 as the midpoint
        normalized_val = (val - vmin) / (vmax - vmin) * 2 - 1
    except ZeroDivisionError:
        normalized_val = 0
    
    if normalized_val <= 0:
        # Interpolate between lower_hex and middle_hex for values <= 0
        r = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[1:3], 16), int(middle_hex[1:3], 16)]))
        g = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[3:5], 16), int(middle_hex[3:5], 16)]))
        b = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[5:7], 16), int(middle_hex[5:7], 16)]))
    else:
        # Interpolate between middle_hex and green_hex for values > 0
        r = int(np.interp(normalized_val, [0, 1], [int(middle_hex[1:3], 16), int(green_hex[1:3], 16)]))
        g = int(np.interp(normalized_val, [0, 1], [int(middle_hex[3:5], 16), int(green_hex[3:5], 16)]))
        b = int(np.interp(normalized_val, [0, 1], [int(middle_hex[5:7], 16), int(green_hex[5:7], 16)]))
    
    # Convert interpolated RGB values to hex format for CSS color styling
    hex_color = f'#{r:02x}{g:02x}{b:02x}'
    
    return f'background-color: {hex_color}; color: black;'


# In[11]:


def get_final_df(aspects_list,device):
    final_df = pd.DataFrame()
    device = device
    aspects_list = aspects_list

    # Iterate over each aspect and execute the query
    for aspect in aspects_list:
        # Construct the SQL query for the current aspect
        query = f"""
        SELECT Keywords,
               COUNT(CASE WHEN Sentiment = 'positive' THEN 1 END) AS Positive_Count,
               COUNT(CASE WHEN Sentiment = 'negative' THEN 1 END) AS Negative_Count,
               COUNT(CASE WHEN Sentiment = 'neutral' THEN 1 END) AS Neutral_Count,
               COUNT(*) as Total_Count
        FROM Copilot_Sentiment_Data
        WHERE Aspect = '{aspect}' AND Product_Family LIKE '%{device}%'
        GROUP BY Keywords
        ORDER BY Total_Count DESC;
        """

        # Execute the query and get the result in 'key_df'
        key_df = ps.sqldf(query, globals())

        # Calculate percentages and keyword contribution
        total_aspect_count = key_df['Total_Count'].sum()
        key_df['Positive_Percentage'] = (key_df['Positive_Count'] / total_aspect_count) * 100
        key_df['Negative_Percentage'] = (key_df['Negative_Count'] / total_aspect_count) * 100
        key_df['Neutral_Percentage'] = (key_df['Neutral_Count'] / total_aspect_count) * 100
        key_df['Keyword_Contribution'] = (key_df['Total_Count'] / total_aspect_count) * 100

        # Drop the count columns
        key_df = key_df.drop(['Positive_Count', 'Negative_Count', 'Neutral_Count', 'Total_Count'], axis=1)

        # Add the current aspect to the DataFrame
        key_df['Aspect'] = aspect

        # Sort by 'Keyword_Contribution' and select the top 2 for the current aspect
        key_df = key_df.sort_values(by='Keyword_Contribution', ascending=False).head(2)

        # Append the results to the final DataFrame
        final_df = pd.concat([final_df, key_df], ignore_index=True)
        
    return final_df


def classify(user_question):
    try:
        prompt_template = """
            Given an input, classify it into one of two categories:
            
            Product = Microsoft Copilot, Copilot in Windows 11, Copilot, Github Copilot , Copilot for Security, Copilot Pro, Copilot for Microsoft 365, Copilot for Mobile
            
            1stFlow: The user_question should focus more on one Product (How does that Product Perform or Summarize that Product reviews ) Then choose the 1st flow.
            2ndFlow: User is seeking any other information like geography wise performance or any quantitative numbers like what is net sentiment for different product families then categorize as 2ndFlow. It should even choose 2nd flow, if it asks for Aspect wise sentiment of one Product.
            
            Example - Geography wise how products are performing or seeking for information across different product families/products.
            What is net sentiment for any particular product/geography
            
        IMPORTANT : Only share the classified category name, no other extra words.
        IMPORTANT : Don't categorize into 1stFlow or 2ndFlow based on number of products, categorize based on the type of question the user is asking
        Input: User Question
        Output: Category (1stFlow or 2ndFlow)
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0.0)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        response = chain({"input_documents": [], "question": user_question}, return_only_outputs=True)
        if "1stflow" in response["output_text"].lower():
            return "1"
        elif "2ndflow" in response["output_text"].lower():
            return "2"
        else:
            return "Others"+"\nPrompt Identified as:"+response["output_text"]+"\n"
    except Exception as e:
        err = f"An error occurred while generating conversation chain for identifying nature of prompt: {e}"
        return err

# In[13]:


#Function to generate chart based on output dataframe 

def generate_chart(df):
    global full_response
    # Determine the data types of the columns
    try:
        df=df.drop('Impact',axis=1)
    except:
        pass
    num_cols = df.select_dtypes(include=['number']).columns
    cat_cols = df.select_dtypes(include=['object', 'category']).columns
    date_cols = df.select_dtypes(include=['datetime']).columns
    
    if len(num_cols)>0:
        for i in range(len(num_cols)):
            df[num_cols[i]]=round(df[num_cols[i]],1)
            
    if len(df.columns)>3:
        try:
            cols_to_drop = [col for col in df.columns if df[col].nunique() == 1]
            df.drop(columns=cols_to_drop, inplace=True)
        except:
            pass
        
        df=df.iloc[:, :3]
        
    num_cols = df.select_dtypes(include=['number']).columns
    cat_cols = df.select_dtypes(include=['object', 'category']).columns
    date_cols = df.select_dtypes(include=['datetime']).columns
    #st.write(num_cols,cat_cols,len(num_cols),len(cat_cols))
    # Simple heuristic to determine the most suitable chart
    if len(df.columns)==2:
        
        if len(num_cols) == 1 and len(cat_cols) == 0:

            plt.figure(figsize=(10, 6))
            sns.histplot(df[num_cols[0]], kde=True)
            plt.title(f"Frequency Distribution of '{num_cols[0]}'")
            st.pyplot(plt)
            # try:
                # chart = plt.to_html()
                # full_response += chart
            # except:
                # st.write("Error in converting chart to html")


        elif len(num_cols) == 2:
   
            plt.figure(figsize=(10, 6))
            sns.scatterplot(x=df[num_cols[0]], y=df[num_cols[1]])
            plt.title(f"Distribution of '{num_cols[0]}' across '{cat_cols[0]}'")
            st.pyplot(plt)
            # try:
                # chart = plt.to_html()
                # full_response += chart
            # except:
                # st.write("Error in converting chart to html")


        elif len(cat_cols) == 1 and len(num_cols) == 1:
            if df[cat_cols[0]].nunique() <= 5 and df[num_cols[0]].sum()>=99 and df[num_cols[0]].sum()<=101:
                fig = px.pie(df, names=cat_cols[0], values=num_cols[0], title=f"Distribution of '{num_cols[0]}' across '{cat_cols[0]}'")
                st.plotly_chart(fig)
                # try:
                    # chart = fig.to_html()
                    # full_response += chart
                # except:
                    # st.write("Error in converting chart to html")

            else:
                num_categories=df[cat_cols[0]].nunique()
                width = 800
                height = max(600,num_categories*50)
                
                bar=px.bar(df,x=num_cols[0],y=cat_cols[0],title=f"Distribution of '{num_cols[0]}' across '{cat_cols[0]}'",text=num_cols[0])
                bar.update_traces(textposition='outside', textfont_size=12)
                bar.update_layout(width=width, height=height)
                st.plotly_chart(bar)
                # try:
                    # chart = bar.to_html()
                    # full_response += chart
                # except:
                    # st.write("Error in converting chart to html")


        elif len(cat_cols) == 2:

            plt.figure(figsize=(10, 6))
            sns.countplot(x=df[cat_cols[0]], hue=df[cat_cols[1]], data=df)
            plt.title(f"Distribution of '{num_cols[0]}' across '{cat_cols[0]}'")
            st.pyplot(plt)
            # try:
                # chart = plt.to_html()
                # full_response += chart
            # except:
                # st.write("Error in converting chart to html")


        elif len(date_cols) == 1 and len(num_cols) == 1:
   
            plt.figure(figsize=(10, 6))
            sns.lineplot(x=df[date_cols[0]], y=df[num_cols[0]], data=df)
            plt.title(f"Distribution of '{num_cols[0]}' across '{cat_cols[0]}'")
            st.pyplot(plt)
            # try:
                # chart = plt.to_html()
                # full_response += chart
            # except:
                # st.write("Error in converting chart to html")


        else:
            sns.pairplot(df)
            st.pyplot(plt)
            
    
            
    elif len(df.columns)==3 and len(cat_cols)>=1:
        
        col_types = df.dtypes

#         cat_col = None
#         num_cols = []

#         for col in df.columns:
#             if col_types[col] == 'object' and df[col].nunique() == len(df):
#                 categorical_col = col
#             elif col_types[col] in ['int64', 'float64']:
#                 num_cols.append(col)
#         st.write(cat_cols,num_cols,len(cat_cols),len(num_cols))
#         st.write(type(cat_cols))
        # Check if we have one categorical and two numerical columns
        if len(cat_cols)==1 and len(num_cols) == 2:
#             df[cat_cols[0]]=df[cat_cols[0]].astype(str)
#             df[cat_cols[0]]=df[cat_cols[0]].fillna('NA')
            
            
            if df[cat_cols[0]].nunique() <= 5 and df[num_cols[0]].sum()>=99 and df[num_cols[0]].sum()<=101:
                fig = px.pie(df, names=cat_cols[0], values=num_cols[0], title=f"Distribution of '{num_cols[0]}' across '{cat_cols[0]}'")
                fig2 = px.pie(df, names=cat_cols[0], values=num_cols[1], title=f"Distribution of '{num_cols[1]}' across '{cat_cols[0]}'")
                st.plotly_chart(fig)
                st.plotly_chart(fig2)
                # try:
                    # chart = fig.to_html()
                    # full_response += chart
                # except:
                    # st.write("Error in converting chart to html")
                # try:
                    # chart = fig2.to_html()
                    # full_response += chart
                # except:
                    # st.write("Error in converting chart to html")
                

            else:
                num_categories=df[cat_cols[0]].nunique()
                width = 800
                height = max(600,num_categories*50)
                
                bar=px.bar(df,x=num_cols[0],y=cat_cols[0],title=f"Distribution of '{num_cols[0]}' across '{cat_cols[0]}'",text=num_cols[0])
                bar.update_traces(textposition='outside', textfont_size=12)
                bar.update_layout(width=width, height=height)
                st.plotly_chart(bar)
                
                bar2=px.bar(df,x=num_cols[1],y=cat_cols[0],title=f"Distribution of '{num_cols[1]}' across '{cat_cols[0]}'",text=num_cols[1])
                bar2.update_traces(textposition='outside', textfont_size=12)
                bar2.update_layout(width=width, height=height)
                st.plotly_chart(bar2)
                # try:
                    # chart = bar.to_html()
                    # full_response += chart
                # except:
                    # st.write("Error in converting chart to html")
                # try:
                    # chart = bar2.to_html()
                    # full_response += chart
                # except:
                    # st.write("Error in converting chart to html")
                
        elif len(cat_cols)==2 and len(num_cols) == 1:
            df[cat_cols[0]]=df[cat_cols[0]].astype(str)
            df[cat_cols[1]]=df[cat_cols[1]].astype(str)
            df[cat_cols[0]]=df[cat_cols[0]].fillna('NA')
            df[cat_cols[1]]=df[cat_cols[1]].fillna('NA')
            
            list_cat=df[cat_cols[0]].unique()
            st.write("\n\n")
            for i in list_cat:
                st.markdown(f"*** {i} OVERVIEW ***")
                df_fltr=df[df[cat_cols[0]]==i]
                df_fltr=df_fltr.drop(cat_cols[0],axis=1)
                num_categories=df_fltr[cat_cols[1]].nunique()
#                 num_categories2=df[cat_cols[1]].nunique()
                height = 600 #max(80,num_categories2*20)
                width=800

                bar=px.bar(df_fltr,x=num_cols[0],y=cat_cols[1],title=f"Distribution of '{num_cols[0]}' across '{cat_cols[1]}'",text=num_cols[0],color=cat_cols[1])
                bar.update_traces(textposition='outside', textfont_size=12)
                bar.update_layout(width=width, height=height)
                st.plotly_chart(bar)
                # try:
                    # chart = bar.to_html()
                    # full_response += chart
                # except:
                    # st.write("Error in converting chart to html")
                



def get_conversational_chain_detailed_deepdive(history):
    try:
        hist = """"""
        for i in history:
            hist = hist+"\nUser: "+i[0]
            if isinstance(i[1],pd.DataFrame):
                x = i[1].to_string()
            else:
                x = i[1]
            hist = hist+"\nResponse: "+ x
        prompt_template = """
        
        1. Your Job is to analyse the Net Sentiment Aspect wise sentiment and Key word regarding the aspect and summarize the reviews that user asks for utilizing the reviews and numbers you get. Use maximum use of the numbers and Justify the numbers using the reviews.
        
        Overall Sentiment is the Net Sentiment.
        
        Condition 1 : If the net sentiment is less than aspect sentiment, which means that particular aspect is driving the net sentiment Lower for that Product. In this case provide why the aspect sentiment is lower than net sentiment by using reviews as justificaton point.
        Condition 2 : If the net sentiment is high than aspect sentiment, which means that particular aspect is driving the net sentiment Higher for that Product. In this case provide why the aspect sentiment is higher than net sentiment by using reviews as justificaton point.
            
            You must be receiving keywords information. If there are any keywords which have more keyword_contribution mention that keyword with its contribution percentage and Positive, negative percentages. 
            Give the reviews summarized for this aspect 
            
            Give at least top 2 keyword information - (Contribution , Positive and Negative Percentage) and when summarizing reviews focus on those particular keywords.
            

            IMPORTANT: Use only the data provided to you and do not rely on pre-trained documents.

            Your summary should justify the above conditions and tie in with the net sentiment and aspect sentiment and keywords. Mention the difference between Net Sentiment and Aspect Sentiment (e.g., -2% or +2% higher than net sentiment) in your summary and provide justification.
            
            
            Example Template :
            
            IMPORTANT : ALWAYS FOLLOW THIS TEMPLATE : Don't miss any of the below: 1st Template

                    Net Sentiment: 41.9%
                    Aspect Sentiment (Interface): 53.1%

                    75% of the users commented about Interface of this Product. Interface drives the sentiment high for CoPilot for Mobile Product

                    Top Keyword: User-Friendly (Contribution: 33.22%, Positive: 68.42%, Negative: 6.32%)
                    - Users have praised the User-Friendly experience on the CoPilot for Mobile, with many mentioning the good layout and interfacce
                    - Some users have reported experiencing lag while gaming, but overall, the gaming performance is highly rated.

                    Top 2nd Keyword: Graphical (Contribution: 33.22%, Positive: 60%, Negative: 8.42%)
                    - Users appreciate the ability to play various games on the Lenovo Legion, mentioning the enjoyable gaming experience.
                    - A few users have mentioned encountering some issues with certain games, but the majority have had a positive experience.

                    Top 3rd Keyword: Play (Contribution: 16.08%, Positive: 56.52%, Negative: 13.04%)
                    - Users mention the ease of playing games on the Lenovo Legion, highlighting the smooth gameplay and enjoyable experience.
                    - Some users have reported difficulties with certain games, experiencing lag or other performance issues.

                    Pros:
                    1. Smooth gameplay experience
                    2. High FPS and enjoyable gaming performance
                    3. Wide range of games available
                    4. Positive feedback on gaming experience
                    5. Ease of playing games

                    Cons:
                    1. Some users have reported lag or performance issues while gaming
                    2. Occasional difficulties with certain games

                    Overall Summary:
                    The net sentiment for the CoPilot for Mobile is 41.9%, while the aspect sentiment for Inteface is 53.1%. This indicates that the Interface aspect is driving the net sentiment higher for the product. Users have praised the smooth gameplay, high FPS, and enjoyable gaming experience on the Lenovo Legion. The top keywords related to gaming contribute significantly to the aspect sentiment, with positive percentages ranging from 56.52% to 68.42%. However, there are some reports of lag and performance issues with certain games. Overall, the Lenovo Legion is highly regarded for its gaming capabilities, but there is room for improvement in addressing performance issues for a seamless gaming experience.
               
           IMPORTANT : Do not ever change the above template of Response. Give Spaces accordingly in the response to make it more readable.
           
           A Good Response should contains all the above mentioned poniters in the example. 
               1. Net Sentiment and The Aspect Sentiment
               2. Total % of mentions regarding the Aspect
               3. A Quick Summary of whether the aspect is driving the sentiment high or low
               4. Top Keyword: Gaming (Contribution: 33.22%, Positive: 68.42%, Negative: 6.32%)
                    - Users have praised the gaming experience on the Lenovo Legion, with many mentioning the smooth gameplay and high FPS.
                    - Some users have reported experiencing lag while gaming, but overall, the gaming performance is highly rated.
                    
                Top 3 Keywords : Their Contribution, Postitive mention % and Negative mention % and one ot two positive mentions regarding this keywords in each pointer
                
                5. Pros and Cons in pointers
                6. Overall Summary. 
                
        IMPORTANT : Only follow this template. Donot miss out any poniters from the above template

                    
          Enhance the model’s comprehension to accurately interpret user queries by:
          Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.
          Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).
          Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references
          Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.
          Generate acurate response only, do not provide extra information.
            
            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\n Following is the previous conversation from User and Response, use it to get context only:""" + hist + """\n
                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\n
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2023-12-01-preview',
            temperature = 0.0)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for detailed review summarization: {e}"
        return err

# Function to handle user queries using the existing vector store
def query_detailed_deepdive(user_question, history, vector_store_path="faiss_index_CopilotSample"):
    try:
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        chain = get_conversational_chain_detailed_deepdive(history)
        docs = vector_store.similarity_search(user_question)
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        return response["output_text"]
    except Exception as e:
        err = f"An error occurred while getting LLM response for detailed review summarization: {e}"
        return err
        
        
def get_conversational_chain_quant_classify2():
    try:
#         hist = """"""
#         for i in history:
#             hist = hist+"\nUser: "+i[0]
#             if isinstance(i[1],pd.DataFrame):
#                 x = i[1].to_string()
#             else:
#                 x = i[1]
#             hist = hist+"\nResponse: "+x

#################################################################################################################################################################################################################################################
        prompt_template = """

                Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.
                There is only one table with table name Copilot_Sentiment_Data where each row is a user review. The table has 10 columns, they are:
                        Review: Review of the Copilot Product
                        Data_Source: From where is the review taken. It contains different retailers
                        Geography: From which Country or Region the review was given. It contains different Geography. The user might mention Geography as Geography/Geographies/Regions
                        Title: What is the title of the review
                        Review_Date: The date on which the review was posted
                        Product: Corresponding product for the review. It contains the value "COPILOT"
                        Product_Family: Which version or type of the corresponding Product was the review posted for. Different Product Families are "Windows Copilot" , "Microsoft Copilot" , "Github Copilot" , "Copilot Pro" , "Copilot for Security" , "Copilot for Mobile", "Copilot for Microsoft 365"
                        Sentiment: What is the sentiment of the review. It contains following values: 'Positive', 'Neutral', 'Negative'.
                        Aspect: The review is talking about which aspect or feature of the product. It contains following values: "Audio-Microphone","Software","Performance","Storage/Memory","Keyboard","Browser","Connectivity","Hardware","Display","Graphics","Battery","Gaming","Design","Ports","Price","Camera","Customer-Service","Touchpad","Account","Generic"
                        Keyword: What are the keywords mentioned in the product
                        Review_Count - It will be 1 for each review or each row
                        Sentiment_Score - It will be 1, 0 or -1 based on the Sentiment.

                    1. If the user asks for count of column 'X', the query should be like this:
                            SELECT COUNT(DISTINCT ('X')) 
                            FROM Copilot_Sentiment_Data
                    2. If the user asks for count of column 'X' for different values of column 'Y', the query should be like this:
                            SELECT 'Y', COUNT(DISTINCT('X')) AS Total_Count
                            FROM Copilot_Sentiment_Data 
                            GROUP BY 'Y'
                            ORDER BY TOTAL_COUNT DESC
                    3. If the user asks for Net overall sentiment the query should be like this:
                            SELECT ((SUM(Sentiment_Score))/(SUM(Review_Count))) * 100 AS Net_Sentiment,  SUM(Review_Count) AS Review_Count
                            FROM Copilot_Sentiment_Data
                            ORDER BY Net_Sentiment DESC

                    4. If the user asks for Net Sentiment for column "X", the query should be exactly like this: 

                            SELECT X, ((SUM(Sentiment_Score)) / (SUM(Review_Count))) * 100 AS Net_Sentiment, SUM(Review_Count) AS Review_Count
                            FROM Copilot_Sentiment_Data
                            GROUP BY X
                            ORDER BY Review_Count DESC


                    5. If the user asks for overall review count, the query should be like this:
                            SELECT SUM(Review_Count) 
                            FROM Copilot_Sentiment_Data
                    6. If the user asks for review distribution across column 'X', the query should be like this:
                            SELECT 'X', SUM(Review_Count) * 100 / (SELECT SUM(Review_Count) FROM Copilot_Sentiment_Data) AS Review_Distribution
                            FROM Copilot_Sentiment_Data 
                            GROUP BY 'X'
                            ORDER BY Review_Distribution DESC
                    7. If the user asks for column 'X' Distribution across column 'Y', the query should be like this: 
                            SELECT 'Y', SUM('X') * 100 / (SELECT SUM('X') AS Reviews FROM Copilot_Sentiment_Data) AS Distribution_PCT
                            FROM Copilot_Sentiment_Data 
                            GROUP BY 'Y'
                            ORDER BY Distribution_PCT DESC

                    Important: While generating SQL query to calculate net_sentiment across column 'X' and 'Y', if 'Y' has less distinct values, keep your response like this - SELECT 'Y','X', ((SUM(Sentiment_Score)) / (SUM(Review_Count))) * 100 AS Net_Sentiment, SUM(Review_Count) AS Review_Count FROM Copilot_Sentiment_Data GROUP BY 'Y','X'
                    
                    Important: Always replace '=' operator with LIKE keyword and add '%' before and after filter value for single or multiple WHERE conditions in the generated SQL query . For example, if the query is like - 'SELCT * FROM Copilot_Sentiment_Data WHERE PRODUCT='ABC' AND GEOGRAPHY='US' ORDER BY Review_Count' , you should modify the query and share the output like this - 'SELCT * FROM Copilot_Sentiment_Data WHERE PRODUCT LIKE '%ABC%' AND GEOGRAPHY LIKE '%US%' ORDER BY Review_Count'

                    Important: Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.
                    Important: Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.
                    Important: You Response should directly start from SQL query nothing else.
                    Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.

                Context:\n {context}?\n
                Question: \n{question}\n

                Answer:
                """
########################################################################################################################################
#########################################################################################
        

        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2024-03-01-preview',
            temperature = 0.1)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for quantifiable review summarization: {e}"
        return err

#Function to convert user prompt to quantitative outputs for Copilot Review Summarization
def query_quant_classify2(user_question, vector_store_path="faiss_index_CopilotSample"):
    try:
        # Initialize the embeddings model
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        
        # Load the vector store with the embeddings model
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        
        # Rest of the function remains unchanged
        chain = get_conversational_chain_quant_classify2()
        docs = []
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        SQL_Query = response["output_text"]
        # st.write(SQL_Query)
        SQL_Query = convert_top_to_limit(SQL_Query)
        SQL_Query = process_tablename(SQL_Query,"Copilot_Sentiment_Data")
        # st.write(SQL_Query)
        data = ps.sqldf(SQL_Query, globals())
        data_1 = data
        html_table = data.to_html(index=False)
    #     return html_table
        return data_1
    except Exception as e:
        err = f"An error occurred while generating response for quantitative review summarization: {e}"
        return err



def quantifiable_data(user_question):
    try:
        #st.write("correct_func")
        response = query_quant_classify2(user_question)
        
        return response
    except Exception as e:
        err = f"An error occurred while generating quantitative review summarization: {e}"
        return err


def identify_prompt(user_question):
    try:
        # Define the prompt template
        prompt_template = """
        Given a user prompt about customer reviews for products (Windows, Surface) and various different features, classify the prompt into one of three categories:

        1. Summarization: This prompt seeks a summary or analysis of the reviews for only one particular device expressed in words.
            (e.g., "Summarize the reviews of Device A", 
                  "What features are most praised in Device B reviews?",
                  "Summarize the reviews of Device A with particular feature (e.g., battery life, Performance, etc.)",
                  "Generalize the reviews of Device A?", etc.)
           

        2. Comparison: This prompt seeks a comparison between exactly 2 devices based on reviews, and it should only be an overall comparison, not specific to any feature or aspect.
            (e.g., "Compare Device A and Device B based on reviews")
            
        3. Other: This prompt does not fit into the Summarization or Comparison categories or includes more than two devices in the user prompt.
            This category includes comparisons between 2 devices with a particular aspect or feature comparison, and devices expressed in words might be separated with commas (',') or 'and'.
            (e.g., "Which product has better battery life according to reviews among Device A, Device B, Device C?",
                   "Compare Device A, Device B, Device C",
                   "Compare Device A and Device B in terms of battery life",
                   "Give the performance comparison among Device A, Device B, Device C",
                   "Summarize the key features of Device A, Device B, Device C",
                   "Can you provide a summary of the main features mentioned in Device A and Device B?")
            IMPORTANT:
                1. If the user prompt includes more than 2 devices for comparison, it should be handled in the Other category.
                2. If the user prompt includes exactly 2 devices for comparision but asks about a particular aspect or feature, it should be handled in the Other category.
                3. If the user prompt includes more than one device for device summary then it should be handled in the Other category.

        

        Input: User prompt about customer reviews
        Output: Category (Summarization, Comparison, or Other)
        Context:
        {context}
        Question:
        {question}

        Answer:
        """


        # Initialize the model and prompt template
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2024-03-01-preview',temperature = 0)
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)

        # Get the response from the model
        response = chain({"input_documents": [], "question": user_question}, return_only_outputs=True)
        print(response)

        # Determine the output category based on the response
        if "summarization" in response["output_text"].lower():
            return "summarization"
        elif "comparison" in response["output_text"].lower():
            return "comparison"
        else:
            return "other"
    except Exception as e:
        print(f"An error occurred while identifying the prompt category: {e}")
        return None
        
def get_conversational_chain_devices_generic():
    try:
        prompt_template = """
        
            IMPORTANT: Use only the data provided to you and do not rely on pre-trained documents.

            INMPORTANT : Verbatims is nothing but Review. if user asks for top reviews. Give some important reviews user mentioned.
            
            Given a dataset with these columns: Review, Data_Source, Geography, Product_Family, Sentiment and Aspect (also called Features)
                      
                      Review: This column contains the opinions and experiences of users regarding different product families across geographies, providing insights into customer satisfaction or complaints and areas for improvement.
                      Data_Source: This column indicates the platform from which the user reviews were collected, such as Amazon, Flipkart, Bestbuy.
                      Geography: This column lists the countries of the users who provided the reviews, allowing for an analysis of regional preferences and perceptions of the products.
                      Product_Family: This column identifies the broader category of products to which the review pertains, enabling comparisons and trend analysis across different product families.
                      Sentiment: This column reflects the overall tone of the review, whether positive, negative, or neutral, and is crucial for gauging customer sentiment.
                      Aspect: This column highlights the particular features or attributes of the product that the review discusses, pinpointing areas of strength or concern.
                      
                      Perform the required task from the list below, as per user's query: 
                      1. Review Summarization - Summarize the reviews by filtering the relevant Aspect, Geography, Product_Family, Sentiment or Data_Source, only based on available reviews and their sentiments in the dataset.
                      2. Aspect Comparison - Provide a summarized comparison for each overlapping feature/aspect between the product families or geographies ,  only based on available user reviews and their sentiments in the dataset. Include pointers for each aspect highlighting the key differences between the product families or geographies, along with the positive and negative sentiments as per customer perception.
                      3. New Feature Suggestion/Recommendation - Generate feature suggestions or improvements or recommendations based on the frequency and sentiment of reviews and mentioned aspects and keywords. Show detailed responses to user queries by analyzing review sentiment, specific aspects, and keywords.
                      4. Hypothetical Reviews - Based on varying customer sentiments for the reviews in the existing dataset, generate hypothetical reviews for any existing feature updation or new feature addition in any device family across any geography, by simulating user reactions. Ensure to synthesize realistic reviews that capture all types of sentiments and opinions of users, by considering their hypothetical prior experience working with the new feature and generate output based on data present in dataset only. After these, provide solutions/remedies for negative hypothetical reviews. 
                      
                      IMPORTANT: Give as much as details as possible. Minimun number of Words should be 300 words atleat you can have more as well.
                      
                      Enhance the model’s comprehension to accurately interpret user queries by:
                      Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.
                      Understanding product family names even when written in reverse order or missing connecting words such as HP Laptop 15, Lenovo Legion 5 15 etc
                      Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references
                      Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.
                      Generate acurate response only, do not provide extra information.
            
            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.
            
            If the user question is not in the data provided. Just mention - "Sorry! I do not have sufficient reviews for mentioned product.". 
            But do not restrict yourself in responding to the user questions like 'hello', 'Hi' and basic chat question
        Context:\n {context}?\n
        Question: \n{question}\n

        Answer:
        """
        prompt = PromptTemplate(template=prompt_template, input_variables=["context", "question"])
        model = AzureChatOpenAI(
            azure_deployment="Verbatim-Synthesis",
            api_version='2024-03-01-preview',temperature = 0.2)
        
        chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
        return chain
    except Exception as e:
        err = f"An error occurred while getting conversation chain for detailed review summarization: {e}"
        return err
      
def query_devices_detailed_generic(user_question, vector_store_path="faiss_index_Windows_116k"):
    try:
        embeddings = AzureOpenAIEmbeddings(azure_deployment="Embedding-Model")
        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)
        chain = get_conversational_chain_generic()
        docs = vector_store.similarity_search(user_question)
        response = chain({"input_documents": docs, "question": user_question}, return_only_outputs=True)
        return response["output_text"]
    except Exception as e:
        err = f"An error occurred while getting LLM response for detailed review summarization: {e}"
        return err

def split_table(data,device_a,device_b):
    # Initialize empty lists for each product
    copilot_index = data[data["ASPECT"] == str(device_b).upper()].index[0]
    if copilot_index != 0:
        device_a_table = data.iloc[:copilot_index]
        device_b_table = data.iloc[copilot_index:]
    else:
        copilot_index = data[data["ASPECT"] == str(device_a).upper()].index[0]
        device_a_table = data.iloc[:copilot_index]
        device_b_table = data.iloc[copilot_index:]

    return device_a_table, device_b_table
    
    
from openai import AzureOpenAI

client = AzureOpenAI(
    api_key=os.getenv("672370cd6ca440f2a0327351d4f4d2bf"),  
    api_version="2024-02-01",
    azure_endpoint = os.getenv("https://hulk-openai.openai.azure.com/")
    )
    
deployment_name='SurfaceGenAI'

context_Prompt = """

As a data scientist analyzing the sentiment data of the Copilot product, we have developed several features to facilitate the synthesis of consumer review sentiment data. 

There are 4 features : “Summarization”, “Quantifiable and visualization”, “Comparison”, “Generic”

If user is seeking for any questions related to net sentiment and aspect sentiment choose Quantifiable and visualization
    Eg: Net Sentiment of any Product Families, Aspect wise sentiment of any Product Families etc, Aspect wise sentiment of different ProductFamilies etc., (It can works for different ProductFamilies)

 [Here, ‘Device’ is synonymous with ‘Product_Family’.] We have created the following list of features:

note : Verbatims means raw reviews

List of aspects : ['Interface', 'Connectivity', 'Privacy','Compatibility', 'Generic', 'Innovation', 'Reliability','Productivity', 'Price', 'Text Summarization/Generation','Code Generation', 'Ease of Use', 'Performance','Personalization/Customization']
List of Product_Families : ["Windows Copilot" , "Microsoft Copilot" , "Github Copilot" , "Copilot Pro" , "Copilot for Security" , "Copilot for Mobile", "Copilot for Microsoft 365"]

1. Quantifiable and visualization - This feature enables the retrieval and visualization of data for any requested product/feature.
    It can answer queries like “Which is the best device?” (Based on Net Sentiment) or “Which device is most commonly commented on?” (Based on Review Count), among others. What is the net sentiment and aspect sentiment of a Product, what is the [Aspect] sentiment of any Product? and Question like that.
    
    It can be Examples :  "Give me the net sentiment/aspect sentiment of any Product", "Give me the net sentiment/aspect sentiment of any Product across geographies", "Give me the net sentiment/aspect sentiment of differnt Product Families" and so on.
    These above Questions are the examples which can come under this category.
    
    IMPORTANT : Whenever user seeks for Quantifiable/Visualization choose Quantifiable and visualization.


2. Generic - This category allows users to ask general questions about any Product, such as the Pros and Cons, common complaints associated with a device, and the top verbatims (Reviews) mentioned in product reviews, etc.
    IMPORTANT : Compare the Interface of all the CoPilot Products (As there is no specific mention of any two device, it should be in Generic)


3. Summarization of reviews for a specific Product - This feature provides a summary of the most frequently mentioned aspects of a device, offering both quantifiable and detailed sentiment analysis. (Don't choose this functionc, if the user asks for basic pros and cons, top verbatims and all).
    Remember this Summarization function is for only one Product - So choose summarization if user specifies any one ProductFamily in the user query. If user question contains lot of Products to summarize. Choose Generic.


4. Comparison - This feature allows users to compare two different Products based on user reviews. Remember that this function only does comparision for 2 different Products.
    IMPORTANT : If the user Question mentions 3 or more different Product Families. Then don't give it as Comparision . Make it as Generic. Example : Compare Github Copilot, Wnidows CopIlot and CoPilot Pro. In this case it should choose "Generic", as 3 Product were mentioned in this user query.

    
IMPORTANT:
    1. In Comparision feature that we have built, we have the capability just to compare only two products. So Choose "Comparison" Only if there are 2 devices mentioned. If there are 2 or more devices, then go with "Generic"
    2. Do not choose Comparision just by seeing the word comparision. 
    3. Compare Interface Aspect of different Product Families - Go with Generic in this case (as user is asking for all the Product families not 2 specific devices to compare)
    4. Compare different features of Windows Copilot, Github Copilot, Microsoft 365 Copilot - Go with Generic in this case (as user is asking for 3 different Product families and no just 2 specific devices to compare)

If user question just mentioned verbatims for devices. Provide Generic
Your task is to categorize incoming user queries into one of these four features.
Your response should be one of the following:

“Summarization”
“Quantifiable and visualization”
“Comparison”
“Generic”
"""

def finetuned_prompt(user_question):
    global context_Prompt
    # Append the new question to the context
    full_prompt = context_Prompt + "\nQuestion:\n" + user_question + "\nAnswer:"
    # Send the query to Azure OpenAI
    response = client.completions.create(
        model=deployment_name,
        prompt=full_prompt,
        max_tokens=500,
        temperature=0
    )
    
    # Extract the generated SQL query
    user_query = response.choices[0].text.strip()
    
    # Update context with the latest interaction
    context_Prompt += "\nQuestion:\n" + user_question + "\nAnswer:\n" + user_query
    
    return user_query   
    
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
os.environ["AZURE_OPENAI_API_KEY"] = "672370cd6ca440f2a0327351d4f4d2bf"
os.environ["AZURE_OPENAI_ENDPOINT"] = "https://hulk-openai.openai.azure.com/"


client = AzureOpenAI(
    api_key=os.getenv("672370cd6ca440f2a0327351d4f4d2bf"),  
    api_version="2024-02-01",
    azure_endpoint = os.getenv("https://hulk-openai.openai.azure.com/")
    )
    
deployment_name='SurfaceGenAI'

context = """
You are given a list of product names and a mapping file that maps these names to their corresponding product families. Your task is two-fold:

CoPilot is the Product and it has following Product_Families:
List of Product_Families : ["Windows Copilot" , "Microsoft Copilot" , "Github Copilot" , "Copilot Pro" , "Copilot for Security" , "Copilot for Mobile", "Copilot for Microsoft 365"]
IMPORTANT : Features/Aspects are : ['Interface', 'Connectivity', 'Privacy','Compatibility', 'Generic', 'Innovation', 'Reliability','Productivity', 'Price', 'Text Summarization/Generation','Code Generation', 'Ease of Use', 'Performance','Personalization/Customization']

1. Rephrase any input sentence by replacing the product name with its correct product family according to the mapping file.
2. Modify the input sentence into one of the specified Features.

Features and sample prompts:
    1. Comparison - "Compare different features for [Product 1] and [Product 2]"
       Example:
        Input - Compare reviews of Copilot for Microsoft 365 and Copilot for Mobile"
        Output - "Compare different features for Copilot  and [Product 2]"
    2. Summarization of reviews - "Summarize the reviews for [Product] / Analyze consumer reviews for [Product]"
    3. Asking net sentiment/aspect sentiment/ review count  - "What is the net sentiment and review count for [product 1]". It might also be "What is the best device?" (Based on Net Sentiment) , "What is the device user mostly comment about" (Based on Review Count) and all of these
        Start with "What" for all the Quantifiable Questions. And whenever user asks across Geographies/across different ProductFamilies. Use "across different Geographies"/"across different ProductFamilies"
        3.1. It can be across any categories such as Product Family, Geography, Data Source etc. Hence repharse the input sentence accordingly.
        3.2 What ever quantifiable Question user asks for start with "What is the" and rephrase the sentence accordingly.
    4. Asking net sentiment or review count for multiple Products - "What is the net sentiment and review count of different Product families?". Do not enter multiple product names in this case.

IMPORTAT : Net Sentiment is different and aspect sentiment is different. Don't rephrase those questions. If the user askes aspect wise sentiment, let it be there as aspect wise sentiment.

Mapping file:

Copilot in Windows 11 -> Windows Copilot
Copilot for Security -> Copilot for Security
Copilot Pro -> Copilot Pro
Microsoft Copilot -> Microsoft Copilot
Copilot for Microsoft 365 -> Copilot for Microsoft 365
Github Copilot -> Github Copilot
Copilot for Mobile -> Copilot for Mobile
Windows Copilot -> Windows Copilot
Copilot for Windows -> Windows Copilot
Copilot Windows -> Windows Copilot
Win Copilot -> Windows Copilot
Security Copilot -> Copilot for Security
Privacy Copilot -> Copilot for Security
M365 -> Copilot for Microsoft 365
Microsoft 365 -> Copilot for Microsoft 365
Office copilot -> Copilot for Microsoft 365
Github -> Github Copilot
MS Office -> Copilot for Microsoft 365
MSOffice -> Copilot for Microsoft 365
Microsoft Office -> Copilot for Microsoft 365
Office Product -> Copilot for Microsoft 365
Mobile -> Copilot for Mobile
App -> Copilot for Mobile
ios -> Copilot for Mobile
apk -> Copilot for Mobile
Copilot -> Microsoft Copilot

IMPORTANT: If the input sentence mentions a device(Laptop or Desktop) instead of Copilot, keep the device name as it is.

Rephrase the following input with the correct product family and modify it to fit one of the specified functionalities.


Please rephrase and modify the following input sentences with the correct product family names and into one of the specified formats:

[List of input sentences]
"""

def rephrased_prompt(user_question):
    global context
    # Append the new question to the context
    full_prompt = context + "\nQuestion:\n" + user_question + "\nAnswer:"
    
    # Send the query to Azure OpenAI
    response = client.completions.create(
        model=deployment_name,
        prompt=full_prompt,
        max_tokens=500,
        temperature=0
    )
    
    # Extract the generated SQL query
    user_query = response.choices[0].text.strip()
    # st.write(user_query)
    
    # Update context with the latest interaction
    context += "\nQuestion:\n" + user_question + "\nAnswer:\n" + user_query
    
    return user_query
    
def user_ques(user_question, raw_question):
    global full_response
    if user_question:
        device_list = Copilot_Sentiment_Data['Product_Family'].to_list()
        sorted_device_list_desc = sorted(device_list, key=lambda x: len(x), reverse=True)

    # Convert user question and product family names to lowercase for case-insensitive comparison
        user_question_lower = user_question.lower()

        # Initialize variables for device names
        device_a = None
        device_b = None

        # Search for product family names in the user question
        for device in sorted_device_list_desc:
            if device.lower() in user_question_lower:
                if device_a is None:
                    device_a = device
                else:
                    if device_a != device and device != 'Copilot':
                        device_b = device
                        break# Found both devices, exit the loop

        # st.write(device_a)
        # st.write(device_b)

        if device_a != None and device_b != None:
            try:
                col1,col2 = st.columns(2) 
                data = query_quant(user_question,[])
                # st.write(data)
                device_a_table,device_b_table = split_table(data,device_a,device_b)   
                with col1:
                    device_a_table = device_a_table.dropna(subset=['ASPECT_SENTIMENT'])
                    device_a_table = device_a_table[~device_a_table["ASPECT"].isin(["Generic", "Account", "Customer-Service", "Browser"])]
                    device_a_table = device_a_table[device_a_table['ASPECT_SENTIMENT'] != 0]
                    device_a_table = device_a_table[device_a_table['ASPECT'] != 'Generic']
                    device_a_table = device_a_table.sort_values(by='REVIEW_COUNT', ascending=False)
                    styled_df_a = device_a_table.style.applymap(lambda x: custom_color_gradient(x, int(-100), int(100)), subset=['ASPECT_SENTIMENT'])
                    data_filtered = device_a_table[(device_a_table["ASPECT"] != device_a) | (device_a_table["ASPECT"] != device_b) & (device_a_table["ASPECT"] != 'Generic')]
                    top_four_aspects = data_filtered.head(4)
                    c = device_a_table.to_dict(orient='records')
                    st.dataframe(styled_df_a)
                    first_table = styled_df_a.to_html(index = False)
                    full_response += first_table

                with col2:

                    device_b_table = device_b_table.dropna(subset=['ASPECT_SENTIMENT'])
                    device_b_table = device_b_table[~device_b_table["ASPECT"].isin(["Generic", "Account", "Customer-Service", "Browser"])]
                    device_b_table = device_b_table[device_b_table['ASPECT_SENTIMENT'] != 0]
                    device_b_table = device_b_table[device_b_table['ASPECT'] != 'Generic']
                    device_b_table = device_b_table.sort_values(by='REVIEW_COUNT', ascending=False)
                    styled_df_b = device_b_table.style.applymap(lambda x: custom_color_gradient(x, int(-100), int(100)), subset=['ASPECT_SENTIMENT'])
                    data_filtered = device_b_table[(device_b_table["ASPECT"] != device_b) | (device_b_table["ASPECT"] != device_a) & (device_b_table["ASPECT"] != 'Generic')]
                    top_four_aspects = data_filtered.head(4)
                    d = device_b_table.to_dict(orient='records')
                    st.dataframe(styled_df_b)
                    second_table = styled_df_b.to_html(index = False)
                    full_response += second_table
                try:
                    raw_question = raw_question.replace("Compare", "Summarize reviews of")
                except:
                    pass
                comparision_summary = query_detailed_compare(raw_question + "Which have the following sentiment data" + str(c)+str(d))
                st.write(comparision_summary)
                full_response += comparision_summary
            except:
                st.write(f"Unable to fetch relevant details based on the provided input. Kindly refine your search query and try again!")


        elif (device_a != None and device_b == None) | (device_a == None and device_b == None):
        
            try:

                data = query_quant(user_question,[]) 
                # st.write(data)
                try:
                    total_reviews = data.loc[data.iloc[:, 0] == 'TOTAL', 'REVIEW_COUNT'].iloc[0]
                except:
                    pass
                # total_reviews = data.loc[data['ASPECT'] == 'TOTAL', 'REVIEW_COUNT'].iloc[0]
                try:
                    data['REVIEW_PERCENTAGE'] = data['REVIEW_COUNT'] / total_reviews * 100
                except:
                    pass
                dataframe_as_dict = data.to_dict(orient='records')

                classify_function = classify(user_question+str(dataframe_as_dict))


                if classify_function == "1":
                    data_new = data
                    data_new = data_new.dropna(subset=['ASPECT_SENTIMENT'])
                    data_new = data_new[~data_new["ASPECT"].isin(["Generic", "Account", "Customer-Service", "Browser"])]
                    data_new = make_desired_df(data_new)
                    styled_df = data_new.style.applymap(lambda x: custom_color_gradient(x, int(-100), int(100)), subset=['ASPECT_SENTIMENT'])
                    data_filtered = data_new[(data_new['ASPECT'] != 'TOTAL') & (data_new['ASPECT'] != 'Generic')]
                    top_four_aspects = data_filtered.head(4)
                    dataframe_as_dict = data_new.to_dict(orient='records')
                    aspects_list = top_four_aspects['ASPECT'].to_list()
            #         formatted_aspects = ', '.join(f"'{aspect}'" for aspect in aspects_list)
                    key_df = get_final_df(aspects_list, device)
                    b =  key_df.to_dict(orient='records')
                    summary_ans = query_aspect_wise_detailed_summary(user_question+"which have the following sentiment :" + str(dataframe_as_dict) + "these are the imporatnt aspect based on aspect ranking : " + str(aspects_list) + "and their respective keywords" + str(b),[])
                    st.write(summary_ans)
                    full_response += summary_ans
                    heat_map = st.checkbox("Would you like to see the Aspect wise sentiment of this Product?")
                    if heat_map:
                        st.dataframe(styled_df)
                        styled_df = styled_df.to_html(index = False)
                        full_response += styled_df
                        aspect_names = ['Interface', 'Connectivity', 'Privacy','Compatibility', 'Generic', 'Innovation', 'Reliability','Productivity', 'Price', 'Text Summarization/Generation','Code Generation', 'Ease of Use', 'Performance','Personalization/Customization']
                        with st.form(key='my_form'):
                            aspect_wise_sentiment = st.markdown("Verbatims")
                            selected_aspect = st.selectbox('Select an aspect to see consumer reviews:', aspect_names)
                            submitted = st.form_submit_button('Submit')
                            if submitted:
                                query = f"""
                                SELECT Keywords,
                                       COUNT(CASE WHEN Sentiment = 'positive' THEN 1 END) AS Positive_Count,
                                       COUNT(CASE WHEN Sentiment = 'negative' THEN 1 END) AS Negative_Count,
                                       COUNT(CASE WHEN Sentiment = 'neutral' THEN 1 END) AS Neutral_Count,
                                       COUNT(*) as Total_Count
                                FROM Copilot_Sentiment_Data
                                WHERE Aspect LIKE '%{selected_aspect}%' AND Product_Family LIKE '%{device}%'
                                GROUP BY Keywords
                                ORDER BY Total_Count DESC;
                                """
                                key_df = ps.sqldf(query, globals())
                                total_aspect_count = key_df['Total_Count'].sum()
                                key_df['Positive_Percentage'] = (key_df['Positive_Count'] / key_df['Total_Count']) * 100
                                key_df['Negative_Percentage'] = (key_df['Negative_Count'] / key_df['Total_Count']) * 100
                                key_df['Neutral_Percentage'] = (key_df['Neutral_Count'] / key_df['Total_Count']) * 100
                                key_df['Keyword_Contribution'] = (key_df['Total_Count'] / total_aspect_count) * 100
                                key_df = key_df.drop(['Positive_Count', 'Negative_Count', 'Neutral_Count', 'Total_Count'], axis=1)
                                key_df = key_df.head(10)
                                b =  key_df.to_dict(orient='records')
                                deep_dive_summary = query_detailed_deepdive("Summarize reviews of" + device + "for " +  selected_aspect +  "Aspect which have following "+str(dataframe_as_dict)+ str(b) + "Reviews: ",[])
                                st.write(deep_dive_summary)
                                full_response += deep_dive_summary
                                
                elif classify_function == "2":
                    data= quantifiable_data(user_question)
                    if len(data)>0:
                        numerical_cols = data.select_dtypes(include='number').columns

        # Round float values in numerical columns to one decimal place
                        data[numerical_cols] = data[numerical_cols].apply(lambda x: x.round(1) if x.dtype == 'float' else x)
                        st.dataframe(data)
                        data_1 = data.to_html(index = False)
                        full_response += data_1
                        if 'NET_SENTIMENT' in data.columns:
                            st.write(f"********** Overall Net Sentiment is {overall_net_sentiment} for {overall_review_count} reviews ***********")
                            data['Impact']=np.where(data['NET_SENTIMENT']<overall_net_sentiment,'Driving Overall Net Sentiment LOW','Driving Overall Net Sentiment HIGH')

                        dataframe_as_dict = data.to_dict(orient='records')

                        try:
                            data = data.dropna()
                        except:
                            pass
                        try:
                            user_question = user_question.replace("What is the", "Summarize reviews of")
                        except:
                            pass
                        qunat_summary = query_detailed_summary(str(dataframe_as_dict),user_question + "Which have the following sentiment data : " + str(dataframe_as_dict),[])
                        st.write(qunat_summary)
                        full_response += qunat_summary
                        if(len(data))>1:
                            generate_chart(data)
                    else:
                        st.write(f"Unable to fetch relevant details based on the provided input. Kindly refine your search query and try again!")
            except:
                st.write(f"Unable to fetch relevant details based on the provided input. Kindly refine your search query and try again!")
        else:
            print('No Flow')
            
global full_response
if __name__ == "__main__":
    if st.sidebar.subheader("Select an option"):
        options = ["Copilot", "Devices"]
        selected_options = st.sidebar.selectbox("Select product", options)
        
        if selected_options == "Copilot":
            st.header("Copilot Review Synthesis Tool")
            if "messages" not in st.session_state:
                st.session_state['messages'] = []
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    if message["role"] == "assistant" and "is_html" in message and message["is_html"]:
                        st.markdown(message["content"], unsafe_allow_html=True)
                    else:
                        st.markdown(message["content"])
            if user_question := st.chat_input("Enter the Prompt: "):
                st.chat_message("user").markdown(user_question)
                st.session_state.messages.append({"role": "user", "content": user_question})
                with st.chat_message("assistant"):
                    full_response = ""
                    try:
                        user_question = user_question.replace("Give me", "What is").replace("Give", "What is")
                    except:
                        pass
                    classification = finetuned_prompt(user_question)
                    print(classification)
                    if classification != 'Generic':
                        user_question_1 = rephrased_prompt(user_question)
                        user_ques(user_question_1, user_question)
                    else:
                        user_question_1 = user_question
                        Gen_Ans = query_detailed_generic(user_question_1)
                        st.write(Gen_Ans)
                        full_response += Gen_Ans
                    st.session_state.messages.append({"role": "assistant", "content": full_response, "is_html": True})
            if st.button("New Chat"):
                st.session_state['messages'] = []
                st.experimental_rerun()
        
        elif selected_options == "Devices":
            st.header("Devices Review Synthesis Tool")
            if "messages" not in st.session_state:
                st.session_state['messages'] = []
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    if message["role"] == "assistant" and "is_html" in message and message["is_html"]:
                        st.markdown(message["content"], unsafe_allow_html=True)
                    else:
                        st.markdown(message["content"])
            if user_question := st.chat_input("Enter the Prompt: "):
                st.chat_message("user").markdown(user_question)
                st.session_state.messages.append({"role": "user", "content": user_question})
                with st.chat_message("assistant"):
                    full_response = ""
                    classification = identify_prompt(user_question)
                    if classification == 'summarization':
                        user_question_1 = identify_devices(user_question)
                        device_summarization(user_question_1)
                    elif classification == 'comparison':
                        st.write("IN PROGRESS")
                    else:
                        Gen_Ans = query_devices_detailed_generic(user_question)
                        st.write(Gen_Ans)
                        full_response += Gen_Ans
                    st.session_state.messages.append({"role": "assistant", "content": full_response, "is_html": True})
            if st.button("New Chat"):
                st.session_state['messages'] = []
                st.experimental_rerun()


			
			