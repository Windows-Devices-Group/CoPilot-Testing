{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ec5270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Libraries\n",
    "import streamlit as st\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import numpy as np\n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import AzureOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "import openai\n",
    "import pyodbc\n",
    "import urllib\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from pandasai import SmartDataframe\n",
    "import pandas as pd\n",
    "from pandasai.llm import AzureOpenAI\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "import base64\n",
    "import pandasql as ps\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "#Initializing API Keys to use LLM\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"a22e367d483f4718b9e96b1f52ce6d53\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://hulk-openai.openai.azure.com/\"\n",
    "\n",
    "#Reading the dataset\n",
    "Sentiment_Data  = pd.read_csv(\"Windows_Data_116K.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a0caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sentiment_Score_Derivation(value):\n",
    "    try:\n",
    "        if value == \"Positive\":\n",
    "            return 1\n",
    "        elif value == \"Negative\":\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while deriving Sentiment Score: {e}\"\n",
    "        return err    \n",
    "\n",
    "#Deriving Sentiment Score and Review Count columns into the dataset\n",
    "Sentiment_Data[\"Sentiment_Score\"] = Sentiment_Data[\"Sentiment\"].apply(Sentiment_Score_Derivation)\n",
    "Sentiment_Data[\"Review_Count\"] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0fd20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_top_to_limit(sql):\n",
    "    try:\n",
    "        tokens = sql.upper().split()\n",
    "        is_top_used = False\n",
    "\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token == 'TOP':\n",
    "                is_top_used = True\n",
    "                if i + 1 < len(tokens) and tokens[i + 1].isdigit():\n",
    "                    limit_value = tokens[i + 1]\n",
    "                    # Remove TOP and insert LIMIT and value at the end\n",
    "                    del tokens[i:i + 2]\n",
    "                    tokens.insert(len(tokens), 'LIMIT')\n",
    "                    tokens.insert(len(tokens), limit_value)\n",
    "                    break  # Exit loop after successful conversion\n",
    "                else:\n",
    "                    raise ValueError(\"TOP operator should be followed by a number\")\n",
    "\n",
    "        return ' '.join(tokens) if is_top_used else sql\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while converting Top to Limit in SQL Query: {e}\"\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "734e7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tablename(sql, table_name):\n",
    "    try:\n",
    "        x = sql.upper()\n",
    "        query = x.replace(table_name.upper(), table_name)\n",
    "        return query\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while processing table name in SQL query: {e}\"\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5611e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_chain_quant(history):\n",
    "    try:\n",
    "        hist = \"\"\"\"\"\"\n",
    "        for i in history:\n",
    "            hist = hist+\"\\nUser: \"+i[0]\n",
    "            if isinstance(i[1],pd.DataFrame):\n",
    "                x = i[1].to_string()\n",
    "            else:\n",
    "                x = i[1]\n",
    "            hist = hist+\"\\nResponse: \"+x\n",
    "        prompt_template = \"\"\"\n",
    "        \n",
    "        If an user is asking for Summarize reviews of any product. Note that user is not seeking for reviews, user is seeking for all the Quantitative things of the product(Net Sentiment & Review Count) and also (Aspect wise sentiment and Aspect wise review count)\n",
    "        So choose to Provide Net Sentiment and Review Count and Aspect wise sentiment and their respective review count and Union them in single table\n",
    "        \n",
    "        Example : If the user Quesiton is \"Summarize reviews of CoPilot Produt\"\n",
    "        \n",
    "        User seeks for net sentiment and aspect wise net sentiment of \"Windows 10\" Product and their respective review count in a single table\n",
    "        \n",
    "        Your response should be : Overall Sentiment is nothing but the net sentiment and overall review count of the product\n",
    "        \n",
    "                        Aspect Aspect_SENTIMENT REVIEW_COUNT\n",
    "                    0 TOTAL 40 15000.0\n",
    "                    1 Performance 31.8 2302.0\n",
    "                    2 Gaming 20.2 570.0\n",
    "                    3 Display 58.9 397.0\n",
    "                    4 Design -1.2 345.0\n",
    "                    5 Touchpad 20.1 288.0\n",
    "                    6 Storage/Memory -22.9 271.0\n",
    "                    7 Audio-Microphone -43.7 247.0\n",
    "                    8 Software -28.6 185.0\n",
    "                    9 Hardware 52.9 170.0\n",
    "                    10 Keyboard 19.1 157.0\n",
    "                    11 Account -44.7 152.0\n",
    "                    12 Price 29.5 95.0\n",
    "                    13 Graphics 18.9 90.0 and so on\n",
    "                    \n",
    "                    The Query has to be like this \n",
    "                    \n",
    "                SELECT 'TOTAL' AS Aspect, \n",
    "                ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, \n",
    "                SUM(Review_Count) AS Review_Count\n",
    "                FROM Sentiment_Data\n",
    "                WHERE Product_Family LIKE '%Asus Rog Zephyrus%'\n",
    "\n",
    "                UNION\n",
    "\n",
    "                SELECT Aspect, \n",
    "                ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, \n",
    "                SUM(Review_Count) AS Review_Count\n",
    "                FROM Sentiment_Data\n",
    "                WHERE Product_Family LIKE '%Asus Rog Zephyrus%'\n",
    "                GROUP BY Aspect\n",
    "\n",
    "                ORDER BY Review_Count DESC\n",
    "\n",
    "                    \n",
    "                    \n",
    "                IMPORTANT : if any particular Aspect \"Performance\" in user prompt:\n",
    "                    \n",
    "\n",
    "                        SELECT 'TOTAL' AS Aspect, \n",
    "                        ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, \n",
    "                        SUM(Review_Count) AS Review_Count\n",
    "                        FROM Sentiment_Data\n",
    "                        WHERE Product_Family LIKE '%Asus Rog Zephyrus%'\n",
    "\n",
    "                        UNION\n",
    "\n",
    "                        SELECT Aspect, \n",
    "                        ROUND((SUM(Sentiment_Score) / SUM(Review_Count)) * 100, 1) AS Aspect_Sentiment, \n",
    "                        SUM(Review_Count) AS Review_Count\n",
    "                        FROM Sentiment_Data\n",
    "                        WHERE Product_Family LIKE '%Asus Rog Zephyrus%'\n",
    "                        GROUP BY Aspect\n",
    "                        HAVING Aspect LIKE %'Performance'%\n",
    "\n",
    "                        ORDER BY Review_Count DESC\n",
    "\n",
    "\n",
    "        \n",
    "        IMPORTANT : IT has to be Net sentiment and Aspect Sentiment. Create 2 SQL Query and UNION them\n",
    "        \n",
    "        1. Your Job is to convert the user question to SQL Query (Follow Microsoft SQL server SSMS syntax.). You have to give the query so that it can be used on Microsoft SQL server SSMS.You have to only return query as a result.\n",
    "            2. There is only one table with table name Sentiment_Data where each row is a user review. The table has 10 columns, they are:\n",
    "                Review: Review of the Copilot Product\n",
    "                Data_Source: From where is the review taken. It contains different retailers\n",
    "                Geography: From which Country or Region the review was given. It contains different Grography.\n",
    "                Title: What is the title of the review\n",
    "                Review_Date: The date on which the review was posted\n",
    "                Product: Corresponding product for the review. It contains following values: \"Windows 11 (Preinstall)\", \"Windows 10\"\n",
    "                Product_Family: Which version or type of the corresponding Product was the review posted for. Different Device Names\n",
    "                Sentiment: What is the sentiment of the review. It contains following values: 'Positive', 'Neutral', 'Negative'.\n",
    "                Aspect: The review is talking about which aspect or feature of the product. It contains following values: \"Audio-Microphone\",\"Software\",\"Performance\",\"Storage/Memory\",\"Keyboard\",\"Browser\",\"Connectivity\",\"Hardware\",\"Display\",\"Graphics\",\"Battery\",\"Gaming\",\"Design\",\"Ports\",\"Price\",\"Camera\",\"Customer-Service\",\"Touchpad\",\"Account\",\"Generic\"\n",
    "                Keyword: What are the keywords mentioned in the product\n",
    "                Review_Count - It will be 1 for each review or each row\n",
    "                Sentiment_Score - It will be 1, 0 or -1 based on the Sentiment.\n",
    "                \n",
    "            3. Sentiment mark is calculated by sum of Sentiment_Score.\n",
    "            4. Net sentiment is calculcated by sum of Sentiment_Score divided by sum of Review_Count. It should be in percentage. Example:\n",
    "                    SELECT ((SUM(Sentiment_Score)*1.0)/(SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment \n",
    "                    FROM Sentiment_Data\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            5. Net sentiment across country or across region is sentiment mark of a country divided by total reviews of that country. It should be in percentage.\n",
    "                Example to calculate net sentiment across country:\n",
    "                    SELECT Geography, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment\n",
    "                    FROM Sentiment_Data\n",
    "                    GROUP BY Geography\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            6. Net Sentiment across a column \"X\" is calculcated by Sentiment Mark for each \"X\" divided by Total Reviews for each \"X\".\n",
    "                Example to calculate net sentiment across a column \"X\":\n",
    "                    SELECT X, ((SUM(Sentiment_Score)*1.0) / (SUM(Review_Count)*1.0)) * 100 AS Net_Sentiment\n",
    "                    FROM Sentiment_Data\n",
    "                    GROUP BY X\n",
    "                    ORDER BY Net_Sentiment DESC\n",
    "            7. Distribution of sentiment is calculated by sum of Review_Count for each Sentiment divided by overall sum of Review_Count\n",
    "                Example: \n",
    "                    SELECT Sentiment, SUM(ReviewCount)*100/(SELECT SUM(Review_Count) AS Reviews FROM Sentiment_Data) AS Total_Reviews \n",
    "                    FROM Sentiment_Data \n",
    "                    GROUP BY Sentiment\n",
    "                    ORDER BY Total_Reviews DESC\n",
    "            8. Convert numerical outputs to float upto 1 decimal point.\n",
    "            9. Always include ORDER BY clause to sort the table based on the aggregate value calculated in the query.\n",
    "            10. Top Country is based on Sentiment_Score i.e., the Country which have highest sum(Sentiment_Score)\n",
    "            11. Always use 'LIKE' operator whenever they mention about any Country. Use 'LIMIT' operator instead of TOP operator.Do not use TOP OPERATOR. Follow syntax that can be used with pandasql.\n",
    "            12. If you are using any field in the aggregate function in select statement, make sure you add them in GROUP BY Clause.\n",
    "            13. Make sure to Give the result as the query so that it can be used on Microsoft SQL server SSMS.\n",
    "            14. Important: Always show Net_Sentiment in Percentage upto 1 decimal point. Hence always make use of ROUND function while giving out Net Sentiment and Add % Symbol after it.\n",
    "            15. Important: User can ask question about any categories including Aspects, Geograpgy, Sentiment etc etc. Hence, include the in SQL Query if someone ask it.\n",
    "            16. Important: You Response should directly starts from SQL query nothing else.\n",
    "            17. Important: Always use LIKE keyword instead of = symbol while generating SQL query.\n",
    "            18. Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\n",
    "            19. Sort all Quantifiable outcomes based on review count\n",
    "        \\n Following is the previous conversation from User and Response, use it to get context only:\"\"\" + hist + \"\"\"\\n\n",
    "                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\\n\n",
    "        Context:\\n {context}?\\n\n",
    "        Question: \\n{question}\\n\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_deployment=\"Verbatim-Synthesis\",\n",
    "            api_version='2023-12-01-preview',\n",
    "            temperature = 0)\n",
    "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "        return chain\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting conversation chain for quantifiable review summarization: {e}\"\n",
    "        return err\n",
    "\n",
    "#Function to convert user prompt to quantitative outputs for Copilot Review Summarization\n",
    "def query_quant(user_question, history, vector_store_path=\"faiss_index_Windows_116k\"):\n",
    "    try:\n",
    "        # Initialize the embeddings model\n",
    "        embeddings = AzureOpenAIEmbeddings(azure_deployment=\"Embedding-Model\")\n",
    "        \n",
    "        # Load the vector store with the embeddings model\n",
    "        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        \n",
    "        # Rest of the function remains unchanged\n",
    "        chain = get_conversational_chain_quant(history)\n",
    "        docs = []\n",
    "        response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
    "        SQL_Query = response[\"output_text\"]\n",
    "        SQL_Query = convert_top_to_limit(SQL_Query)\n",
    "        print(SQL_Query)\n",
    "        SQL_Query = process_tablename(SQL_Query,\"Sentiment_Data\")\n",
    "    #     print(SQL_Query)\n",
    "        data = ps.sqldf(SQL_Query, globals())\n",
    "        data_1 = data\n",
    "        html_table = data.to_html(index=False)\n",
    "    #     return html_table\n",
    "        return data_1\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while generating response for quantitative review summarization: {e}\"\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4548bf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_chain_detailed(history):\n",
    "    try:\n",
    "        hist = \"\"\"\"\"\"\n",
    "        for i in history:\n",
    "            hist = hist+\"\\nUser: \"+i[0]\n",
    "            if isinstance(i[1],pd.DataFrame):\n",
    "                x = i[1].to_string()\n",
    "            else:\n",
    "                x = i[1]\n",
    "            hist = hist+\"\\nResponse: \"+ x\n",
    "        prompt_template = \"\"\"\n",
    "        \n",
    "        1. Your Job is to analyse the Net Sentiment Aspect wise sentiment and Key word regarding the aspect and summarize the reviews that user asks for utilizing the reviews and numbers you get. Use maximum use of the numbers and Justify the numbers using the reviews.\n",
    "        \n",
    "        Overall Sentiment is the Net Sentiment.\n",
    "        \n",
    "        Condition 1 : If the net sentiment is less than aspect sentiment, which means that particular aspect is driving the net sentiment Higher for that device. In this case provide why the aspect sentiment is lower than net sentiment.\n",
    "        Condition 2 : If the net sentiment is high than aspect sentiment, which means that particular aspect is driving the net sentiment Lower for that device. In this case provide why the aspect sentiment is higher than net sentiment.\n",
    "            \n",
    "            You must be receiving keywords information. If there are any keywords which have more keyword_contribution mention that keyword with its contribution percentage and Positive, negative percentages. \n",
    "            Give the reviews summarized for this aspect \n",
    "            \n",
    "            Give at least top 2 keyword information - (Contribution , Positive and Negative Percentage) and when summarizing reviews focus on those particular keywords.\n",
    "            \n",
    "            \n",
    "\n",
    "            IMPORTANT: Use only the data provided to you and do not rely on pre-trained documents.\n",
    "\n",
    "            Your summary should justify the above conditions and tie in with the net sentiment and aspect sentiment and keywords. Mention the difference between Net Sentiment and Aspect Sentiment (e.g., -2% or +2% higher than net sentiment) in your summary and provide justification.\n",
    "            \n",
    "            \n",
    "            Your response should be : \n",
    "            Net Sentiment of the device and aspect sentiment of that aspect of the device (Mention Performance, Aspect Sentiment) . \n",
    "            Top Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed\n",
    "            Top 2nd Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed\n",
    "            Top 3rd Keyword contribution and their positive and negative percentages and summarize Reviews what user have spoken regarding this keywords in 2 to 3 lines detailed\n",
    "               Limit yourself to top 3 keywords and don't mention as top 1, top 2, top 3 and all. Mention them as pointers\n",
    "            Pros and 5 Cons\n",
    "            Overall Summary\n",
    "            \n",
    "            IMPORTANT : Example Template :\n",
    "            \n",
    "            ALWAYS FOLLOW THIS TEMPLATE : Don't miss any of the below:\n",
    "                        \n",
    "                        \n",
    "            Response : \"BOLD ALL THE NUMBERS\"\n",
    "            \n",
    "            \n",
    "                    Net Sentiment: 41.9%\n",
    "                    Aspect Sentiment (Gaming): 53.1%\n",
    "\n",
    "                    75% of the users commented about Gaming on this device. Gaming drives the sentiment high for Lenovo Legion\n",
    "\n",
    "                    Top Keyword: Gaming (Contribution: 33.22%, Positive: 68.42%, Negative: 6.32%)\n",
    "                    - Users have praised the gaming experience on the Lenovo Legion, with many mentioning the smooth gameplay and high FPS.\n",
    "                    - Some users have reported experiencing lag while gaming, but overall, the gaming performance is highly rated.\n",
    "\n",
    "                    Top 2nd Keyword: Game (Contribution: 33.22%, Positive: 60%, Negative: 8.42%)\n",
    "                    - Users appreciate the ability to play various games on the Lenovo Legion, mentioning the enjoyable gaming experience.\n",
    "                    - A few users have mentioned encountering some issues with certain games, but the majority have had a positive experience.\n",
    "\n",
    "                    Top 3rd Keyword: Play (Contribution: 16.08%, Positive: 56.52%, Negative: 13.04%)\n",
    "                    - Users mention the ease of playing games on the Lenovo Legion, highlighting the smooth gameplay and enjoyable experience.\n",
    "                    - Some users have reported difficulties with certain games, experiencing lag or other performance issues.\n",
    "\n",
    "                    Pros:\n",
    "                    1. Smooth gameplay experience\n",
    "                    2. High FPS and enjoyable gaming performance\n",
    "                    3. Wide range of games available\n",
    "                    4. Positive feedback on gaming experience\n",
    "                    5. Ease of playing games\n",
    "\n",
    "                    Cons:\n",
    "                    1. Some users have reported lag or performance issues while gaming\n",
    "                    2. Occasional difficulties with certain games\n",
    "\n",
    "                    Overall Summary:\n",
    "                    The net sentiment for the Lenovo Legion is 41.9%, while the aspect sentiment for gaming is 53.1%. This indicates that the gaming aspect is driving the net sentiment higher for the device. Users have praised the smooth gameplay, high FPS, and enjoyable gaming experience on the Lenovo Legion. The top keywords related to gaming contribute significantly to the aspect sentiment, with positive percentages ranging from 56.52% to 68.42%. However, there are some reports of lag and performance issues with certain games. Overall, the Lenovo Legion is highly regarded for its gaming capabilities, but there is room for improvement in addressing performance issues for a seamless gaming experience.\n",
    "               \n",
    "           IMPORTANT : Do not ever change the above template of Response. Give Spaces accordingly in the response to make it more readable.\n",
    "                    \n",
    "          Enhance the model’s comprehension to accurately interpret user queries by:\n",
    "          Recognizing abbreviations for country names (e.g., ‘DE’ for Germany, ‘USA’or 'usa' or 'US' for the United States of America) and expanding them to their full names for clarity.\n",
    "          Understanding product family names even when written in reverse order or missing connecting words (e.g., ‘copilot in windows 11’ as ‘copilot windows’ and ‘copilot for security’ as ‘copilot security’ etc.).\n",
    "          Utilizing context and available data columns to infer the correct meaning and respond appropriately to user queries involving variations in product family names or geographical references\n",
    "          Please provide a comprehensive Review summary, feature comparison, feature suggestions for specific product families and actionable insights that can help in product development and marketing strategies.\n",
    "          Generate acurate response only, do not provide extra information.\n",
    "            \n",
    "            Important: Generate outputs using the provided dataset only, don't use pre-trained information to generate outputs.\\n Following is the previous conversation from User and Response, use it to get context only:\"\"\" + hist + \"\"\"\\n\n",
    "                Use the above conversation chain to gain context if the current prompt requires context from previous conversation.\\n\n",
    "        Context:\\n {context}?\\n\n",
    "        Question: \\n{question}\\n\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "        model = AzureChatOpenAI(\n",
    "            azure_deployment=\"Verbatim-Synthesis\",\n",
    "            api_version='2023-12-01-preview',\n",
    "            temperature = 0.0)\n",
    "        chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "        return chain\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting conversation chain for detailed review summarization: {e}\"\n",
    "        return err\n",
    "\n",
    "# Function to handle user queries using the existing vector store\n",
    "def query_detailed(user_question, history, vector_store_path=\"faiss_index_CopilotSample\"):\n",
    "    try:\n",
    "        embeddings = AzureOpenAIEmbeddings(azure_deployment=\"Embedding-Model\")\n",
    "        vector_store = FAISS.load_local(vector_store_path, embeddings, allow_dangerous_deserialization=True)\n",
    "        chain = get_conversational_chain_detailed(history)\n",
    "        docs = vector_store.similarity_search(user_question)\n",
    "        response = chain({\"input_documents\": docs, \"question\": user_question}, return_only_outputs=True)\n",
    "        return response[\"output_text\"]\n",
    "    except Exception as e:\n",
    "        err = f\"An error occurred while getting LLM response for detailed review summarization: {e}\"\n",
    "        return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def custom_color_gradient(val, vmin, vmax):\n",
    "    green_hex = '#347c47'\n",
    "    middle_hex = '#dcdcdc'\n",
    "    lower_hex = '#b0343c'\n",
    "    \n",
    "    # Adjust the normalization to set the middle value as 0\n",
    "    try:\n",
    "        normalized_val = (val - vmin) / (vmax - vmin) if vmax != vmin else 0.5\n",
    "    except ZeroDivisionError:\n",
    "        normalized_val = 0.5\n",
    "    \n",
    "    normalized_val = (normalized_val - 0.5) * 2  # Scale and shift to set middle value as 0\n",
    "    \n",
    "    if normalized_val <= 0:\n",
    "        # Interpolate between lower_hex and middle_hex for values <= 0\n",
    "        r = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[1:3], 16), int(middle_hex[1:3], 16)]))\n",
    "        g = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[3:5], 16), int(middle_hex[3:5], 16)]))\n",
    "        b = int(np.interp(normalized_val, [-1, 0], [int(lower_hex[5:7], 16), int(middle_hex[5:7], 16)]))\n",
    "    else:\n",
    "        # Interpolate between middle_hex and green_hex for values > 0\n",
    "        r = int(np.interp(normalized_val, [0, 1], [int(middle_hex[1:3], 16), int(green_hex[1:3], 16)]))\n",
    "        g = int(np.interp(normalized_val, [0, 1], [int(middle_hex[3:5], 16), int(green_hex[3:5], 16)]))\n",
    "        b = int(np.interp(normalized_val, [0, 1], [int(middle_hex[5:7], 16), int(green_hex[5:7], 16)]))\n",
    "    \n",
    "    # Convert interpolated RGB values to hex format for CSS color styling\n",
    "    hex_color = f'#{r:02x}{g:02x}{b:02x}'\n",
    "    \n",
    "    return f'background-color: {hex_color}; color: black;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9be2930f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-18 13:11:18.513 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\v-sansuresh\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "st.title(\"Quantitative Review Summarization\")\n",
    "device_name = st.text_input(\"Enter the Product name : \")\n",
    "if device_name:\n",
    "    st.subheader(\"Net Sentiment and Aspects driving the sentiment: \")\n",
    "    data = query_quant(\"Summarize the reviews of \"+ device_name, [])\n",
    "    total_reviews = data.loc[data['ASPECT'] == 'TOTAL', 'REVIEW_COUNT'].iloc[0]\n",
    "    data['REVIEW_PERCENTAGE'] = data['REVIEW_COUNT'] / total_reviews * 100\n",
    "    dataframe_as_dict = data.to_dict(orient='records')\n",
    "    data_new = data\n",
    "    data_new = data_new.dropna(subset=['ASPECT_SENTIMENT'])\n",
    "    data_new = data_new[data_new[\"ASPECT_SENTIMENT\"] != \"TOTAL\"]\n",
    "    vmin = data_new['ASPECT_SENTIMENT'].min()\n",
    "    vmax = data_new['ASPECT_SENTIMENT'].max()\n",
    "    styled_df = data_new.style.applymap(lambda x: custom_color_gradient(x, vmin, vmax), subset=['ASPECT_SENTIMENT'])\n",
    "    st.dataframe(styled_df,hide_index=True)\n",
    "    st.subheader(\"Review Summarization\")\n",
    "    with st.form(key='my_form'):\n",
    "        aspect_names = ['All', 'Performance', 'Design', 'Audio', 'Battery', 'Camera', 'Connectivity', 'Display', 'Customer Service','Gaming', 'Graphics', 'Hardware', 'Keyboard', 'Touchpad', 'Ports', 'Price', 'Software', 'Storage/Memory']\n",
    "#         aspect_names =  ['Microsoft Product', 'Interface', 'Code Generation', 'Image Generation', 'Productivity', 'Text Summarization/Generation', 'Connectivity', 'Compatibility', 'Privacy', 'Ease of Use', 'Reliability', 'Price', 'Innovation', 'Customization/Personalization', 'Generic']\n",
    "        selected_aspect = st.selectbox('Select an aspect to see consumer reviews:', aspect_names)\n",
    "        submitted = st.form_submit_button('Submit')\n",
    "        if submitted:\n",
    "            device = device_name\n",
    "\n",
    "            query = f\"\"\"\n",
    "            SELECT Keywords,\n",
    "                   COUNT(CASE WHEN Sentiment = 'Positive' THEN 1 END) AS Positive_Count,\n",
    "                   COUNT(CASE WHEN Sentiment = 'Negative' THEN 1 END) AS Negative_Count,\n",
    "                   COUNT(CASE WHEN Sentiment = 'Neutral' THEN 1 END) AS Neutral_Count,\n",
    "                   COUNT(*) as Total_Count\n",
    "            FROM Sentiment_Data\n",
    "            WHERE Aspect LIKE '%{selected_aspect}%' AND Product_Family LIKE '%{device}%'\n",
    "            GROUP BY Keywords\n",
    "            ORDER BY Total_Count DESC;\n",
    "        \"\"\"\n",
    "            key_df = ps.sqldf(query, globals())\n",
    "            total_aspect_count = key_df['Total_Count'].sum()\n",
    "            key_df['Positive_Percentage'] = (key_df['Positive_Count'] / key_df['Total_Count']) * 100\n",
    "            key_df['Negative_Percentage'] = (key_df['Negative_Count'] / key_df['Total_Count']) * 100\n",
    "            key_df['Neutral_Percentage'] = (key_df['Neutral_Count'] / key_df['Total_Count']) * 100\n",
    "            key_df['Keyword_Contribution'] = (key_df['Total_Count'] / total_aspect_count) * 100\n",
    "            key_df = key_df.drop(['Positive_Count', 'Negative_Count', 'Neutral_Count', 'Total_Count'], axis=1)\n",
    "            key_df = key_df.head(10)\n",
    "            b =  key_df.to_dict(orient='records')\n",
    "            st.write((query_detailed(\"Summarize reviews of\" + device + \"for \" +  selected_aspect +  \"Aspect which have following \"+str(dataframe_as_dict)+ str(b) + \"Reviews: \",[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d63973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
